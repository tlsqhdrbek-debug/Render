import streamlit as st
import fitz  # PyMuPDF
import os
import re
import numpy as np
from openai import OpenAI
from pathlib import Path
from docx import Document
from datetime import datetime
import tiktoken
import json
import traceback
import time
import uuid
from functools import wraps
import pandas as pd

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
    }
    .stApp {
        background: white;
        border-radius: 24px;
        padding: 40px;
        margin: 20px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.15);
    }
    /* ì‚¬ì´ë“œë°” ë„ˆë¹„ ì¦ê°€ */
    [data-testid="stSidebar"] {
        min-width: 350px !important;
        max-width: 350px !important;
    }
    /* ì‚¬ì´ë“œë°” ë²„íŠ¼ í¬ê¸° ì¡°ì • */
    .stSidebar button {
        font-size: 11px !important;
        padding: 5px 10px !important;
        white-space: nowrap !important;
    }
    /* Expander ë‚´ë¶€ ë²„íŠ¼ë„ ì‘ê²Œ */
    [data-testid="stExpander"] button {
        font-size: 11px !important;
    }
    /* íƒ­ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8fafc;
        padding: 10px;
        border-radius: 12px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 0 30px;
        background-color: white;
        border-radius: 8px;
        font-size: 16px !important;
        font-weight: 600 !important;
        color: #64748b;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }
    .stTabs [data-baseweb="tab"]:hover {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border-color: transparent !important;
    }
    .keyword-tag {
        display: inline-flex;
        align-items: center;
        padding: 4px 10px;
        margin: 3px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        font-size: 12px;
        font-weight: 500;
        white-space: nowrap;
    }
    .template-container {
        display: flex;
        flex-wrap: wrap;
        gap: 5px;
        align-items: center;
        margin-bottom: 10px;
    }
    .delete-btn {
        background: rgba(255, 255, 255, 0.2);
        border: none;
        color: white;
        width: 20px;
        height: 20px;
        border-radius: 50%;
        cursor: pointer;
        margin-left: 8px;
    }
</style>
""", unsafe_allow_html=True)

# .env íŒŒì¼ ë¡œë“œ
def load_env():
    """Load environment variables from .env file"""
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

load_env()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = None
if os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_API_KEY") != "your-api-key-here":
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=openai_api_key)
    st.sidebar.success("âœ… OpenAI API í‚¤ ë¡œë“œë¨")
else:
    st.sidebar.warning("âš ï¸ .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase_client = None
try:
    from supabase import create_client, Client
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")
    
    if supabase_url and supabase_key:
        supabase_client = create_client(supabase_url, supabase_key)
        st.sidebar.success("âœ… Supabase ì—°ê²°ë¨")
    else:
        st.sidebar.info("â„¹ï¸ Supabase ë¯¸ì—°ê²° (í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì •)")
except Exception as e:
    st.sidebar.error(f"âš ï¸ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")

# Upstage API í‚¤ í™•ì¸
UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
if UPSTAGE_API_KEY and UPSTAGE_API_KEY != "your-upstage-api-key-here":
    st.sidebar.success("âœ… Upstage Document Parse ì—°ê²°ë¨")
else:
    st.sidebar.info("â„¹ï¸ Upstage API ë¯¸ì„¤ì • (ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ)")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if 'template' not in st.session_state:
    st.session_state.template = []
if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = {}
if 'pdf_text' not in st.session_state:
    st.session_state.pdf_text = ""
if 'report_sections' not in st.session_state:
    # ê¸°ë³¸ ë³´ê³ ì„œ ì„¹ì…˜ ì„ íƒ (ëª¨ë‘ ì„ íƒ)
    st.session_state.report_sections = [
        "ê¸°ì—… ê°œìš”",
        "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„",
        "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„",
        "ì¬ë¬´ ìš”ì•½",
        "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„",
        "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„",
        "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„",
        "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„",
        "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬",
        "ë¦¬ìŠ¤í¬ ìš”ì¸",
        "ì¢…í•© í‰ê°€"
    ]
if 'show_template_editor' not in st.session_state:
    st.session_state.show_template_editor = False
if 'reference_pdfs' not in st.session_state:
    st.session_state.reference_pdfs = {}  # {filename: extracted_text}
if 'structured_data' not in st.session_state:
    st.session_state.structured_data = None  # Upstage Parse êµ¬ì¡°í™” ë°ì´í„°

# ë¡œê¹… ì‹œìŠ¤í…œìš© ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸
if 'user_name' not in st.session_state:
    st.session_state.user_name = None
if 'user_email' not in st.session_state:
    st.session_state.user_email = None
if 'session_id' not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if 'current_test_session_id' not in st.session_state:
    st.session_state.current_test_session_id = None

# ============================================
# ë¡œê¹… ì‹œìŠ¤í…œ
# ============================================

def create_or_get_test_user(name, email=None):
    """í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ì¡°íšŒ"""
    if not supabase_client:
        return None
    
    try:
        # ì´ë¦„ê³¼ ì´ë©”ì¼ë¡œ ê¸°ì¡´ ì‚¬ìš©ì í™•ì¸
        if email:
            response = supabase_client.table("test_users").select("*").eq("name", name).eq("email", email).execute()
        else:
            response = supabase_client.table("test_users").select("*").eq("name", name).is_("email", "null").execute()
        
        if response.data:
            return response.data[0]
        
        # ìƒˆ ì‚¬ìš©ì ìƒì„±
        user_data = {
            "name": name,
            "email": email
        }
        response = supabase_client.table("test_users").insert(user_data).execute()
        return response.data[0] if response.data else None
    except Exception as e:
        st.error(f"ì‚¬ìš©ì ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def start_test_session(user_id, company_name, pdf_filename):
    """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘"""
    if not supabase_client:
        return None
    
    try:
        session_data = {
            "user_id": user_id,
            "company_name": company_name,
            "pdf_filename": pdf_filename,
            "status": "in_progress"
        }
        response = supabase_client.table("test_sessions").insert(session_data).execute()
        session_id = response.data[0]["id"] if response.data else None
        st.session_state.current_test_session_id = session_id
        return session_id
    except Exception as e:
        st.error(f"ì„¸ì…˜ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return None

def complete_test_session(status, error_message=None, execution_time_ms=None):
    """í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì™„ë£Œ"""
    if not supabase_client or not st.session_state.current_test_session_id:
        return
    
    try:
        update_data = {
            "completed_at": datetime.now().isoformat(),
            "status": status
        }
        if error_message:
            update_data["error_message"] = error_message
        # execution_time_msëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ (í…Œì´ë¸”ì— í•„ë“œ ì—†ìŒ)
        
        supabase_client.table("test_sessions").update(update_data).eq("id", st.session_state.current_test_session_id).execute()
    except Exception as e:
        st.error(f"ì„¸ì…˜ ì™„ë£Œ ê¸°ë¡ ì‹¤íŒ¨: {e}")

def log_activity(step, status, details=None, execution_time_ms=None):
    """í™œë™ ë¡œê·¸ ê¸°ë¡"""
    if not supabase_client:
        return
    
    # user_loginì€ ì„¸ì…˜ ID ì—†ì´ë„ ê¸°ë¡ (ì¼ë°˜ í…ìŠ¤íŠ¸ session_id ì‚¬ìš©)
    if step == "user_login":
        try:
            log_data = {
                "session_id": st.session_state.session_id,  # UUIDê°€ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì„¸ì…˜ ID
                "step": step,
                "status": status,
                "details": details if details else {},
                "execution_time_ms": execution_time_ms
            }
            supabase_client.table("activity_logs").insert(log_data).execute()
        except Exception as e:
            print(f"ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")
        return
    
    # ê·¸ ì™¸ ë¡œê·¸ëŠ” test_session_id í•„ìš”
    if not st.session_state.current_test_session_id:
        return
    
    try:
        log_data = {
            "session_id": st.session_state.current_test_session_id,
            "step": step,
            "status": status,
            "details": details if details else {},
            "execution_time_ms": execution_time_ms
        }
        supabase_client.table("activity_logs").insert(log_data).execute()
    except Exception as e:
        print(f"ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")  # st.error ëŒ€ì‹  print ì‚¬ìš© (ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨ëŠ” ì‚¬ìš©ìì—ê²Œ ë…¸ì¶œ ì•ˆ í•¨)

def log_error(step, error, stack_trace=None):
    """ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡"""
    if not supabase_client:
        return
    
    try:
        error_details = {
            "error_type": type(error).__name__,
            "error_message": str(error),
            "stack_trace": stack_trace or traceback.format_exc()
        }
        
        # test_session_idê°€ ìˆìœ¼ë©´ UUID ì‚¬ìš©, ì—†ìœ¼ë©´ ì¼ë°˜ session_id ì‚¬ìš©
        session_id_to_use = st.session_state.current_test_session_id if st.session_state.current_test_session_id else st.session_state.session_id
        
        log_data = {
            "session_id": session_id_to_use,
            "step": step,
            "status": "failed",
            "details": error_details
        }
        supabase_client.table("activity_logs").insert(log_data).execute()
    except Exception as e:
        print(f"ì—ëŸ¬ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")

def log_execution_time(step_name):
    """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            log_activity(step_name, "started")
            
            try:
                result = func(*args, **kwargs)
                execution_time_ms = int((time.time() - start_time) * 1000)
                log_activity(step_name, "success", execution_time_ms=execution_time_ms)
                return result
            except Exception as e:
                execution_time_ms = int((time.time() - start_time) * 1000)
                log_error(step_name, e)
                log_activity(step_name, "failed", execution_time_ms=execution_time_ms)
                raise
        return wrapper
    return decorator

def log_data_quality(
    selected_keywords,
    ocr_raw_text,
    ocr_structured_data,
    llm_extracted_data,
    llm_extraction_time_ms,
    company_name=None,
    pdf_filename=None,
    pdf_pages=None,
    report_content=None,
    report_generation_time_ms=None
):
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¡œê·¸ ê¸°ë¡ - OCR, LLM ì¶”ì¶œ, ë³´ê³ ì„œ ìƒì„± ë¹„êµ"""
    if not supabase_client or not st.session_state.current_test_session_id:
        return None
    
    try:
        # ì¶”ì¶œ ì„±ê³µë¥  ê³„ì‚°
        keywords_with_data = sum(1 for v in llm_extracted_data.values() if v and v != "ì •ë³´ ì—†ìŒ")
        keywords_missing_data = len(llm_extracted_data) - keywords_with_data
        extraction_success_rate = (keywords_with_data / len(llm_extracted_data) * 100) if llm_extracted_data else 0
        
        # í‘œ ë° ì°¨íŠ¸ ê°œìˆ˜ ê³„ì‚°
        ocr_tables_count = len(ocr_structured_data.get('tables', [])) if ocr_structured_data else 0
        ocr_charts_count = len(ocr_structured_data.get('charts', [])) if ocr_structured_data else 0
        
        log_data = {
            "session_id": st.session_state.current_test_session_id,
            "user_name": st.session_state.user_name,
            "company_name": company_name,
            
            # 1. ì„ íƒëœ í‚¤ì›Œë“œ
            "selected_keywords": selected_keywords,
            
            # 2. OCR ì›ë³¸ ë°ì´í„°
            "ocr_raw_text": ocr_raw_text[:20000] if ocr_raw_text else None,  # ì²˜ìŒ 20000ìë§Œ ì €ì¥ (ì¬ë¬´í‘œ ì „ì²´ í¬í•¨)
            "ocr_structured_data": ocr_structured_data,
            "ocr_tables_count": ocr_tables_count,
            "ocr_charts_count": ocr_charts_count,
            
            # 3. LLM ì¶”ì¶œ ë°ì´í„°
            "llm_extracted_data": llm_extracted_data,
            "llm_model": "gpt-4o-mini",
            "llm_extraction_time_ms": llm_extraction_time_ms,
            
            # 4. ë³´ê³ ì„œ ë°ì´í„°
            "report_generated": report_content is not None,
            "report_content": report_content[:20000] if report_content else None,  # ì²˜ìŒ 20000ìë§Œ ì €ì¥
            "report_model": "gpt-4o-mini" if report_content else None,
            "report_generation_time_ms": report_generation_time_ms,
            
            # 5. í’ˆì§ˆ ë©”íŠ¸ë¦­
            "extraction_success_rate": round(extraction_success_rate, 2),
            "keywords_with_data": keywords_with_data,
            "keywords_missing_data": keywords_missing_data,
            
            # 6. ê¸°íƒ€
            "pdf_filename": pdf_filename,
            "pdf_pages": pdf_pages,
        }
        
        result = supabase_client.table("data_quality_logs").insert(log_data).execute()
        
        if result.data and len(result.data) > 0:
            log_id = result.data[0]['id']
            print(f"âœ… ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {log_id}")
            return log_id
        
        return None
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return None

def generate_quality_log_txt(log_data):
    """ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ë¥¼ AI ë¶„ì„ìš© TXT íŒŒì¼ë¡œ ë³€í™˜"""
    
    # ê¸°ë³¸ ì •ë³´
    company = log_data.get('company_name', 'Unknown')
    user = log_data.get('user_name', 'N/A')
    created_at = log_data.get('created_at', 'N/A')[:19].replace('T', ' ')
    pdf_filename = log_data.get('pdf_filename', 'N/A')
    pdf_pages = log_data.get('pdf_pages', 0)
    
    # í’ˆì§ˆ ë©”íŠ¸ë¦­
    success_rate = log_data.get('extraction_success_rate', 0)
    keywords_success = log_data.get('keywords_with_data', 0)
    keywords_failed = log_data.get('keywords_missing_data', 0)
    ocr_tables = log_data.get('ocr_tables_count', 0)
    ocr_charts = log_data.get('ocr_charts_count', 0)
    
    # í‚¤ì›Œë“œ, OCR, LLM ë°ì´í„°
    keywords = log_data.get('selected_keywords', [])
    ocr_raw = log_data.get('ocr_raw_text', '')
    structured_data = log_data.get('ocr_structured_data', {})
    extracted = log_data.get('llm_extracted_data', {})
    report = log_data.get('report_content', '')
    
    # TXT íŒŒì¼ ìƒì„±
    txt = []
    txt.append("=" * 80)
    txt.append("ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¡œê·¸ - AI ë¶„ì„ìš©")
    txt.append("=" * 80)
    txt.append("")
    txt.append("[ê¸°ë³¸ ì •ë³´]")
    txt.append(f"- íšŒì‚¬ëª…: {company}")
    txt.append(f"- ì‚¬ìš©ì: {user}")
    txt.append(f"- ì‘ì„±ì¼: {created_at}")
    txt.append(f"- PDF íŒŒì¼: {pdf_filename}")
    txt.append(f"- PDF í˜ì´ì§€: {pdf_pages}í˜ì´ì§€")
    txt.append("")
    txt.append("[í’ˆì§ˆ ë©”íŠ¸ë¦­]")
    txt.append(f"- ì¶”ì¶œ ì„±ê³µë¥ : {success_rate}%")
    txt.append(f"- ì„±ê³µ: {keywords_success}ê°œ")
    txt.append(f"- ì‹¤íŒ¨: {keywords_failed}ê°œ")
    txt.append(f"- OCR í‘œ ì¸ì‹: {ocr_tables}ê°œ")
    txt.append(f"- OCR ì°¨íŠ¸/ê·¸ë˜í”„ ì¸ì‹: {ocr_charts}ê°œ")
    txt.append("")
    
    # 1. ì„ íƒëœ í‚¤ì›Œë“œ
    txt.append("=" * 80)
    txt.append("1. ì„ íƒëœ ì¶”ì¶œ í‚¤ì›Œë“œ")
    txt.append("=" * 80)
    txt.append("")
    if keywords:
        for idx, kw in enumerate(keywords, 1):
            txt.append(f"{idx}. {kw}")
        txt.append("")
        txt.append(f"(ì´ {len(keywords)}ê°œ í‚¤ì›Œë“œ)")
    else:
        txt.append("í‚¤ì›Œë“œ ì •ë³´ ì—†ìŒ")
    txt.append("")
    txt.append("")
    
    # 2. OCR ì›ë³¸ ë°ì´í„°
    txt.append("=" * 80)
    txt.append("2. OCR ì›ë³¸ ë°ì´í„° (Upstage Parse)")
    txt.append("=" * 80)
    txt.append("")
    
    # í‘œ ë°ì´í„°
    if structured_data and structured_data.get('tables'):
        txt.append(f"[í‘œ ë°ì´í„° - ì´ {len(structured_data['tables'])}ê°œ]")
        txt.append("")
        for idx, table in enumerate(structured_data['tables'], 1):  # ëª¨ë“  í‘œ í‘œì‹œ
            txt.append(f"--- í‘œ {idx} (í˜ì´ì§€ {table.get('page', '?')}) ---")
            table_content = table.get('content', 'ë‚´ìš© ì—†ìŒ')
            txt.append(table_content[:1000])  # ê° í‘œë‹¹ 1000ìë¡œ ì¦ê°€ (ì¬ë¬´í‘œ ì „ì²´ í¬í•¨)
            if len(table_content) > 1000:
                txt.append("... (ìƒëµ)")
            txt.append("")
    else:
        txt.append("[í‘œ ë°ì´í„° ì—†ìŒ]")
        txt.append("")
    
    # ì›ë³¸ í…ìŠ¤íŠ¸
    txt.append("[ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸]")
    txt.append("")
    if ocr_raw:
        txt.append(ocr_raw[:5000])  # ì²˜ìŒ 5000ìë¡œ ì¦ê°€ (ì¬ë¬´í‘œ ì „ì²´ í¬í•¨)
        if len(ocr_raw) > 5000:
            txt.append("")
            txt.append("... (ì´í•˜ ìƒëµ)")
    else:
        txt.append("ì›ë³¸ í…ìŠ¤íŠ¸ ì—†ìŒ")
    txt.append("")
    txt.append("")
    
    # 3. LLM ì¶”ì¶œ ë°ì´í„°
    txt.append("=" * 80)
    txt.append("3. LLM ì¶”ì¶œ ë°ì´í„°")
    txt.append("=" * 80)
    txt.append("")
    
    if extracted:
        # ì„±ê³µ/ì‹¤íŒ¨ êµ¬ë¶„
        success_data = {k: v for k, v in extracted.items() if v and v != "ì •ë³´ ì—†ìŒ"}
        failed_data = {k: v for k, v in extracted.items() if not v or v == "ì •ë³´ ì—†ìŒ"}
        
        txt.append(f"[âœ… ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œëœ ë°ì´í„° - {len(success_data)}ê°œ]")
        txt.append("")
        if success_data:
            for idx, (key, value) in enumerate(success_data.items(), 1):
                txt.append(f"{idx}. {key}")
                txt.append(f"   â†’ {value}")
                txt.append("")
        else:
            txt.append("ì—†ìŒ")
            txt.append("")
        
        txt.append("")
        txt.append(f"[âŒ ì¶”ì¶œ ì‹¤íŒ¨ ë°ì´í„° - {len(failed_data)}ê°œ]")
        txt.append("")
        if failed_data:
            for idx, key in enumerate(failed_data.keys(), 1):
                txt.append(f"{idx}. {key}")
                txt.append(f"   â†’ ì •ë³´ ì—†ìŒ")
                txt.append("")
        else:
            txt.append("ì—†ìŒ")
            txt.append("")
    else:
        txt.append("LLM ì¶”ì¶œ ë°ì´í„° ì—†ìŒ")
        txt.append("")
    
    txt.append("")
    txt.append(f"[LLM ì²˜ë¦¬ ì •ë³´]")
    txt.append(f"- ëª¨ë¸: {log_data.get('llm_model', 'N/A')}")
    txt.append(f"- ì²˜ë¦¬ ì‹œê°„: {log_data.get('llm_extraction_time_ms', 0)}ms")
    txt.append("")
    txt.append("")
    
    # 4. ë³´ê³ ì„œ (ì„ íƒ)
    if log_data.get('report_generated') and report:
        txt.append("=" * 80)
        txt.append("4. ë³´ê³ ì„œ ìƒì„± ê²°ê³¼ (ì„ íƒ)")
        txt.append("=" * 80)
        txt.append("")
        txt.append(report[:2000])  # ì²˜ìŒ 2000ì
        if len(report) > 2000:
            txt.append("")
            txt.append("... (ì´í•˜ ìƒëµ)")
        txt.append("")
        txt.append("")
        txt.append(f"[ë³´ê³ ì„œ ìƒì„± ì •ë³´]")
        txt.append(f"- ëª¨ë¸: {log_data.get('report_model', 'N/A')}")
        txt.append(f"- ìƒì„± ì‹œê°„: {log_data.get('report_generation_time_ms', 0)}ms")
        txt.append(f"- ì „ì²´ ê¸¸ì´: {len(report)}ì")
        txt.append("")
        txt.append("")
    
    # AI ë¶„ì„ì„ ìœ„í•œ ì§ˆë¬¸
    txt.append("=" * 80)
    txt.append("AI ë¶„ì„ì„ ìœ„í•œ ì§ˆë¬¸")
    txt.append("=" * 80)
    txt.append("")
    txt.append("ì´ ë¡œê·¸ë¥¼ AIì—ê²Œ ì²¨ë¶€í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ìš”ì²­í•˜ì„¸ìš”:")
    txt.append("")
    txt.append("1. OCR ì›ë³¸ ë°ì´í„°ì—ëŠ” ìˆëŠ”ë° LLMì´ ì¶”ì¶œí•˜ì§€ ëª»í•œ ì •ë³´ê°€ ìˆë‚˜ìš”?")
    txt.append("   â†’ ì–´ë–¤ í‚¤ì›Œë“œê°€ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.")
    txt.append("")
    txt.append("2. LLMì´ ì˜ëª» ì¶”ì¶œí•œ ê°’ì´ ìˆë‚˜ìš”?")
    txt.append("   â†’ OCR ì›ë³¸ê³¼ ë¹„êµí•˜ì—¬ ì˜ëª»ëœ ë¶€ë¶„ì„ ì§€ì í•´ì£¼ì„¸ìš”.")
    txt.append("   (ì˜ˆ: ì˜ì—…ì´ìµê³¼ ì˜ì—…ì´ìµë¥  í˜¼ë™, ë‹¨ìœ„ ì˜¤ë¥˜ ë“±)")
    txt.append("")
    txt.append("3. ì¶”ì¶œ ì‹¤íŒ¨ ë°ì´í„°ì— ëŒ€í•´:")
    txt.append("   â†’ OCR ì›ë³¸ì— í•´ë‹¹ ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    txt.append("   â†’ ìˆë‹¤ë©´ ì™œ LLMì´ ì°¾ì§€ ëª»í–ˆëŠ”ì§€ ë¶„ì„í•´ì£¼ì„¸ìš”.")
    txt.append("")
    txt.append("4. í”„ë¡¬í”„íŠ¸ë¥¼ ì–´ë–»ê²Œ ê°œì„ í•˜ë©´ ì¶”ì¶œ ì„±ê³µë¥ ì„ ë†’ì¼ ìˆ˜ ìˆë‚˜ìš”?")
    txt.append("   â†’ êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ ê°œì„ ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”.")
    txt.append("")
    txt.append("5. OCR ë‹¨ê³„ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‚˜ìš”?")
    txt.append("   â†’ í‘œ ì¸ì‹, í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆ ë“±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.")
    txt.append("")
    txt.append("")
    txt.append("=" * 80)
    txt.append("ë¶„ì„ ì™„ë£Œ í›„ ê°œì„  ë°©í–¥")
    txt.append("=" * 80)
    txt.append("")
    txt.append("AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ:")
    txt.append("1. streamlit_app.pyì˜ extract_all_keywords_batch() í•¨ìˆ˜ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •")
    txt.append("2. OCR ì„¤ì • ì¡°ì • (í‘œ êµ¬ì¡° ì¸ì‹ ëª¨ë“œ ë“±)")
    txt.append("3. í‚¤ì›Œë“œ ì •ì˜ ê°œì„  (ë” ëª…í™•í•œ í‚¤ì›Œë“œëª… ì‚¬ìš©)")
    txt.append("4. ì¬í…ŒìŠ¤íŠ¸ ë° ì„±ê³µë¥  ë¹„êµ")
    txt.append("")
    txt.append("=" * 80)
    txt.append("íŒŒì¼ ë")
    txt.append("=" * 80)
    
    return "\n".join(txt)

# ë³´ê³ ì„œ ì„¹ì…˜ë³„ ì‘ì„± ì§€ì¹¨ ì •ì˜
REPORT_SECTION_TEMPLATES = {
    "ê¸°ì—… ê°œìš”": """1. **ê¸°ì—… ê°œìš”**
   - íšŒì‚¬ëª…, ì—…ì¢…, ì£¼ìš” ì‚¬ì—… ë‚´ìš©
   - ë§¤ì¶œ/ì˜ì—…ì´ìµ ë“± ê¸°ë³¸ ì •ë³´
   - ì„¤ë¦½ ë°°ê²½ ë° ì£¼ìš” ì—°í˜
   - ì¡°ì§ êµ¬ì¡° ìš”ì•½(ì„ íƒ)
   - ì¶”ì¶œëœ ë°ì´í„°ë§Œ ì‚¬ìš©""",
    
    "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„": """2. **ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„**
   - ì£¼ìš” ì‚¬ì—…ë¶€ êµ¬ì¡° ë° ë§¤ì¶œ ë¹„ì¤‘
   - ì œí’ˆ/ì„œë¹„ìŠ¤ë³„ ìˆ˜ìµ ëª¨ë¸
   - ê³ ê° ëŒ€ìƒêµ°(B2B/B2C), ì§€ì—­ë³„ ë§¤ì¶œ êµ¬ì¡°
   - ì£¼ìš” ì›ê°€/ë§ˆì§„ êµ¬ì¡°
   - ì—¬ì‹  ì‹¬ì‚¬ì— í•„ìš”í•œ í•µì‹¬ í•­ëª©
   - ì¶”ì¶œëœ ë°ì´í„° ê¸°ë°˜, ì—†ìœ¼ë©´ ì—…ì¢… íŠ¹ì„± ë°˜ì˜
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ìµœì‹  ì •ë³´ë‚˜ ê²½ìŸì‚¬ ë¹„êµê°€ í•„ìš”í•˜ë©´ ê´€ë ¨ PDFë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„": """3. **ì‚°ì—… ë° ì‹œì¥ ë¶„ì„**
   - ì‚°ì—… ê·œëª¨, ì„±ì¥ì„±, ì‹œì¥ ë™í–¥
   - ê²½ìŸ êµ¬ë„ ë° íŠ¸ë Œë“œ
   - í•´ë‹¹ ê¸°ì—…ì´ ì†í•œ ì‹œì¥ì˜ ìœ„í—˜ ìš”ì¸
   - PDFì— ì •ë³´ ì—†ìœ¼ë©´ ì—…ì¢… ê¸°ì¤€ ì¼ë°˜ ë¶„ì„
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ìµœì‹  ì‚°ì—… ë¦¬í¬íŠ¸ë‚˜ ì‹œì¥ ë¶„ì„ ìë£Œë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ì¬ë¬´ ìš”ì•½": """4. **ì¬ë¬´ ìš”ì•½**
   - ë§¤ì¶œ, ì˜ì—…ì´ìµ, ì„±ì¥ë¥  ë¶„ì„
   - ì¶”ì¶œëœ í•µì‹¬ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜
   - ìˆ˜ìµì„±Â·ì„±ì¥ì„± ì§€í‘œ
   - ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ , ìˆ˜ìµì„± ì§€í‘œ í¬í•¨""",
    
    "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„": """5. **ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„**
   - ë¶€ì±„ êµ¬ì¡°(ë‹¨ê¸°/ì¥ê¸°)
   - ì´ìë³´ìƒë°°ìœ¨, ì°¨ì… ì˜ì¡´ë„
   - ì˜ì—…í˜„ê¸ˆíë¦„ ì•ˆì •ì„±
   - ìˆœìš´ì „ìë³¸(NWC) ë¶„ì„
   - ëŒ€ì¶œ ìƒí™˜ëŠ¥ë ¥ í‰ê°€ í•µì‹¬ ì§€í‘œ
   - ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜""",
    
    "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„": """6. **ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„**
   - ì£¼ìš” ê³ ê°ì‚¬ TOP5
   - ë‹¨ì¼ ê±°ë˜ì²˜ ì˜ì¡´ë„
   - ë§¤ì¶œ ë‹¤ë³€í™” ìˆ˜ì¤€
   - ê±°ë˜ì²˜ ë³€ê²½ ê°€ëŠ¥ì„±
   - ìºí”¼íƒˆ ë¦¬ìŠ¤í¬ ì‹¬ì‚¬ì—ì„œ ë§¤ìš° ì¤‘ìš”
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¸ê¸‰""",
    
    "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„": """7. **ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„**
   - ì—…ì¢… ë‚´ ì£¼ìš” ê²½ìŸì‚¬ ë¹„êµ
   - ê²½ìŸ ìš°ìœ„Â·ì—´ìœ„ ë¶„ì„
   - ì‹œì¥ ì ìœ ìœ¨ ì¶”ì •
   - ë°ì´í„° ì—†ìœ¼ë©´ ì—…ì¢… ê¸°ë°˜ ì¼ë°˜ ë¹„êµ
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ê²½ìŸì‚¬ ì‚¬ì—…ë³´ê³ ì„œë‚˜ IR ìë£Œë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¹„êµ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„": """8. **ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„**
   - CEO ë° í•µì‹¬ ì„ì› ê²½ë ¥
   - ì§€ë¶„ êµ¬ì¡°, ì˜¤ë„ˆ ë¦¬ìŠ¤í¬
   - ì§€ë°°êµ¬ì¡° íˆ¬ëª…ì„±
   - ê²½ì˜ì§„ êµì²´ ì´ë ¥
   - íŠ¹íˆ ì¤‘ì†Œê¸°ì—… ì‹¬ì‚¬ì— ë§¤ìš° ì¤‘ìš”
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¸ê¸‰ ì•ˆ í•¨""",
    
    "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬": """9. **ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬**
   - ì‹ ìš©ë“±ê¸‰(ìˆìœ¼ë©´)
   - ê°ì‚¬ ì˜ê²¬(ì ì •/í•œì • ë“±)
   - ìµœê·¼ ì†Œì†¡Â·ë¶„ìŸÂ·ì œì¬ ì—¬ë¶€
   - ê³µì •ìœ„/ê¸ˆìœµìœ„ ì œì¬ ì—¬ë¶€
   - ê¸°ë³¸ ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ êµ¬ë¶„ë˜ëŠ” ì •ëŸ‰ì  ë¦¬ìŠ¤í¬
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*""",
    
    "ë¦¬ìŠ¤í¬ ìš”ì¸": """10. **ë¦¬ìŠ¤í¬ ìš”ì¸**
   - ì‚°ì—… ë¦¬ìŠ¤í¬
   - ìš´ì˜ ë¦¬ìŠ¤í¬
   - ì¬ë¬´ì  ì¼ë°˜ ë¦¬ìŠ¤í¬
   - PDFì— ë¦¬ìŠ¤í¬ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
   - ì—†ìœ¼ë©´ í•´ë‹¹ ì‚°ì—…ì˜ ì¼ë°˜ì  ë¦¬ìŠ¤í¬ ì„¤ëª…
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*""",
    
    "ì¢…í•© í‰ê°€": """11. **ì¢…í•© í‰ê°€ (íˆ¬ì/ëŒ€ì¶œ ê´€ì )**
   - ì¬ë¬´ ì•ˆì •ì„± í‰ê°€
   - ìƒí™˜ ëŠ¥ë ¥ í‰ê°€
   - ì„±ì¥ ê°€ëŠ¥ì„± ìš”ì•½
   - ì¢…í•© ì˜ê²¬ ë° ê¶Œì¥ ì¡°ì¹˜
   - ëŒ€ì¶œ ìŠ¹ì¸/ì¡°ê±´/ìœ ì˜ì‚¬í•­ ì œì‹œ ê°€ëŠ¥
   - ì¶”ì¶œëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì  íŒë‹¨"""
}

# Supabase í—¬í¼ í•¨ìˆ˜
def save_to_supabase(company_name, pdf_file, extracted_text, extracted_data, report_content=None, create_embeddings_flag=True):
    """Supabaseì— ë°ì´í„° ë° ì„ë² ë”© ì €ì¥"""
    if not supabase_client:
        st.warning("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # 1. ê¸°ì—… ì •ë³´ ì €ì¥
        company_data = {
            "company_name": company_name,
            "industry": extracted_data.get("ì—…ì¢…") or extracted_data.get("ì‚°ì—…ë¶„ë¥˜") or "ë¯¸ë¶„ë¥˜"
        }
        company_response = supabase_client.table("companies").insert(company_data).execute()
        company_id = company_response.data[0]["id"]
        st.info(f"âœ… ê¸°ì—… ì •ë³´ ì €ì¥ ì™„ë£Œ (ID: {company_id})")
        
        # 2. PDF íŒŒì¼ì„ Storageì— ì €ì¥ (ì„ íƒì‚¬í•­ - ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´ì‹œ)
        try:
            file_path = f"{company_id}/main.pdf"
            pdf_file.seek(0)
            pdf_bytes = pdf_file.read()
            supabase_client.storage.from_("company-pdfs").upload(
                file_path,
                pdf_bytes,
                {"content-type": "application/pdf"}
            )
            file_size = len(pdf_bytes)
            st.info("âœ… PDF íŒŒì¼ Storage ì €ì¥ ì™„ë£Œ")
        except Exception as storage_error:
            st.warning(f"âš ï¸ PDF Storage ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {storage_error}")
            file_path = "not_stored"
            file_size = 0
        
        # 3. PDF íŒŒì¼ ì •ë³´ ì €ì¥
        pdf_data = {
            "company_id": company_id,
            "file_name": getattr(pdf_file, 'name', 'unknown.pdf'),
            "file_type": "main",
            "storage_path": file_path,
            "file_size": file_size,
            "extracted_text": extracted_text[:50000],  # í…ìŠ¤íŠ¸ í¬ê¸° ì œí•œ
            "pages_count": extracted_text.count("=== í˜ì´ì§€")
        }
        supabase_client.table("pdf_files").insert(pdf_data).execute()
        st.info("âœ… PDF ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
        # 4. ì¶”ì¶œëœ ë°ì´í„° ì €ì¥
        data_entries = []
        for field_name, field_value in extracted_data.items():
            data_entries.append({
                "company_id": company_id,
                "field_name": field_name,
                "field_value": str(field_value)[:5000]  # ê¸¸ì´ ì œí•œ
            })
        
        if data_entries:
            supabase_client.table("extracted_data").insert(data_entries).execute()
            st.info(f"âœ… ì¶”ì¶œ ë°ì´í„° {len(data_entries)}ê°œ ì €ì¥ ì™„ë£Œ")
        
        # 5. ë³´ê³ ì„œ ì €ì¥ (ì„ íƒì‚¬í•­)
        if report_content:
            report_data = {
                "company_id": company_id,
                "report_content": report_content[:100000]  # í¬ê¸° ì œí•œ
            }
            supabase_client.table("reports").insert(report_data).execute()
            st.info("âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ")
        
        # 6. êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥ (Upstage Parse ê²°ê³¼)
        if st.session_state.get('structured_data'):
            try:
                import json
                structured_json = json.dumps(st.session_state.structured_data, ensure_ascii=False)
                
                # companies í…Œì´ë¸”ì— structured_data ì»¬ëŸ¼ ì¶”ê°€ í•„ìš”
                # ì¼ë‹¨ extracted_data í…Œì´ë¸”ì— íŠ¹ìˆ˜ í•„ë“œë¡œ ì €ì¥
                supabase_client.table("extracted_data").insert({
                    "company_id": company_id,
                    "field_name": "__structured_data__",
                    "field_value": structured_json[:50000]  # í¬ê¸° ì œí•œ
                }).execute()
                st.info("âœ… êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ (ì¬ì‚¬ìš© ê°€ëŠ¥)")
            except Exception as e:
                st.warning(f"âš ï¸ êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # 7. ì„ë² ë”© ìƒì„± ë° ì €ì¥ (RAG ì‹œìŠ¤í…œ)
        if create_embeddings_flag and openai_client:
            with st.spinner("ğŸ”® ì„ë² ë”© ë²¡í„° ìƒì„± ì¤‘..."):
                # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
                chunks = split_text_into_chunks(extracted_text, max_tokens=500, overlap_tokens=50)
                st.info(f"ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
                
                # ì„ë² ë”© ìƒì„±
                embeddings = create_embeddings(chunks)
                
                if embeddings:
                    # Supabaseì— ì €ì¥
                    save_embeddings_to_supabase(company_id, embeddings, file_type="main")
                else:
                    st.warning("âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ì€ ì œí•œë©ë‹ˆë‹¤")
        
        return company_id
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"âŒ Supabase ì €ì¥ ì‹¤íŒ¨")
        st.error(f"ì—ëŸ¬: {str(e)}")
        with st.expander("ìƒì„¸ ì—ëŸ¬ ë¡œê·¸"):
            st.code(error_detail)
        return None

def load_companies_list():
    """ì €ì¥ëœ ê¸°ì—… ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not supabase_client:
        return []
    
    try:
        response = supabase_client.table("companies").select("*").order("created_at", desc=True).limit(50).execute()
        return response.data
    except Exception as e:
        st.error(f"ê¸°ì—… ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def load_company_data(company_id):
    """íŠ¹ì • ê¸°ì—…ì˜ ì¶”ì¶œëœ ë°ì´í„° ë° êµ¬ì¡°í™”ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not supabase_client:
        return {}, None
    
    try:
        response = supabase_client.table("extracted_data").select("*").eq("company_id", company_id).execute()
        
        extracted_data = {}
        structured_data = None
        
        for item in response.data:
            field_name = item["field_name"]
            field_value = item["field_value"]
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„° ë³µì›
            if field_name == "__structured_data__":
                try:
                    import json
                    structured_data = json.loads(field_value)
                except:
                    pass
            else:
                extracted_data[field_name] = field_value
        
        return extracted_data, structured_data
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}, None

# ============================================
# ì„ë² ë”© ë° RAG ì‹œìŠ¤í…œ
# ============================================

def split_text_into_chunks(text, max_tokens=500, overlap_tokens=50):
    """í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸°ë°˜ìœ¼ë¡œ ì²­í¬ ë¶„í• """
    try:
        encoding = tiktoken.encoding_for_model("text-embedding-3-small")
        tokens = encoding.encode(text)
        
        chunks = []
        start = 0
        
        while start < len(tokens):
            end = start + max_tokens
            chunk_tokens = tokens[start:end]
            chunk_text = encoding.decode(chunk_tokens)
            
            chunks.append({
                "text": chunk_text,
                "start_pos": start,
                "end_pos": end,
                "token_count": len(chunk_tokens)
            })
            
            start += (max_tokens - overlap_tokens)
        
        return chunks
    except Exception as e:
        st.error(f"ì²­í¬ ë¶„í•  ì‹¤íŒ¨: {e}")
        # í´ë°±: ë‹¨ìˆœ ë¬¸ì ê¸°ë°˜ ë¶„í• 
        chunk_size = 2000
        overlap = 200
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk_text = text[start:end]
            chunks.append({
                "text": chunk_text,
                "start_pos": start,
                "end_pos": end,
                "token_count": len(chunk_text) // 4  # ëŒ€ëµì  ì¶”ì •
            })
            start += (chunk_size - overlap)
        return chunks

def create_embeddings(text_chunks):
    """OpenAI APIë¡œ ì„ë² ë”© ë²¡í„° ìƒì„±"""
    if not openai_client:
        st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    embeddings = []
    try:
        for i, chunk in enumerate(text_chunks):
            response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=chunk["text"]
            )
            embedding_vector = response.data[0].embedding
            
            embeddings.append({
                "chunk_index": i,
                "text": chunk["text"],
                "embedding": embedding_vector,
                "token_count": chunk["token_count"]
            })
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if (i + 1) % 10 == 0:
                st.info(f"ì„ë² ë”© ìƒì„± ì¤‘... {i + 1}/{len(text_chunks)}")
        
        return embeddings
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return []

def save_embeddings_to_supabase(company_id, embeddings, file_type="main"):
    """Supabaseì— ì„ë² ë”© ë²¡í„° ì €ì¥"""
    if not supabase_client:
        st.warning("Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ë²¡í„° ë°ì´í„° ì¤€ë¹„
        vector_entries = []
        for emb in embeddings:
            # í…ìŠ¤íŠ¸ë¥¼ UTF-8ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì¸ì½”ë”©/ë””ì½”ë”©í•˜ì—¬ í•œê¸€ ê¹¨ì§ ë°©ì§€
            chunk_text = emb["text"][:5000]
            # ì´ë¯¸ ë¬¸ìì—´ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (Python 3ëŠ” ê¸°ë³¸ UTF-8)
            
            vector_entries.append({
                "company_id": company_id,
                "file_type": file_type,
                "chunk_index": emb["chunk_index"],
                "chunk_text": chunk_text,  # UTF-8 í…ìŠ¤íŠ¸
                "embedding": emb["embedding"],
                "token_count": emb["token_count"]
            })
        
        # ë°°ì¹˜ë¡œ ì €ì¥ (í•œ ë²ˆì— ë„ˆë¬´ ë§ìœ¼ë©´ ë¶„í• )
        batch_size = 100
        for i in range(0, len(vector_entries), batch_size):
            batch = vector_entries[i:i + batch_size]
            supabase_client.table("document_embeddings").insert(batch).execute()
            st.info(f"ë²¡í„° ì €ì¥ ì¤‘... {min(i + batch_size, len(vector_entries))}/{len(vector_entries)}")
        
        st.success(f"âœ… {len(vector_entries)}ê°œ ì„ë² ë”© ë²¡í„° ì €ì¥ ì™„ë£Œ!")
        return True
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        with st.expander("ìƒì„¸ ì—ëŸ¬ ë¡œê·¸"):
            st.code(error_detail)
        return False

def semantic_search(query, company_id=None, top_k=5, file_type=None):
    """ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê²€ìƒ‰"""
    if not supabase_client or not openai_client:
        st.warning("Supabase ë˜ëŠ” OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        response = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=query
        )
        query_embedding = response.data[0].embedding
        
        # Supabaseì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (RPC í•¨ìˆ˜ ì‚¬ìš©)
        rpc_params = {
            "query_embedding": query_embedding,
            "match_threshold": 0.5,
            "match_count": top_k
        }
        
        # íšŒì‚¬ ID í•„í„°
        if company_id:
            rpc_params["filter_company_id"] = company_id
        
        # íŒŒì¼ íƒ€ì… í•„í„°
        if file_type:
            rpc_params["filter_file_type"] = file_type
        
        # RPC í˜¸ì¶œ
        result = supabase_client.rpc(
            "match_documents",
            rpc_params
        ).execute()
        
        return result.data
    except Exception as e:
        st.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def retrieve_relevant_context(query, company_id=None, max_tokens=3000):
    """RAG: ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    search_results = semantic_search(query, company_id=company_id, top_k=10)
    
    if not search_results:
        return "ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # í† í° ì œí•œ ë‚´ì—ì„œ ê´€ë ¨ í…ìŠ¤íŠ¸ ì¡°í•©
    context_parts = []
    total_tokens = 0
    
    for result in search_results:
        chunk_text = result.get("chunk_text", "")
        similarity = result.get("similarity", 0)
        token_count = result.get("token_count", 0)
        
        if total_tokens + token_count > max_tokens:
            break
        
        context_parts.append(f"[ìœ ì‚¬ë„: {similarity:.3f}]\n{chunk_text}")
        total_tokens += token_count
    
    return "\n\n---\n\n".join(context_parts)

# ============================================
# Upstage Document Parse API ì—°ë™
# ============================================
import requests

# Upstage API URL (ìµœì‹  Document Digitization API)
UPSTAGE_API_URL = "https://api.upstage.ai/v1/document-digitization"

def check_upstage_available():
    """Upstage API í‚¤ ì„¤ì • í™•ì¸"""
    return bool(UPSTAGE_API_KEY and UPSTAGE_API_KEY != "your-upstage-api-key-here")

# OCR Reader (lazy loading) - ë¡œì»¬ í´ë°±ìš©
_ocr_reader = None

def get_ocr_reader():
    """OCR Readerë¥¼ lazy loadingìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸° (ë¡œì»¬ í´ë°±)"""
    global _ocr_reader
    if _ocr_reader is None:
        import easyocr
        _ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False)
    return _ocr_reader

def extract_text_from_pdf(pdf_file, max_pages=50, use_ocr=False):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        pdf_file.seek(0)
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        num_pages = min(len(doc), max_pages)
        
        text = ""
        for page_num in range(num_pages):
            page = doc[page_num]
            page_text = page.get_text()
            text += f"\n\n=== í˜ì´ì§€ {page_num+1} ===\n\n{page_text}"
        
        # í…ìŠ¤íŠ¸ê°€ ì¶©ë¶„í•˜ê³  OCR ìš”ì²­ ì•ˆ í–ˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if len(text.strip()) > 100 and not use_ocr:
            doc.close()
            return text, num_pages
        
        # OCR ì‚¬ìš©
        if use_ocr or len(text.strip()) < 100:
            if len(text.strip()) < 100:
                st.warning("í…ìŠ¤íŠ¸ ì¶”ì¶œëŸ‰ì´ ì ì–´ ê³ ê¸‰ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            else:
                st.info("ğŸ” í‘œ êµ¬ì¡° ì¸ì‹ ëª¨ë“œë¡œ ì¬ì¶”ì¶œí•©ë‹ˆë‹¤...")
            
            # Upstage API ì‹œë„
            if check_upstage_available():
                st.info("â˜ï¸ Upstage Document Parse ì‚¬ìš© (í‘œ êµ¬ì¡°í™” + OCR)")
                doc.close()
                pdf_file.seek(0)
                return extract_text_with_upstage(pdf_file, max_pages)
            else:
                # ë¡œì»¬ OCR í´ë°± (Upstage ì—†ì„ ë•Œë§Œ)
                st.warning("âš ï¸ Upstage API ë¯¸ì„¤ì •, ê¸°ë³¸ OCR ì‚¬ìš©")
                doc.close()
                pdf_file.seek(0)
                return extract_text_with_easyocr(pdf_file, max_pages)
        
        doc.close()
        return text, num_pages
        
    except Exception as e:
        st.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {e}")
        return "", 0

def extract_text_with_upstage(pdf_file, max_pages=50):
    """Upstage Document Parse APIë¡œ PDF ì „ì²´ ë¶„ì„ (í‘œ êµ¬ì¡°í™”!)"""
    if not UPSTAGE_API_KEY:
        st.error("Upstage API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "", 0
    
    try:
        pdf_file.seek(0)
        pdf_bytes = pdf_file.read()
        
        st.info("ğŸš€ Upstage Document Parseë¡œ PDF ë¶„ì„ ì¤‘... (í‘œ êµ¬ì¡° ì¸ì‹)")
        
        # Upstage API í˜¸ì¶œ
        headers = {
            "Authorization": f"Bearer {UPSTAGE_API_KEY}"
        }
        
        files = {
            "document": (getattr(pdf_file, 'name', 'document.pdf'), pdf_bytes, "application/pdf")
        }
        
        # Upstage Document Parse API íŒŒë¼ë¯¸í„° (í‘œ + ì°¨íŠ¸ ì¸ì‹)
        data = {
            "ocr": "force",  # Always apply OCR
            "model": "document-parse",  # ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ ì§€ì •
            "output_formats": "['text', 'html', 'markdown']",  # JSON ë°°ì—´ì„ ë¬¸ìì—´ë¡œ
            "coordinates": "true",  # ì¢Œí‘œ ì •ë³´ í¬í•¨
            "base64_encoding": "['table', 'figure']",  # í‘œì™€ ì°¨íŠ¸/ê·¸ë˜í”„ ëª¨ë‘ ì¸ì½”ë”©
        }
        
        response = requests.post(
            UPSTAGE_API_URL,
            headers=headers,
            files=files,
            data=data,
            timeout=120  # PDF ë¶„ì„ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ
        )
        
        if response.status_code != 200:
            st.error(f"âŒ Upstage API ì˜¤ë¥˜: {response.status_code}")
            st.error(f"ìƒì„¸: {response.text}")
            return "", 0
        
        result = response.json()
        
        # ë””ë²„ê·¸: ì‘ë‹µ êµ¬ì¡° í™•ì¸
        with st.expander("ğŸ” ë””ë²„ê·¸: Upstage API ì‘ë‹µ êµ¬ì¡°"):
            st.write("**ì‘ë‹µ í‚¤:**", list(result.keys()))
            if "content" in result:
                st.write("**Content í‚¤:**", list(result["content"].keys()))
            if "pages" in result:
                st.write(f"**í˜ì´ì§€ ìˆ˜:** {len(result['pages'])}")
                if result['pages']:
                    first_page = result['pages'][0]
                    st.write("**ì²« í˜ì´ì§€ í‚¤:**", list(first_page.keys()))
                    if "elements" in first_page:
                        st.write(f"**ì²« í˜ì´ì§€ ìš”ì†Œ ìˆ˜:** {len(first_page['elements'])}")
                        if first_page['elements']:
                            st.write("**ì²« ìš”ì†Œ ì˜ˆì‹œ:**", first_page['elements'][0])
        
        # êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        content = result.get("content", {})
        text = content.get("text", "")
        html = content.get("html", "")
        markdown = content.get("markdown", "")  # ë§ˆí¬ë‹¤ìš´ë„ ì¶”ì¶œ
        
        # API v2.0 ì‘ë‹µ êµ¬ì¡°: elements ë°°ì—´ì—ì„œ ì§ì ‘ ì¶”ì¶œ
        elements_list = result.get("elements", [])
        
        # êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ (í‘œ, ì°¨íŠ¸, ì œëª©, ë¦¬ìŠ¤íŠ¸ ë“±)
        structured_elements = {
            "tables": [],
            "charts": [],  # ì°¨íŠ¸/ê·¸ë˜í”„ ì¶”ê°€
            "headings": [],
            "paragraphs": [],
            "lists": []
        }
        
        # elements ë°°ì—´ì—ì„œ ì§ì ‘ ì¶”ì¶œ (v2.0 API)
        for element in elements_list:
            elem_category = element.get("category", "")
            elem_content = element.get("content", {})
            elem_page = element.get("page", 0)
            
            # contentëŠ” dict í˜•íƒœ {html, markdown, text}
            elem_html = elem_content.get("html", "") if isinstance(elem_content, dict) else ""
            elem_text = elem_content.get("text", "") if isinstance(elem_content, dict) else str(elem_content)
            elem_markdown = elem_content.get("markdown", "") if isinstance(elem_content, dict) else ""
            
            if "table" in elem_category.lower():
                structured_elements["tables"].append({
                    "page": elem_page,
                    "content": elem_text or elem_html or elem_markdown,
                    "html": elem_html,
                    "markdown": elem_markdown
                })
            elif "figure" in elem_category.lower() or "chart" in elem_category.lower() or "image" in elem_category.lower():
                structured_elements["charts"].append({
                    "page": elem_page,
                    "content": elem_text or elem_html or elem_markdown,
                    "html": elem_html,
                    "markdown": elem_markdown,
                    "category": elem_category
                })
            elif "heading" in elem_category.lower() or "title" in elem_category.lower():
                structured_elements["headings"].append({
                    "page": elem_page,
                    "content": elem_text or elem_html
                })
            elif "list" in elem_category.lower():
                structured_elements["lists"].append({
                    "page": elem_page,
                    "content": elem_text or elem_html
                })
            elif "paragraph" in elem_category.lower():
                structured_elements["paragraphs"].append({
                    "page": elem_page,
                    "content": elem_text or elem_html
                })
        
        # í˜ì´ì§€ë³„ ì •ë³´ (í˜¸í™˜ì„± ìœ ì§€)
        pages = result.get("pages", [])
        if not pages and elements_list:
            # pagesê°€ ì—†ìœ¼ë©´ elementsë¡œë¶€í„° ìƒì„±
            num_pages = max([e.get("page", 1) for e in elements_list] + [1])
        else:
            num_pages = len(pages)
        
        # í‘œ ë° ì°¨íŠ¸ ì •ë³´ ì¶”ì¶œ
        table_count = len(structured_elements["tables"])
        chart_count = len(structured_elements["charts"])
        
        st.success(f"âœ… Upstage ë¶„ì„ ì™„ë£Œ: {num_pages}í˜ì´ì§€, {len(text)}ì, **í‘œ {table_count}ê°œ, ì°¨íŠ¸ {chart_count}ê°œ** ì¸ì‹")
        
        # í‘œê°€ ì¸ì‹ë˜ì—ˆì„ ë•Œ ìƒì„¸ ì •ë³´ í‘œì‹œ
        if table_count > 0:
            with st.expander(f"ğŸ“Š ì¸ì‹ëœ í‘œ ì •ë³´ ({table_count}ê°œ)"):
                for idx, table in enumerate(structured_elements["tables"][:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    st.write(f"**í‘œ {idx} (í˜ì´ì§€ {table.get('page', '?')})**")
                    table_content = table.get('html', '') or table.get('content', '')
                    if table_content:
                        st.text(table_content[:300] + ("..." if len(table_content) > 300 else ""))
                    st.markdown("---")
        
        # ì°¨íŠ¸ê°€ ì¸ì‹ë˜ì—ˆì„ ë•Œ ìƒì„¸ ì •ë³´ í‘œì‹œ
        if chart_count > 0:
            with st.expander(f"ğŸ“ˆ ì¸ì‹ëœ ì°¨íŠ¸/ê·¸ë˜í”„ ì •ë³´ ({chart_count}ê°œ)"):
                for idx, chart in enumerate(structured_elements["charts"][:3], 1):  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                    st.write(f"**ì°¨íŠ¸ {idx} (í˜ì´ì§€ {chart.get('page', '?')}) - {chart.get('category', 'unknown')}**")
                    chart_content = chart.get('content', '') or chart.get('html', '')
                    if chart_content:
                        st.text(chart_content[:300] + ("..." if len(chart_content) > 300 else ""))
                    st.markdown("---")
        
        # ë””ë²„ê·¸: í‘œ/ì°¨íŠ¸ ì¸ì‹ ì‹¤íŒ¨ ì‹œ ê²½ê³ 
        if table_count == 0 and chart_count == 0 and num_pages > 0:
            st.warning("âš ï¸ Upstageê°€ í‘œì™€ ì°¨íŠ¸ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.info("**ê°€ëŠ¥í•œ ì›ì¸:**\n- PDFê°€ ì´ë¯¸ì§€ ìŠ¤ìº”ë³¸ (OCR í’ˆì§ˆ ì €í•˜)\n- í‘œ/ì°¨íŠ¸ êµ¬ì¡°ê°€ ë³µì¡í•˜ê±°ë‚˜ ë¹„ì •í˜•\n- í…ìŠ¤íŠ¸ë¡œ ëœ í‘œ í˜•ì‹ ë°ì´í„°")
            st.info("ğŸ’¡ **í•´ê²° ë°©ë²•:** LLMì´ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ í‘œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ê°€ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            
            # ë””ë²„ê·¸ ì •ë³´
            with st.expander("ğŸ” ë””ë²„ê·¸: Upstage ì‘ë‹µ ë¶„ì„"):
                st.write("**API ì‘ë‹µ êµ¬ì¡°:**")
                st.write(f"- ì „ì²´ ìš”ì†Œ ìˆ˜: {len(elements_list)}ê°œ")
                st.write(f"- ì œëª©: {len(structured_elements['headings'])}ê°œ")
                st.write(f"- ë‹¨ë½: {len(structured_elements['paragraphs'])}ê°œ")
                st.write(f"- ë¦¬ìŠ¤íŠ¸: {len(structured_elements['lists'])}ê°œ")
                st.write(f"- í‘œ: {len(structured_elements['tables'])}ê°œ")
                st.write(f"- ì°¨íŠ¸: {len(structured_elements['charts'])}ê°œ")
                
                # elements ì¹´í…Œê³ ë¦¬ ë¶„í¬
                categories = {}
                for elem in elements_list[:50]:  # ìµœëŒ€ 50ê°œ
                    cat = elem.get("category", "unknown")
                    categories[cat] = categories.get(cat, 0) + 1
                
                if categories:
                    st.write("\n**ìš”ì†Œ ì¹´í…Œê³ ë¦¬ ë¶„í¬:**")
                    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                        st.write(f"  - {cat}: {count}ê°œ")
        
        # ì„¸ì…˜ì— êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
        st.session_state.structured_data = structured_elements
        
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì¡°í™” (elementsë¡œë¶€í„° ì¬êµ¬ì„±)
        structured_text = ""
        if elements_list:
            # elementsë¥¼ í˜ì´ì§€ë³„ë¡œ ê·¸ë£¹í™”
            pages_dict = {}
            for elem in elements_list:
                page_num = elem.get("page", 1)
                if page_num not in pages_dict:
                    pages_dict[page_num] = []
                
                content_obj = elem.get("content", {})
                if isinstance(content_obj, dict):
                    elem_text = content_obj.get("text", "") or content_obj.get("html", "")
                else:
                    elem_text = str(content_obj)
                
                if elem_text:
                    pages_dict[page_num].append(elem_text)
            
            # í˜ì´ì§€ë³„ë¡œ í…ìŠ¤íŠ¸ êµ¬ì„±
            for page_num in sorted(pages_dict.keys())[:max_pages]:
                structured_text += f"\n\n=== í˜ì´ì§€ {page_num} ===\n\n"
                structured_text += "\n\n".join(pages_dict[page_num])
        
        # structured_textê°€ ì—†ìœ¼ë©´ content.text ì‚¬ìš©
        final_text = structured_text if structured_text.strip() else text
        
        return final_text, min(num_pages, max_pages)
        
    except requests.Timeout:
        st.error("â±ï¸ Upstage API íƒ€ì„ì•„ì›ƒ (ëŒ€ìš©ëŸ‰ PDFëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        return "", 0
    except Exception as e:
        st.error(f"âŒ Upstage API ì˜¤ë¥˜: {e}")
        import traceback
        st.error(traceback.format_exc())
        return "", 0

def extract_text_with_easyocr(pdf_file, max_pages=50):
    """ë¡œì»¬ EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ëŠë¦¼)"""
    text = ""
    try:
        pdf_file.seek(0)
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        num_pages = min(len(doc), max_pages)
        
        progress_bar = st.progress(0)
        
        for page_num in range(num_pages):
            page = doc[page_num]
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            
            if pix.n == 4:
                img_array = img_array[:, :, :3]
            
            ocr_reader = get_ocr_reader()
            ocr_result = ocr_reader.readtext(img_array, detail=0, paragraph=True)
            page_text = "\n".join(ocr_result)
            text += f"\n\n=== í˜ì´ì§€ {page_num+1} ===\n\n{page_text}"
            
            progress_bar.progress((page_num + 1) / num_pages)
        
        progress_bar.empty()
        doc.close()
        return text, num_pages
    except Exception as e:
        st.error(f"ë¡œì»¬ OCR ì˜¤ë¥˜: {e}")
        return "", 0

def extract_all_keywords_batch(text, field_names, structured_data=None):
    """ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•œ ë²ˆì— ì¶”ì¶œ (êµ¬ì¡°í™”ëœ ë°ì´í„° ìš°ì„  í™œìš©)"""
    if not openai_client:
        # API ì—†ìœ¼ë©´ ê°œë³„ ë°©ì‹ìœ¼ë¡œ í´ë°±
        result = {}
        for field_name in field_names:
            result[field_name] = extract_keyword_simple(text, field_name)
        return result
    
    try:
        # êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìš°ì„  í™œìš© - í‘œë¥¼ ëª…í™•í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        context_info = ""
        has_structured_tables = False
        
        if structured_data:
            # í‘œ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´/HTML í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if structured_data.get("tables"):
                has_structured_tables = True
                context_info += "\n\n" + "="*60 + "\n"
                context_info += "ğŸ“Š **êµ¬ì¡°í™”ëœ í‘œ ë°ì´í„° (ìµœìš°ì„  ì°¸ì¡°!)**\n"
                context_info += "="*60 + "\n\n"
                context_info += "âš ï¸ **ì¬ë¬´ ë°ì´í„°ëŠ” ì•„ë˜ í‘œì—ì„œë§Œ ì¶”ì¶œí•˜ì„¸ìš”! ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë¬´ì‹œ!**\n\n"
                
                for idx, table in enumerate(structured_data['tables']):  # ëª¨ë“  í‘œ í‘œì‹œ
                    context_info += f"â–¶ **[í‘œ {idx+1}] (í˜ì´ì§€ {table.get('page', '?')})**\n\n"
                    
                    # Markdownì´ ê°€ì¥ íŒŒì‹±í•˜ê¸° ì‰¬ìš°ë¯€ë¡œ ìš°ì„ 
                    table_markdown = table.get('markdown', '')
                    table_html = table.get('html', '')
                    table_content = table.get('content', '')
                    
                    # í‘œ í˜•ì‹ ì„ íƒ (Markdown > Content > HTML)
                    if table_markdown and len(table_markdown) > 20:
                        # Markdown í‘œë¥¼ ë” ëª…í™•í•˜ê²Œ í‘œì‹œ
                        context_info += "```í‘œ (Markdown í˜•ì‹)\n"
                        context_info += table_markdown[:1500]  # ì¦ê°€
                        context_info += "\n```\n\n"
                    elif table_content and len(table_content) > 20:
                        # Contentë¥¼ êµ¬ì¡°í™”í•´ì„œ í‘œì‹œ
                        context_info += "```í‘œ (í…ìŠ¤íŠ¸ í˜•ì‹)\n"
                        context_info += table_content[:1500]  # ì¦ê°€
                        context_info += "\n```\n\n"
                    elif table_html:
                        context_info += "```í‘œ (HTML í˜•ì‹)\n"
                        context_info += table_html[:1000]
                        context_info += "\n```\n\n"
                    
                    # í‘œ í•´ì„ íŒíŠ¸ ì¶”ê°€
                    context_info += "ğŸ’¡ ì´ í‘œì—ì„œ í–‰ ì´ë¦„(ì²« ë²ˆì§¸ ì—´)ê³¼ ê°’ë“¤ì„ ì •í™•íˆ ë§¤ì¹­í•˜ì„¸ìš”.\n\n"
                    
                context_info += "\n" + "="*60 + "\n"
                context_info += "ğŸ¯ **ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ì‹œ í•„ìˆ˜ í™•ì¸:**\n"
                context_info += "- í‘œì—ì„œ 'ì˜ì—…ì´ìµ' í–‰ì„ ì°¾ê³  í•´ë‹¹ ì—´ì˜ ìˆ«ìë¥¼ ì¶”ì¶œ\n"
                context_info += "- í‘œì—ì„œ 'ë§¤ì¶œì•¡' í–‰ì„ ì°¾ê³  í•´ë‹¹ ì—´ì˜ ìˆ«ìë¥¼ ì¶”ì¶œ\n"
                context_info += "- í‘œ ìƒë‹¨ì— 'ë‹¨ìœ„: ì–µì›' ê°™ì€ í‘œì‹œê°€ ìˆìœ¼ë©´ ëª¨ë“  ìˆ«ìì— ë‹¨ìœ„ ì ìš©\n"
                context_info += "- ë³¸ë¬¸ì— 'ì˜ì—… ìƒì‚°ì„±' ê°™ì€ ë¹„ìŠ·í•œ ë‹¨ì–´ê°€ ìˆì–´ë„ ë¬´ì‹œ!\n"
                context_info += "="*60 + "\n\n"
            
            # ì°¨íŠ¸/ê·¸ë˜í”„ ë°ì´í„° ì¶”ê°€
            if structured_data.get("charts"):
                context_info += "\n\n" + "="*60 + "\n"
                context_info += "ğŸ“ˆ **ì¸ì‹ëœ ì°¨íŠ¸/ê·¸ë˜í”„ ë°ì´í„°**\n"
                context_info += "="*60 + "\n\n"
                
                for idx, chart in enumerate(structured_data['charts']):  # ëª¨ë“  ì°¨íŠ¸ í‘œì‹œ
                    context_info += f"â–¶ **[ì°¨íŠ¸ {idx+1}] (í˜ì´ì§€ {chart.get('page', '?')}) - {chart.get('category', 'chart')}**\n\n"
                    
                    chart_content = chart.get('content', '') or chart.get('html', '')
                    if chart_content:
                        context_info += f"```\n{chart_content[:500]}\n```\n\n"
                
                context_info += "\nğŸ’¡ ì°¨íŠ¸ ë°ì´í„°ì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ì •ë³´(ì„±ì¥ë¥ , ì¶”ì„¸ ë“±)ë¥¼ í™œìš©í•˜ì„¸ìš”.\n\n"
                context_info += "="*60 + "\n\n"
            
            # ì£¼ìš” ì œëª© ìš”ì•½ (ë¬¸ì„œ êµ¬ì¡° íŒŒì•…ìš©)
            if structured_data.get("headings"):
                context_info += "\n[ğŸ“‘ ë¬¸ì„œ êµ¬ì¡° - ì£¼ìš” ì„¹ì…˜]\n"
                for heading in structured_data['headings'][:15]:  # ìµœëŒ€ 15ê°œ
                    heading_text = heading['content'][:100]  # ê¸´ ì œëª©ì€ ìë¥´ê¸°
                    context_info += f"  â€¢ í˜ì´ì§€ {heading.get('page', '?')}: {heading_text}\n"
                context_info += "\n"
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì¡°ì • - í‘œê°€ ìˆìœ¼ë©´ ì¤‘ê°„, ì—†ìœ¼ë©´ ê¸¸ê²Œ
        if has_structured_tables:
            text_preview = text[:8000]  # í‘œê°€ ìˆì–´ë„ ì¶©ë¶„í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ (ì¬ë¬´í‘œ ì „ì²´ í¬í•¨)
        else:
            text_preview = text[:15000]  # í‘œê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì°¾ì•„ì•¼ í•˜ë¯€ë¡œ ë” ê¸¸ê²Œ
        
        # ëª¨ë“  í•„ë“œë¥¼ í•œ ë²ˆì— ìš”ì²­
        fields_list = "\n".join([f"{i+1}. {name}" for i, name in enumerate(field_names)])
        
        # í‘œê°€ ìˆì„ ë•Œì™€ ì—†ì„ ë•Œ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸
        if has_structured_tables:
            extraction_guide = """
ğŸ¯ **ì¶”ì¶œ ê°€ì´ë“œ (êµ¬ì¡°í™”ëœ í‘œ ìˆìŒ)**

1. **â­ í‘œ ë°ì´í„° ì ˆëŒ€ ìš°ì„ !**
   - ìœ„ì— ì œê³µëœ "êµ¬ì¡°í™”ëœ í‘œ ë°ì´í„°"ë¥¼ **ë°˜ë“œì‹œ ë¨¼ì €** ë¶„ì„í•˜ì„¸ìš”
   - ë³¸ë¬¸ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡° ì°¸ê³ ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”
   - HTML/Markdown í‘œ êµ¬ì¡°ë¥¼ ì •í™•íˆ íŒŒì‹±í•˜ì„¸ìš”
   - í‘œì˜ í—¤ë”(ì—´ ì´ë¦„)ì™€ ë°ì´í„° í–‰ì„ êµ¬ë¶„í•˜ì„¸ìš”

2. **ğŸ”¢ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ê·œì¹™ (ì—„ê²©)**
   
   **ğŸ’° ê¸ˆì•¡ ë°ì´í„° (ë°˜ë“œì‹œ ìˆ«ì + ë‹¨ìœ„):**
   - ë§¤ì¶œì•¡: "Revenue", "Sales", "ë§¤ì¶œì•¡" í–‰ â†’ ì˜ˆ: "294ì–µ ì›"
   - ì˜ì—…ì´ìµ: "Operating Profit", "ì˜ì—…ì´ìµ" í–‰ â†’ ì˜ˆ: "43ì–µ ì›"
   - ìˆœì´ìµ: "Net Profit", "Net Income", "ë‹¹ê¸°ìˆœì´ìµ" í–‰ â†’ ì˜ˆ: "24ì–µ ì›"
   - EBITDA: "EBITDA" í–‰ ì°¾ê¸°
   - CAPEX: "CAPEX", "ìë³¸ì ì§€ì¶œ", "ì„¤ë¹„íˆ¬ì" í–‰
   - í˜„ê¸ˆíë¦„: "Cash Flow", "ì˜ì—…í˜„ê¸ˆíë¦„", "OCF" í–‰
   - âš ï¸ ì£¼ì˜: "17.6%"ëŠ” ê¸ˆì•¡ì´ ì•„ë‹™ë‹ˆë‹¤! ë¹„ìœ¨/ë°±ë¶„ìœ¨ì€ ì œì™¸!
   
   **ğŸ“Š ë¹„ìœ¨ ë°ì´í„° (ë°˜ë“œì‹œ % í¬í•¨):**
   - ì˜ì—…ì´ìµë¥ : "Operating Margin", "ì˜ì—…ì´ìµë¥ " í–‰ ë˜ëŠ” (ì˜ì—…ì´ìµ/ë§¤ì¶œì•¡Ã—100)
   - ìˆœì´ìµë¥ : "Net Margin", "ìˆœì´ìµë¥ " í–‰ ë˜ëŠ” (ìˆœì´ìµ/ë§¤ì¶œì•¡Ã—100)
   - ë¶€ì±„ë¹„ìœ¨: "Debt Ratio", "ë¶€ì±„ë¹„ìœ¨" í–‰
   - ROE: "ROE", "ìê¸°ìë³¸ì´ìµë¥ " í–‰
   - ì„±ì¥ë¥ : "YoY", "Growth Rate", "CAGR" â†’ ì˜ˆ: "+15.3%", "-9.3%"
   
   **â›” ì ˆëŒ€ ê¸ˆì§€:**
   - "ì˜ì—… ìƒì‚°ì„±", "ì˜ì—… íš¨ìœ¨" ë“±ì€ ì˜ì—…ì´ìµì´ ì•„ë‹™ë‹ˆë‹¤!
   - ë³¸ë¬¸ì— "ì˜ì—…ì´ìµ"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ìˆì–´ë„ í‘œë¥¼ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”!
   - ì¶”ì¸¡í•˜ê±°ë‚˜ ê³„ì‚°í•˜ì§€ ë§ˆì„¸ìš” (í‘œì— ì§ì ‘ ìˆëŠ” ê°’ë§Œ!)

3. **ğŸ¢ ê¸°ì—… ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ**
   - íšŒì‚¬ëª…/ê¸°ì—…ëª…/ë²•ì¸ëª…: í‘œì§€, í—¤ë”, "íšŒì‚¬ëª…:" ë¼ë²¨ ì°¾ê¸°
   - ëŒ€í‘œì´ì‚¬/CEO: "ëŒ€í‘œì´ì‚¬", "CEO", "Representative" ì°¾ê¸°
   - ì„¤ë¦½ì¼: "ì„¤ë¦½ì¼", "ì„¤ë¦½ì—°ë„", "Founded" (YYYY-MM-DD ë˜ëŠ” YYYYë…„)
   - ë³¸ì‚¬ ìœ„ì¹˜: "ë³¸ì‚¬", "Head Office", "Location", "ì£¼ì†Œ"
   - ì§ì› ìˆ˜: "ì„ì§ì›ìˆ˜", "ì§ì›ìˆ˜", "Employees" (ìˆ«ì+ëª…)
   - ì—…ì¢…/ì‚°ì—…ë¶„ë¥˜: "ì—…ì¢…", "Industry", "Sector"

4. **ğŸ­ ì‚¬ì—…êµ¬ì¡° & ì œí’ˆ ì •ë³´**
   - ì‚¬ì—…ë¶„ì•¼: "ì‚¬ì—…ì˜ì—­", "Business Area", "ì£¼ìš”ì‚¬ì—…" (ì—¬ëŸ¬ ê°œë©´ ì‰¼í‘œë¡œ êµ¬ë¶„)
   - ì£¼ìš” ì œí’ˆ: "ì œí’ˆ", "Products", "Services" (êµ¬ì²´ì  ì œí’ˆëª…)
   - í•µì‹¬ ê¸°ìˆ : "Core Technology", "ê¸°ìˆ ë ¥", "R&D" (ê¸°ìˆ ëª…)
   - ì‹œì¥ ì ìœ ìœ¨: "Market Share", "ì ìœ ìœ¨" (% ë˜ëŠ” ìˆœìœ„)
   - ê³ ê°ì‚¬: "ì£¼ìš” ê³ ê°", "ê±°ë˜ì²˜", "Customers" (ê¸°ì—…ëª…ë“¤)
   - ê²½ìŸìš°ìœ„: "ê°•ì ", "Competitive Advantage", "ì°¨ë³„í™”"

5. **âš”ï¸ ê²½ìŸí™˜ê²½ & ë¦¬ìŠ¤í¬**
   - ê²½ìŸì‚¬: "ê²½ìŸì—…ì²´", "Competitors" (íšŒì‚¬ëª…ë“¤)
   - ì‹œì¥ ê·œëª¨: "Market Size" (ê¸ˆì•¡ + ë‹¨ìœ„)
   - ì‹œì¥ ì„±ì¥ë¥ : "Market Growth Rate", "CAGR" (%)
   - ì§„ì…ì¥ë²½: "Entry Barrier", "ì§„ì…ì¥ë²½"
   - SWOT ë¶„ì„: "Strength", "Weakness", "Opportunity", "Threat"
   - ë¦¬ìŠ¤í¬: "Risk", "ìœ„í—˜ìš”ì¸", "ë¶ˆí™•ì‹¤ì„±"
   - ê·œì œ ì´ìŠˆ: "ê·œì œ", "Regulation"

6. **ğŸš€ ì „ëµ & ë¯¸ë˜ ê³„íš**
   - ì‹ ê·œ ì‚¬ì—…: "New Business", "ì‹ ì‚¬ì—…"
   - M&A: "ì¸ìˆ˜í•©ë³‘", "M&A"
   - íˆ¬ì ê³„íš: "íˆ¬ìê³„íš", "CAPEX", "ì„¤ë¹„íˆ¬ì"
   - ê¸€ë¡œë²Œ ì§„ì¶œ: "í•´ì™¸ì§„ì¶œ", "Global Expansion"
   - R&D: "ì—°êµ¬ê°œë°œ", "R&D íˆ¬ì"
   - ESG ì „ëµ: "ESG", "ì§€ì†ê°€ëŠ¥ê²½ì˜", "íƒ„ì†Œì¤‘ë¦½"

7. **ğŸ“… ë¶„ê¸°/ì—°ë„ ë°ì´í„° ì²˜ë¦¬**
   - ë¶„ê¸°ë³„ ë°ì´í„°: "24.3Q", "25.2Q", "25.3Q" ë“±ì˜ ì—´
   - ìµœì‹  ë¶„ê¸° ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì¶œí•˜ì„¸ìš”
   - ì—¬ëŸ¬ ë¶„ê¸°ê°€ ìˆìœ¼ë©´ ëª¨ë‘ ë‚˜ì—´: "43ì–µ ì› (25.3Q), 32ì–µ ì› (25.2Q)"

8. **ğŸ“ ë‹¨ìœ„ ì¸ì‹ ë° í‘œê¸°**
   - "ë‹¨ìœ„: ì–µì›" â†’ ëª¨ë“  ìˆ«ì ë’¤ì— "ì–µ ì›" ì¶”ê°€
   - "(ì‹­ì–µ ë‹¬ëŸ¬)" â†’ "billion USD" ë˜ëŠ” "ì‹­ì–µ ë‹¬ëŸ¬"
   - "%", "ë¹„ìœ¨" â†’ ë°±ë¶„ìœ¨ ë°ì´í„°
   - "ëª…", "ê°œ", "ê±´" â†’ ê°œìˆ˜ ë‹¨ìœ„

9. **âœ… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
   - [ ] í‘œì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œì˜ í–‰ì„ ì°¾ì•˜ë‚˜ìš”?
   - [ ] ê¸ˆì•¡ì€ ìˆ«ì+ë‹¨ìœ„ í˜•íƒœì¸ê°€ìš”? (ì˜ˆ: 43ì–µ ì› âœ…, 17.6% âŒ)
   - [ ] ë¹„ìœ¨ì€ %ê°€ í¬í•¨ë˜ì–´ ìˆë‚˜ìš”?
   - [ ] ê¸°ì—… ì •ë³´ëŠ” ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ê°€ìš”?
   - [ ] ì—¬ëŸ¬ í•­ëª©ì´ ìˆìœ¼ë©´ ì‰¼í‘œë¡œ êµ¬ë¶„í–ˆë‚˜ìš”?
   - [ ] í‘œì— ì—†ì–´ì„œ ë³¸ë¬¸ì„ ë´¤ë‹¤ë©´, ì •ë§ í‘œì— ì—†ëŠ” ê²Œ ë§ë‚˜ìš”?
"""
        else:
            extraction_guide = """
ğŸ¯ **ì¶”ì¶œ ê°€ì´ë“œ (í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì‹±)**

1. **ğŸ“ í‘œ í˜•ì‹ í…ìŠ¤íŠ¸ íŒŒì‹±**
   - "| êµ¬ë¶„ | 24.3Q | 25.2Q |" â†’ í‘œ í—¤ë”
   - "| ì˜ì—…ì´ìµ | 561 | 390 |" â†’ ë°ì´í„° í–‰
   - íŒŒì´í”„(|) êµ¬ë¶„ìë¡œ ì—´ì„ ë‚˜ëˆ  íŒŒì‹±í•˜ì„¸ìš”
   - í‘œ í˜•ì‹ì´ ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì³ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì „ì²´ ìŠ¤ìº”

2. **ğŸ” ì„¹ì…˜ë³„ íƒìƒ‰ ìš°ì„ ìˆœìœ„**
   
   **ì¬ë¬´ ë°ì´í„°:**
   â‘  "Financial Results", "ê²½ì˜ì‹¤ì ", "ì˜ì—…ì‹¤ì ", "ì†ìµê³„ì‚°ì„œ", "ì‹¤ì  ìš”ì•½"
   â‘¡ "ì¬ë¬´ì •ë³´", "ì¬ë¬´í˜„í™©", "ì¬ë¬´ìƒíƒœí‘œ", "3Q Results"
   â‘¢ ì°¨íŠ¸ ì œëª© ë° ë°ì´í„° (Chart Type: bar/line ë“±)
   
   **ê¸°ì—… ì •ë³´:**
   â‘  ì²« í˜ì´ì§€, í‘œì§€, í—¤ë”/í‘¸í„°
   â‘¡ "Company Overview", "ê¸°ì—…ê°œìš”", "íšŒì‚¬ì†Œê°œ"
   â‘¢ "Organization", "ì¡°ì§ë„"
   
   **ì‚¬ì—… ì •ë³´:**
   â‘  "Business", "ì‚¬ì—…êµ¬ì¡°", "ì‚¬ì—…ì˜ì—­"
   â‘¡ "Products & Services", "ì œí’ˆ ë° ì„œë¹„ìŠ¤"
   â‘¢ "Core Competency", "í•µì‹¬ì—­ëŸ‰"
   
   **ì „ëµ ì •ë³´:**
   â‘  "Strategy", "ì „ëµ", "Growth Strategy"
   â‘¡ "Future Plans", "í–¥í›„ ê³„íš"
   â‘¢ "Investment", "íˆ¬ìê³„íš"
   
   âš ï¸ ì •ë³´ê°€ ë¬¸ì„œ ì „ì²´ì— ë¶„ì‚°ë˜ì–´ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ ì „ì²´ë¥¼ ìŠ¤ìº”í•˜ì„¸ìš”

3. **ğŸ”¢ ì¬ë¬´ ë°ì´í„° êµ¬ë³„ (ì¤‘ìš”!)**
   
   **ğŸ’° ê¸ˆì•¡ (ìˆ«ì + ë‹¨ìœ„ í•„ìˆ˜):**
   - ë§¤ì¶œì•¡: "2,345ì–µ ì›", "294ì–µ ì›" (âœ…)
   - ì˜ì—…ì´ìµ: "43ì–µ ì›", "561ì–µ ì›" (âœ…)
   - ìˆœì´ìµ: "24ì–µ ì›", "390ì–µ ì›" (âœ…)
   - EBITDA: "450ì–µ ì›" (âœ…)
   - CAPEX: "150ì–µ ì›" (âœ…)
   - "17.6%"ëŠ” ê¸ˆì•¡ì´ ì•„ë‹™ë‹ˆë‹¤! (âŒ)
   
   **ğŸ“Š ë¹„ìœ¨ (% í•„ìˆ˜):**
   - ì˜ì—…ì´ìµë¥ : "14.6%", "23.5%" (âœ…)
   - ë¶€ì±„ë¹„ìœ¨: "45.3%", "120%" (âœ…)
   - ROE: "15.2%" (âœ…)
   - ì„±ì¥ë¥ : "+15.3%", "YoY -9.3%" (âœ…)
   
   **â›” í˜¼ë™ ì£¼ì˜:**
   - "ì˜ì—… ìƒì‚°ì„± 17.6%" â‰  ì˜ì—…ì´ìµ!
   - "ì˜ì—… íš¨ìœ¨ì„± 15%" â‰  ì˜ì—…ì´ìµë¥ !
   - "ì‹œì¥ ì ìœ ìœ¨ 25%" â‰  ì„±ì¥ë¥ !

4. **ğŸ¢ ê¸°ì—… ì •ë³´ ì¶”ì¶œ íŒ¨í„´**
   
   **íšŒì‚¬ëª…/ê¸°ì—…ëª…:**
   - "â—‹â—‹ì£¼ì‹íšŒì‚¬", "â—‹â—‹(ì£¼)", "â—‹â—‹ Co., Ltd."
   - ë¬¸ì„œ ìƒë‹¨, ë¡œê³  ê·¼ì²˜, "íšŒì‚¬ëª…:" ë¼ë²¨
   
   **ëŒ€í‘œì´ì‚¬/CEO:**
   - "ëŒ€í‘œì´ì‚¬: í™ê¸¸ë™"
   - "CEO: John Doe"
   - "Representative Director"
   
   **ì„¤ë¦½ì¼:**
   - "ì„¤ë¦½ì¼: 1998ë…„ 3ì›” 15ì¼"
   - "Founded: 1998"
   - "Since 1998"
   
   **ì‚¬ì—…ë¶„ì•¼:**
   - "ì£¼ìš” ì‚¬ì—…: A, B, C"
   - "Business Areas: Manufacturing, Distribution"
   - ì—¬ëŸ¬ ê°œë©´ ì‰¼í‘œë¡œ êµ¬ë¶„
   
   **ì£¼ìš” ì œí’ˆ:**
   - êµ¬ì²´ì ì¸ ì œí’ˆëª…/ì„œë¹„ìŠ¤ëª…
   - "ì œí’ˆ ë¼ì¸ì—…:", "Product Portfolio:"
   
   **ê³ ê°ì‚¬:**
   - ê¸°ì—…ëª… ë‚˜ì—´: "ì‚¼ì„±, LG, SK"
   - "Major Clients:", "ì£¼ìš” ê±°ë˜ì²˜:"

5. **âš”ï¸ ê²½ìŸ & ë¦¬ìŠ¤í¬ ì •ë³´**
   
   **ê²½ìŸì‚¬:**
   - "ê²½ìŸì—…ì²´:", "Competitors:"
   - íšŒì‚¬ëª…ë“¤ ë‚˜ì—´
   
   **ì‹œì¥ ê·œëª¨:**
   - "ì‹œì¥ ê·œëª¨: 5ì¡° ì›"
   - "Market Size: $5B"
   
   **SWOT ë¶„ì„:**
   - "ê°•ì (Strength):", "ì•½ì (Weakness):"
   - "ê¸°íšŒ(Opportunity):", "ìœ„í˜‘(Threat):"
   
   **ë¦¬ìŠ¤í¬:**
   - "ë¦¬ìŠ¤í¬ ìš”ì¸:", "Risk Factors:"
   - "ì£¼ìš” ìœ„í—˜:", "Risks:"

6. **ğŸš€ ì „ëµ & ê³„íš ì •ë³´**
   
   **ì‹ ê·œ ì‚¬ì—…:**
   - "ì‹ ì‚¬ì—…:", "New Business:"
   - "ì‚¬ì—… ë‹¤ê°í™”", "Diversification"
   
   **M&A:**
   - "ì¸ìˆ˜í•©ë³‘:", "M&A:"
   - "Acquisition", "Merger"
   
   **íˆ¬ì ê³„íš:**
   - "íˆ¬ì ê³„íš:", "Investment Plan:"
   - "CAPEX:", "ì„¤ë¹„íˆ¬ì:"
   
   **ê¸€ë¡œë²Œ ì§„ì¶œ:**
   - "í•´ì™¸ ì§„ì¶œ:", "Global Expansion:"
   - "ìˆ˜ì¶œ:", "Export:"

7. **ğŸ“‹ íŒ¨í„´ ë§¤ì¹­ ì˜ˆì‹œ**
   - "ë§¤ì¶œì•¡: 2,345ì–µ ì›" â†’ "2,345ì–µ ì›"
   - "ì˜ì—…ì´ìµë¥  23.5%" â†’ "23.5%"
   - "24.3Q ì˜ì—…ì´ìµ 561ì–µ" â†’ "561ì–µ ì› (24.3Q)"
   - "| ì˜ì—…ì´ìµ | 43 | 32 |" â†’ "43ì–µ ì› (ìµœì‹ ), 32ì–µ ì›"
   - "íšŒì‚¬ëª…: ë™êµ­ìƒëª…ê³¼í•™" â†’ "ë™êµ­ìƒëª…ê³¼í•™"
   - "ëŒ€í‘œì´ì‚¬: í™ê¸¸ë™" â†’ "í™ê¸¸ë™"
   - "ì£¼ìš” ì œí’ˆ: A, B, C" â†’ "A, B, C"

8. **ğŸš« ì‹¤íŒ¨ ë°©ì§€ ì „ëµ**
   - í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ê¼¼ê¼¼íˆ ìŠ¤ìº”í•˜ì„¸ìš”
   - ìœ ì‚¬ ìš©ì–´ë„ í™•ì¸: 
     â€¢ "ë§¤ì¶œì•¡" = "Sales" = "Revenue" = "ì´ë§¤ì¶œ"
     â€¢ "ì˜ì—…ì´ìµ" = "Operating Profit" = "Operating Income"
     â€¢ "ìˆœì´ìµ" = "Net Profit" = "Net Income" = "ë‹¹ê¸°ìˆœì´ìµ"
     â€¢ "íšŒì‚¬ëª…" = "ê¸°ì—…ëª…" = "ë²•ì¸ëª…" = "Company Name"
     â€¢ "ëŒ€í‘œì´ì‚¬" = "CEO" = "ëŒ€í‘œ" = "Representative"
   - ì•½ì–´ë„ í™•ì¸:
     â€¢ "R&D" = "ì—°êµ¬ê°œë°œ"
     â€¢ "M&A" = "ì¸ìˆ˜í•©ë³‘"
     â€¢ "ESG" = "í™˜ê²½Â·ì‚¬íšŒÂ·ì§€ë°°êµ¬ì¡°"
   - "ì •ë³´ ì—†ìŒ"ì€ ì •ë§ í…ìŠ¤íŠ¸ ì–´ë””ì—ë„ ì—†ì„ ë•Œë§Œ!
   - ë‹¨ìœ„ê°€ í‘œì‹œë˜ì–´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
   - ë§¥ë½ì—ì„œ ìœ ì¶” ê°€ëŠ¥í•œ ì •ë³´ë„ í™œìš©í•˜ì„¸ìš”
"""
        
        prompt = f"""ë‹¹ì‹ ì€ ê¸°ì—… ì‹¤ì  ë°œí‘œ ìë£Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë°ì´í„°ì—ì„œ ìš”ì²­í•œ í•­ëª©ì„ **ì •í™•íˆ** ì¶”ì¶œí•˜ì„¸ìš”.

{context_info}

{"[ë³¸ë¬¸ í…ìŠ¤íŠ¸ - ë³´ì¡° ì°¸ê³ ìš©]" if has_structured_tables else "[ë³¸ë¬¸ í…ìŠ¤íŠ¸ - ì£¼ ë¶„ì„ ëŒ€ìƒ]"}
```
{text_preview}
```

---

**ğŸ“‹ ì¶”ì¶œí•  í•­ëª©:**
{fields_list}

{extraction_guide}

6. **âš ï¸ ì¶œë ¥ í˜•ì‹ (ì—„ê²©íˆ ì¤€ìˆ˜!)**
   ```
   [í•­ëª©ëª…]: ì¶”ì¶œëœ ê°’
   ```
   
   âœ… **ì˜¬ë°”ë¥¸ ì˜ˆì‹œ (ëª¨ë“  íƒ€ì…):**
   ```
   # ì¬ë¬´ ë°ì´í„° (ê¸ˆì•¡)
   [ë§¤ì¶œì•¡]: 294ì–µ ì› (2025.3Q), 349ì–µ ì› (2025.2Q)
   [ì˜ì—…ì´ìµ]: 43ì–µ ì› (2025.3Q), 32ì–µ ì› (2025.2Q)
   [ìˆœì´ìµ]: 24ì–µ ì› (2025.3Q), 29ì–µ ì› (2025.2Q)
   [EBITDA]: 450ì–µ ì› (2025.3Q)
   [CAPEX]: 150ì–µ ì› (2024ë…„)
   [í˜„ê¸ˆíë¦„]: 380ì–µ ì› (ì˜ì—…í™œë™)
   
   # ì¬ë¬´ ë°ì´í„° (ë¹„ìœ¨)
   [ì˜ì—…ì´ìµë¥ ]: 14.6% (2025.3Q), 9.2% (2025.2Q)
   [ìˆœì´ìµë¥ ]: 8.2% (2025.3Q)
   [ë¶€ì±„ë¹„ìœ¨]: 45.3% (2024ë…„ ë§)
   [ROE]: 15.2% (2024ë…„)
   [YoY]: -9.3% (ë§¤ì¶œì•¡ ê¸°ì¤€)
   [CAGR]: +12.5% (2020-2024)
   
   # ê¸°ì—… ê¸°ë³¸ ì •ë³´
   [íšŒì‚¬ëª…]: ë™êµ­ìƒëª…ê³¼í•™
   [ê¸°ì—…ëª…]: ë™êµ­ìƒëª…ê³¼í•™ ì£¼ì‹íšŒì‚¬
   [ëŒ€í‘œì´ì‚¬]: í™ê¸¸ë™
   [CEO]: í™ê¸¸ë™
   [ì„¤ë¦½ì¼]: 1998ë…„ 3ì›” 15ì¼
   [ë³¸ì‚¬ ìœ„ì¹˜]: ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬
   [ì§ì› ìˆ˜]: 350ëª… (2024ë…„ ê¸°ì¤€)
   [ì—…ì¢…]: ì œì•½ì—…
   [ì‚°ì—…ë¶„ë¥˜]: ì˜ì•½í’ˆ ì œì¡°ì—…
   
   # ì‚¬ì—…êµ¬ì¡° & ì œí’ˆ
   [ì‚¬ì—…ë¶„ì•¼]: ì¡°ì˜ì œ ì œì¡° ë° íŒë§¤, ì˜ë£Œê¸°ê¸° ìœ í†µ, í—¬ìŠ¤ì¼€ì–´
   [ì£¼ìš” ì œí’ˆ]: íŒŒë¯¸ë ˆì´, ë©”ë””ë ˆì´, ìœ ë‹ˆë ˆì´, ê°€ë„ë¹„ì „
   [í•µì‹¬ ê¸°ìˆ ]: First Generic ê¸°ìˆ ë ¥, ê³ ìˆœë„ ì •ì œ ê¸°ìˆ , ìˆ˜ì§ ê³„ì—´í™”
   [ì‹œì¥ ì ìœ ìœ¨]: êµ­ë‚´ ì¡°ì˜ì œ ì‹œì¥ 21.4% (1ìœ„)
   [ê³ ê°ì‚¬]: ì„œìš¸ì•„ì‚°ë³‘ì›, ì‚¼ì„±ì„œìš¸ë³‘ì›, ì„¸ë¸Œë€ìŠ¤ë³‘ì› ë“± 21ê°œ ìƒê¸‰ë³‘ì›
   [ê²½ìŸìš°ìœ„]: êµ­ë‚´ ìœ ì¼ ìˆ˜ì§ ê³„ì—´í™”, ìµœë‹¤ í’ˆëª© ë¼ì¸ì—… 43ì¢…
   
   # ê²½ìŸí™˜ê²½
   [ê²½ìŸì‚¬]: Aì œì•½, Bë°”ì´ì˜¤, Cí—¬ìŠ¤ì¼€ì–´
   [ì‹œì¥ ê·œëª¨]: êµ­ë‚´ ì¡°ì˜ì œ ì‹œì¥ 5,000ì–µ ì› (2024ë…„)
   [ì‹œì¥ ì„±ì¥ë¥ ]: ì—°í‰ê·  7.5% ì„±ì¥ (2020-2024)
   [ì§„ì…ì¥ë²½]: ë†’ìŒ (ì¸í—ˆê°€, ê¸°ìˆ ë ¥, ìœ í†µë§ í•„ìš”)
   [SWOT ë¶„ì„]: ê°•ì -ê¸°ìˆ ë ¥/ì‹œì¥ì ìœ ìœ¨, ì•½ì -í•´ì™¸ë§¤ì¶œë¹„ì¤‘, ê¸°íšŒ-ê³ ë ¹í™”/ì§„ë‹¨ìˆ˜ìš”, ìœ„í˜‘-ê²½ìŸì‹¬í™”
   
   # ë¦¬ìŠ¤í¬
   [ì¬ë¬´ ë¦¬ìŠ¤í¬]: í™˜ìœ¨ ë³€ë™, ì›ì¬ë£Œ ê°€ê²© ìƒìŠ¹
   [ìš´ì˜ ë¦¬ìŠ¤í¬]: í’ˆì§ˆ ì´ìŠˆ, ìƒì‚° ì°¨ì§ˆ
   [ê·œì œ ë¦¬ìŠ¤í¬]: ì•½ê°€ ì¸í•˜ ì••ë ¥, ë³´í—˜ê¸‰ì—¬ ì •ì±… ë³€í™”
   
   # ì „ëµ & ë¯¸ë˜
   [ì‹ ê·œ ì‚¬ì—…]: AI ì§„ë‹¨ ì†Œí”„íŠ¸ì›¨ì–´ ì‚¬ì—… ì§„ì¶œ (2025ë…„)
   [M&A]: ì¤‘ì†Œ ì˜ë£Œê¸°ê¸° ì—…ì²´ ì¸ìˆ˜ ê²€í†  ì¤‘
   [íˆ¬ì ê³„íš]: 2025ë…„ CAPEX 200ì–µ ì› (ìƒì‚°ì„¤ë¹„ ì¦ì„¤)
   [ê¸€ë¡œë²Œ ì§„ì¶œ]: ë™ë‚¨ì•„ì‹œì•„ 5ê°œêµ­ ì§„ì¶œ (ì¸ë„ë„¤ì‹œì•„, ë² íŠ¸ë‚¨, íƒœêµ­ ë“±)
   [R&D]: ì—°ê°„ ë§¤ì¶œì˜ 5.5% R&D íˆ¬ì (ì‹ ê·œ ì¡°ì˜ì œ ê°œë°œ)
   [ESG ì „ëµ]: 2030ë…„ íƒ„ì†Œì¤‘ë¦½ ë‹¬ì„± ëª©í‘œ
   ```
   
   âŒ **ì˜ëª»ëœ ì˜ˆì‹œ (ì ˆëŒ€ ê¸ˆì§€!):**
   ```
   [ì˜ì—…ì´ìµ]: 17.6% (â† ì´ê±´ ë¹„ìœ¨ì´ì§€ ê¸ˆì•¡ì´ ì•„ë‹˜!)
   [ì˜ì—…ì´ìµ]: ì˜ì—… ìƒì‚°ì„± 17.6% (â† ì˜ì—…ì´ìµ â‰  ì˜ì—… ìƒì‚°ì„±!)
   [ì˜ì—…ì´ìµë¥ ]: ì •ë³´ ì—†ìŒ (â† í‘œì— ì˜ì—…ì´ìµ 43, ë§¤ì¶œì•¡ 294ê°€ ìˆìœ¼ë©´ ê³„ì‚° ê°€ëŠ¥!)
   [ë§¤ì¶œì•¡]: ì•½ 300ì–µ ì› ì •ë„ (â† ì¶”ì¸¡ ê¸ˆì§€! ì •í™•í•œ ê°’ë§Œ!)
   [íšŒì‚¬ëª…]: íšŒì‚¬ (â† ë„ˆë¬´ ë¶ˆëª…í™•!)
   [ëŒ€í‘œì´ì‚¬]: CEO (â† ì´ë¦„ì„ ì°¾ì•„ì•¼ í•¨!)
   [ì‚¬ì—…ë¶„ì•¼]: ì œì¡°ì—… (â† ë„ˆë¬´ ì¼ë°˜ì ! êµ¬ì²´ì ìœ¼ë¡œ!)
   [ê³ ê°ì‚¬]: ì—¬ëŸ¬ ë³‘ì› (â† êµ¬ì²´ì ì¸ ì´ë¦„ í•„ìš”!)
   ```

7. **ğŸ¯ í•„ìˆ˜ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:**
   - [ ] ì¬ë¬´ ë°ì´í„°(ë§¤ì¶œ, ì´ìµ ë“±)ëŠ” í‘œì—ì„œ í™•ì¸í–ˆë‚˜ìš”?
   - [ ] ê¸ˆì•¡ í•­ëª©ì— ìˆ«ì+ë‹¨ìœ„(ì–µ ì›, ë‹¬ëŸ¬)ë¥¼ í¬í•¨í–ˆë‚˜ìš”?
   - [ ] ë¹„ìœ¨ í•­ëª©(%ë¡œ ëë‚˜ëŠ” ê²ƒ)ì— %ë¥¼ í¬í•¨í–ˆë‚˜ìš”?
   - [ ] ë³¸ë¬¸ì˜ "ì˜ì—… ìƒì‚°ì„±", "ì˜ì—… íš¨ìœ¨" ë“±ì„ ì˜ì—…ì´ìµìœ¼ë¡œ ì°©ê°í•˜ì§€ ì•Šì•˜ë‚˜ìš”?
   - [ ] ê¸°ì—…ëª…ì€ ì •í™•í•˜ê³  ê³µì‹ ëª…ì¹­ì¸ê°€ìš”?
   - [ ] ì‚¬ì—…ë¶„ì•¼ëŠ” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í–ˆë‚˜ìš”? (ì˜ˆ: "ì œì¡°ì—…" âŒ â†’ "ì˜ì•½í’ˆ ì œì¡°ì—…" âœ…)
   - [ ] ì—¬ëŸ¬ í•­ëª©ì´ ìˆìœ¼ë©´ ì‰¼í‘œë¡œ êµ¬ë¶„í–ˆë‚˜ìš”?
   - [ ] ë¶„ê¸°/ì—°ë„ ì •ë³´ë¥¼ í•¨ê»˜ í‘œê¸°í–ˆë‚˜ìš”?
   - [ ] ì •ë§ ì •ë³´ê°€ ì—†ì–´ì„œ "ì •ë³´ ì—†ìŒ"ì´ë¼ê³  í–ˆë‚˜ìš”?

**ğŸš€ ì§€ê¸ˆ ì‹œì‘í•˜ì„¸ìš”! í‘œë¥¼ ë¨¼ì € ë³´ê³ , ì •í™•í•œ ê°’ì„ ì¶”ì¶œí•˜ì„¸ìš”!**"""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ '[í•­ëª©ëª…]: ë‚´ìš©' í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤. ëª¨ë“  ìš”ì²­ëœ í•­ëª©ì— ëŒ€í•´ ë¹ ì§ì—†ì´ ë‹µë³€í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=1500,  # ë” ë§ì€ í‚¤ì›Œë“œ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ ì¦ê°€ (800 â†’ 1500)
            temperature=0.1
        )
        
        result_text = response.choices[0].message.content.strip()
        print(f"[DEBUG] ë°°ì¹˜ ì¶”ì¶œ ê²°ê³¼:\n{result_text}\n")
        
        # ê²°ê³¼ íŒŒì‹± - ë” ê°„ë‹¨í•œ ë°©ì‹
        extracted_data = {}
        
        for line in result_text.split('\n'):
            line = line.strip()
            if not line:
                continue
            
            # [í•­ëª©ëª…]: ë˜ëŠ” í•­ëª©ëª…: í˜•ì‹ ì°¾ê¸°
            if ':' in line:
                # [ ] ì œê±°
                line = line.replace('[', '').replace(']', '')
                parts = line.split(':', 1)
                
                if len(parts) == 2:
                    field_name = parts[0].strip()
                    value = parts[1].strip()
                    
                    # í•„ë“œëª…ì´ ìš”ì²­í•œ í•­ëª© ì¤‘ í•˜ë‚˜ì¸ì§€ í™•ì¸
                    for fn in field_names:
                        if fn == field_name or fn in field_name or field_name in fn:
                            extracted_data[fn] = value
                            break
        
        # ëˆ„ë½ëœ í•„ë“œëŠ” "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ ì±„ìš°ê¸°
        for field_name in field_names:
            if field_name not in extracted_data:
                extracted_data[field_name] = "ì •ë³´ ì—†ìŒ"
        
        print(f"[DEBUG] íŒŒì‹±ëœ ë°ì´í„°: {extracted_data}\n")
        return extracted_data
        
    except Exception as e:
        print(f"[DEBUG] ë°°ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê°œë³„ ë°©ì‹ìœ¼ë¡œ í´ë°±
        result = {}
        for field_name in field_names:
            result[field_name] = extract_keyword_simple(text, field_name)
        return result

def extract_keyword(text, field_name):
    """OpenAI APIë¡œ ì§€ëŠ¥ì ìœ¼ë¡œ í‚¤ì›Œë“œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ"""
    if not openai_client:
        return extract_keyword_simple(text, field_name)
    
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ)
        text_preview = text[:4000]
        
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ "{field_name}"ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì„œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text_preview}

ìš”êµ¬ì‚¬í•­:
1. "{field_name}"ì™€ ê´€ë ¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¶”ì¶œ
2. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì •ë³´ ì—†ìŒ"ì´ë¼ê³ ë§Œ ì‘ë‹µ
3. ì¶”ì¶œí•œ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ë‹µë³€ (ì„¤ëª… ì—†ì´)
4. ì—¬ëŸ¬ í•­ëª©ì´ ìˆìœ¼ë©´ ëª¨ë‘ í¬í•¨
5. ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ìœ ì§€

ë‹µë³€:"""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìš”ì²­ë°›ì€ ì •ë³´ë¥¼ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì™„ì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.1
        )
        
        result = response.choices[0].message.content.strip()
        
        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ í´ë°±
        if not result or len(result) < 2:
            return extract_keyword_simple(text, field_name)
        
        return result
        
    except Exception as e:
        print(f"[DEBUG] OpenAI ì¶”ì¶œ ì‹¤íŒ¨ ({field_name}): {e}")
        return extract_keyword_simple(text, field_name)

def extract_keyword_simple(text, field_name):
    """ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë§¤ì¹­ ë°©ì‹ (í´ë°±)"""
    keywords_map = {
        "íšŒì‚¬": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "íšŒì‚¬ëª…": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "íšŒì‚¬ì´ë¦„": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "ê¸°ì—…ëª…": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "ëŒ€í‘œ": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "ëŒ€í‘œì´ë¦„": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "ëŒ€í‘œì´ì‚¬": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "CEO": ["CEO", "ëŒ€í‘œ", "ëŒ€í‘œì´ì‚¬"],
        "ì‚¬ì—…": ["ì‚¬ì—…", "ì—…ì¢…", "ì‚¬ì—…ë¶„ì•¼", "ì‚¬ì—…ë‚´ìš©"],
        "ì‚¬ì—…ë¶„ì•¼": ["ì‚¬ì—…ë¶„ì•¼", "ì‚¬ì—…", "ì—…ì¢…", "ì£¼ìš” ì‚¬ì—…"],
        "ì‚¬ì—…ë‚´ìš©": ["ì‚¬ì—…ë‚´ìš©", "ì‚¬ì—…", "ì—…ì¢…"],
        "ë§¤ì¶œ": ["ë§¤ì¶œ", "ë§¤ì¶œì•¡", "Revenue"],
        "ë§¤ì¶œì•¡": ["ë§¤ì¶œì•¡", "ë§¤ì¶œ", "Revenue"],
        "ì—°ë§¤ì¶œ": ["ì—°ë§¤ì¶œ", "ë§¤ì¶œì•¡", "ë§¤ì¶œ", "ì—°ê°„ë§¤ì¶œ"],
        "ì˜ì—…ì´ìµ": ["ì˜ì—…ì´ìµ", "ì˜ì—…ìµ", "Operating Profit"],
        "ìˆœì´ìµ": ["ìˆœì´ìµ", "ë‹¹ê¸°ìˆœì´ìµ", "Net Profit"],
        "ì„±ê³¼": ["ì„±ê³¼", "ì‹¤ì ", "ì£¼ìš” ì„±ê³¼", "ì„±ê³¼ ì§€í‘œ"],
    }
    
    search_keywords = keywords_map.get(field_name, [field_name])
    
    lines = text.split('\n')
    result = []
    
    for keyword in search_keywords:
        pattern = re.compile(rf'{re.escape(keyword)}[:\s]*([^\n]+)', re.IGNORECASE)
        for line in lines:
            match = pattern.search(line)
            if match:
                value = match.group(1).strip()
                if value and len(value) > 1:
                    result.append(value)
    
    return result[0] if result else "ì •ë³´ ì—†ìŒ"

def generate_report_with_openai(data_dict, report_sections=None, model="gpt-4o-mini", company_id=None, use_rag=True, structured_data=None):
    """RAG ê¸°ë°˜ + êµ¬ì¡°í™”ëœ ë°ì´í„° í™œìš© OpenAI APIë¡œ ì²´ê³„ì ì¸ ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    if not openai_client:
        return "âŒ OpenAI API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”."
    
    # ë³´ê³ ì„œ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if report_sections is None:
        report_sections = st.session_state.get('report_sections', [])
    
    # ì„ íƒëœ ì„¹ì…˜ì— í•´ë‹¹í•˜ëŠ” ì‘ì„± ì§€ì¹¨ë§Œ ì¡°í•©
    selected_guidelines = []
    for section in report_sections:
        if section in REPORT_SECTION_TEMPLATES:
            selected_guidelines.append(REPORT_SECTION_TEMPLATES[section])
    
    report_template = "\n\n".join(selected_guidelines)
    
    # ì‘ì„± ê·œì¹™ ì¶”ê°€
    report_template += """

**ì‘ì„± ê·œì¹™:**
- ê° ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±
- PDFì—ì„œ ì¶”ì¶œí•œ ì •ë³´ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
- PDFì— ì—†ëŠ” ì •ë³´ë¡œ ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ "*> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´ ì™¸ë¶€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€ ìƒì„± (ì¶œì²˜: [ì •ë³´ ì¶œì²˜])*" í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš© (## ì œëª©, **ê°•ì¡°**)
- ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ í†¤ ìœ ì§€
- êµ¬ì²´ì ì¸ ìˆ«ìì™€ ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±"""
    
    # ì¶”ì¶œëœ ë°ì´í„° ì •ë¦¬
    available_data = []
    missing_fields = []
    
    for key, value in data_dict.items():
        if value and value != "ì •ë³´ ì—†ìŒ":
            available_data.append(f"- {key}: {value}")
        else:
            missing_fields.append(key)
    
    if not available_data:
        return "âŒ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    available_data_text = "\n".join(available_data)
    missing_fields_text = ", ".join(missing_fields) if missing_fields else "ì—†ìŒ"
    
    # RAG: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    rag_context = ""
    if use_rag and company_id and supabase_client:
        with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
            # ë³´ê³ ì„œ ì„¹ì…˜ë³„ ì¿¼ë¦¬ ìƒì„±
            queries = [
                f"{company_name} ì¬ë¬´ ì •ë³´ ë§¤ì¶œ ì˜ì—…ì´ìµ",
                f"{company_name} ì‚¬ì—… êµ¬ì¡° ì œí’ˆ ì„œë¹„ìŠ¤",
                f"{company_name} ê²½ìŸì‚¬ ì‹œì¥ ë¶„ì„",
                "ë¦¬ìŠ¤í¬ ìš”ì¸ ìœ„í—˜ ìš”ì†Œ"
            ]
            
            retrieved_contexts = []
            for query in queries:
                context = retrieve_relevant_context(query, company_id=company_id, max_tokens=1000)
                if context and context != "ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.":
                    retrieved_contexts.append(context)
            
            if retrieved_contexts:
                rag_context = "\n\n**ğŸ” ê´€ë ¨ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ (ë²¡í„° ê²€ìƒ‰ ê²°ê³¼):**\n" + "\n\n".join(retrieved_contexts[:2])  # ìƒìœ„ 2ê°œë§Œ
                st.success(f"âœ… {len(retrieved_contexts)}ê°œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ")
    
    # êµ¬ì¡°í™”ëœ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    structured_context = ""
    if structured_data:
        structured_context = "\n\n**ğŸ“Š ë¬¸ì„œ êµ¬ì¡° ì •ë³´ (Upstage Parse):**\n"
        
        # í‘œ ë°ì´í„° ìš”ì•½
        if structured_data.get("tables"):
            structured_context += f"\n[í‘œ ë°ì´í„° {len(structured_data['tables'])}ê°œ ì¸ì‹]\n"
            for idx, table in enumerate(structured_data['tables']):
                structured_context += f"\ní‘œ {idx+1} (í˜ì´ì§€ {table['page']}):\n{table['content'][:800]}\n"
        
        # ë¬¸ì„œ êµ¬ì¡°
        if structured_data.get("headings"):
            structured_context += f"\n[ë¬¸ì„œ êµ¬ì¡° - ì£¼ìš” ì„¹ì…˜]\n"
            for heading in structured_data['headings'][:15]:
                structured_context += f"- {heading['content']}\n"
    
    # ì°¸ê³ ìë£Œ í…ìŠ¤íŠ¸ ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹)
    reference_context = ""
    if st.session_state.get('reference_pdfs'):
        reference_texts = []
        for filename, text in st.session_state.reference_pdfs.items():
            # ê° ì°¸ê³ ìë£Œì—ì„œ ì•ë¶€ë¶„ 2000ìë§Œ ì‚¬ìš© (í† í° ì ˆì•½)
            reference_texts.append(f"[{filename}]\n{text[:2000]}")
        
        reference_context = "\n\n**ì°¸ê³ ìë£Œ (ê²½ìŸì‚¬/ì‚°ì—… ë¶„ì„ ìë£Œ):**\n" + "\n\n---\n\n".join(reference_texts)
    
    try:
        prompt = f"""ë‹¤ìŒ ê¸°ì—… ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**PDFì—ì„œ ì¶”ì¶œëœ ë°ì´í„°:**
{available_data_text}

**PDFì— ì—†ëŠ” ì •ë³´:** {missing_fields_text}

{structured_context}

{rag_context}

{reference_context}

**ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨:**
{report_template}

**ì¤‘ìš”: í‘œ ë°ì´í„°ì˜ ìˆ˜ì¹˜ë¥¼ ì •í™•í•˜ê²Œ ì¸ìš©í•˜ê³ , ë¬¸ì„œ êµ¬ì¡°ë¥¼ ì°¸ê³ í•˜ì—¬ ì²´ê³„ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.**

**ë³´ê³ ì„œ:**"""
        
        response = openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": """ë‹¹ì‹ ì€ ê¸°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

**ì¶œì²˜ í‘œì‹œ ê·œì¹™ (í•„ìˆ˜):**
1. PDFì—ì„œ ì¶”ì¶œí•œ ì›ë³¸ ë°ì´í„°: `[ì¶œì²˜: ë©”ì¸ PDF]`
   ì˜ˆ: "2023ë…„ ë§¤ì¶œì€ 100ì–µì›ì…ë‹ˆë‹¤. [ì¶œì²˜: ë©”ì¸ PDF]"

2. ì°¸ê³ ìë£Œì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´: `[ì¶œì²˜: ì°¸ê³ ìë£Œ - íŒŒì¼ëª…]`
   ì˜ˆ: "ê²½ìŸì‚¬ Aì˜ ì‹œì¥ì ìœ ìœ¨ì€ 30%ì…ë‹ˆë‹¤. [ì¶œì²˜: ì°¸ê³ ìë£Œ - ì‚°ì—…ë¶„ì„.pdf]"

3. PDF ë°ì´í„°ë¥¼ ë¶„ì„/ì¶”ë¡ í•œ ë‚´ìš©: `[ë¶„ì„: ë©”ì¸ PDF ê¸°ë°˜]`
   ì˜ˆ: "ì˜ì—…ì´ìµë¥ ì´ 16%ë¡œ ì´ìë³´ìƒëŠ¥ë ¥ì´ ì–‘í˜¸í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. [ë¶„ì„: ë©”ì¸ PDF ê¸°ë°˜]"

4. AI í•™ìŠµ ë°ì´í„° ê¸°ë°˜ ì¼ë°˜ ì§€ì‹: `[ì¶œì²˜: AI í•™ìŠµ ë°ì´í„° (2023ë…„ 10ì›” ê¸°ì¤€)]`
   ì˜ˆ: "AI ì‚°ì—…ì€ ê¸°ìˆ  ë³€í™”ê°€ ë¹ ë¥¸ íŠ¹ì„±ì´ ìˆìŠµë‹ˆë‹¤. [ì¶œì²˜: AI í•™ìŠµ ë°ì´í„° (2023ë…„ 10ì›” ê¸°ì¤€)]"

5. PDF + AI ì§€ì‹ì„ ì¢…í•© ë¶„ì„: `[ë¶„ì„: ì¢…í•© íŒë‹¨]`
   ì˜ˆ: "ì•ˆì •ì  ìˆ˜ìµì„±ì„ ë³´ìœ í•˜ë‚˜ ê²½ìŸ ì‹¬í™”ë¡œ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤. [ë¶„ì„: ì¢…í•© íŒë‹¨]"

**ì¤‘ìš”:**
- ëª¨ë“  ë¬¸ì¥ì— ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- [ì¶”ì •], [ì˜ˆìƒ] ê°™ì€ ì• ë§¤í•œ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì¶œì²˜ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ ë‚´ìš©ì„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”

íˆ¬ììì™€ ëŒ€ì¶œ ì‹¬ì‚¬ì—­ì´ ì½ê¸°ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤."""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}"

# íƒ€ì´í‹€
st.markdown("""
<div style='
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 20px 40px;
    border-radius: 20px;
    margin-bottom: 30px;
    box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
    text-align: center;
'>
    <div style='
        font-size: 32px;
        font-weight: 800;
        color: white;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        margin-bottom: 8px;
        letter-spacing: -1px;
    '>
        ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°
    </div>
    <div style='
        font-size: 15px;
        color: rgba(255, 255, 255, 0.95);
        font-weight: 500;
        letter-spacing: 0.5px;
    '>
        âœ¨ AI ê¸°ë°˜ ìë™ ì •ë³´ ì¶”ì¶œ ë° ì „ë¬¸ ë³´ê³ ì„œ ì‘ì„± ì‹œìŠ¤í…œ
    </div>
</div>
""", unsafe_allow_html=True)
st.markdown("")

# ì‚¬ì´ë“œë°” - í…œí”Œë¦¿ ì„¤ì •
with st.sidebar:
    st.header("ğŸ“ í…œí”Œë¦¿ ì„¤ì •")
    
    # ì´ì „ ë¶„ì„ ë¶ˆëŸ¬ì˜¤ê¸°
    if supabase_client:
        st.markdown("---")
        with st.expander("ğŸ“‚ ì´ì „ ë¶„ì„ ë¶ˆëŸ¬ì˜¤ê¸°"):
            companies = load_companies_list()
            if companies:
                company_names = [f"{c['company_name']} ({c['created_at'][:10]})" for c in companies]
                selected = st.selectbox("ê¸°ì—… ì„ íƒ", ["ì„ íƒí•˜ì„¸ìš”..."] + company_names)
                
                if selected != "ì„ íƒí•˜ì„¸ìš”...":
                    idx = company_names.index(selected)
                    company_id = companies[idx]["id"]
                    
                    if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
                        loaded_data, loaded_structured_data = load_company_data(company_id)
                        if loaded_data:
                            # ì¶”ì¶œëœ ë°ì´í„° ë¡œë“œ
                            st.session_state.extracted_data = loaded_data
                            
                            # êµ¬ì¡°í™”ëœ ë°ì´í„° ë¡œë“œ (Upstage Parse ê²°ê³¼)
                            if loaded_structured_data:
                                st.session_state.structured_data = loaded_structured_data
                                st.success(f"âœ… êµ¬ì¡°í™”ëœ ë°ì´í„° ë³µì› ì™„ë£Œ! (í‘œ {len(loaded_structured_data.get('tables', []))}ê°œ)")
                            
                            # í…œí”Œë¦¿ ìë™ ìƒì„± (í‚¤ì›Œë“œ ë³µì›)
                            st.session_state.template = []
                            for field_name in loaded_data.keys():
                                # ìˆ«ì ê´€ë ¨ í‚¤ì›Œë“œëŠ” ìˆ«ì íƒ€ì…, ë‚˜ë¨¸ì§€ëŠ” í…ìŠ¤íŠ¸ íƒ€ì…
                                field_type = "ìˆ«ì" if any(keyword in field_name for keyword in ["ë§¤ì¶œ", "ì´ìµ", "ë¹„ìœ¨", "YoY", "CAPEX", "ROE", "EBITDA", "ë¶€ì±„", "í˜„ê¸ˆ"]) else "í…ìŠ¤íŠ¸"
                                st.session_state.template.append({
                                    "name": field_name,
                                    "type": field_type
                                })
                            
                            st.success(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ({len(loaded_data)}ê°œ í‚¤ì›Œë“œ)")
                            st.rerun()
            else:
                st.info("ì €ì¥ëœ ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
    
    # ì¶”ì²œ í‚¤ì›Œë“œ
    st.subheader("ğŸ¯ ì¶”ì²œ í‚¤ì›Œë“œ")
    
    categories = {
        "ğŸ¢ ê¸°ì—… ê¸°ë³¸ ì •ë³´": [
            ("íšŒì‚¬ëª…", "í…ìŠ¤íŠ¸"), ("ê¸°ì—…ëª…", "í…ìŠ¤íŠ¸"), ("ë²•ì¸ëª…", "í…ìŠ¤íŠ¸"), ("ì„¤ë¦½ì¼", "í…ìŠ¤íŠ¸"),
            ("ë³¸ì‚¬ ìœ„ì¹˜", "í…ìŠ¤íŠ¸"), ("ëŒ€í‘œì´ì‚¬", "í…ìŠ¤íŠ¸"), ("CEO", "í…ìŠ¤íŠ¸"), ("ì§ì› ìˆ˜", "í…ìŠ¤íŠ¸"),
            ("ê³„ì—´ì‚¬", "í…ìŠ¤íŠ¸"), ("ì—…ì¢…", "í…ìŠ¤íŠ¸"), ("ì‚°ì—…ë¶„ë¥˜", "í…ìŠ¤íŠ¸"), ("ê¸°ì—… ê·œëª¨", "í…ìŠ¤íŠ¸")
        ],
        "ğŸ’° ì¬ë¬´ì •ë³´": [
            ("ë§¤ì¶œì•¡", "ìˆ«ì"), ("ì˜ì—…ì´ìµ", "ìˆ«ì"), ("ì˜ì—…ì´ìµë¥ ", "ìˆ«ì"), ("ìˆœì´ìµ", "ìˆ«ì"),
            ("EBITDA", "ìˆ«ì"), ("ë¶€ì±„ë¹„ìœ¨", "ìˆ«ì"), ("í˜„ê¸ˆíë¦„", "ìˆ«ì"), ("ROE", "ìˆ«ì"),
            ("CAPEX", "ìˆ«ì"), ("ì „ë…„ ëŒ€ë¹„ ì¦ê°", "ìˆ«ì"), ("YoY", "ìˆ«ì"), ("ë¶„ê¸° ì‹¤ì ", "ìˆ«ì")
        ],
        "ğŸ­ ì‚¬ì—…êµ¬ì¡° & ì œí’ˆ": [
            ("ì‚¬ì—…ë¶„ì•¼", "í…ìŠ¤íŠ¸"), ("ì£¼ìš” ì œí’ˆ", "í…ìŠ¤íŠ¸"), ("í•µì‹¬ ê¸°ìˆ ", "í…ìŠ¤íŠ¸"), ("ê²½ìŸìš°ìœ„", "í…ìŠ¤íŠ¸"),
            ("ì‹œì¥ ì ìœ ìœ¨", "í…ìŠ¤íŠ¸"), ("ê³ ê°ì‚¬", "í…ìŠ¤íŠ¸"), ("ìœ í†µ êµ¬ì¡°", "í…ìŠ¤íŠ¸"), ("í”Œë«í¼", "í…ìŠ¤íŠ¸")
        ],
        "âš”ï¸ ê²½ìŸí™˜ê²½": [
            ("ê²½ìŸì‚¬", "í…ìŠ¤íŠ¸"), ("ì‹œì¥ ê·œëª¨", "í…ìŠ¤íŠ¸"), ("ì‹œì¥ ì„±ì¥ë¥ ", "í…ìŠ¤íŠ¸"), ("ì§„ì…ì¥ë²½", "í…ìŠ¤íŠ¸"),
            ("SWOT ë¶„ì„", "í…ìŠ¤íŠ¸"), ("ê·œì œ ì´ìŠˆ", "í…ìŠ¤íŠ¸"), ("ì‚°ì—… íŠ¸ë Œë“œ", "í…ìŠ¤íŠ¸"), ("CAGR", "í…ìŠ¤íŠ¸")
        ],
        "âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬": [
            ("ì¬ë¬´ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ìš´ì˜ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ê³µê¸‰ë§ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ê¸°ìˆ  ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"),
            ("ê·œì œ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("í™˜ìœ¨ ì˜í–¥", "í…ìŠ¤íŠ¸"), ("ë²•ì  ì´ìŠˆ", "í…ìŠ¤íŠ¸"), ("ESG ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸")
        ],
        "ğŸš€ ê¸°íšŒ ìš”ì¸ & ì „ëµ": [
            ("ì‹ ê·œ ì‚¬ì—…", "í…ìŠ¤íŠ¸"), ("M&A", "í…ìŠ¤íŠ¸"), ("íˆ¬ì ê³„íš", "í…ìŠ¤íŠ¸"), ("ê¸€ë¡œë²Œ ì§„ì¶œ", "í…ìŠ¤íŠ¸"),
            ("R&D", "í…ìŠ¤íŠ¸"), ("ì‹ ì œí’ˆ ì¶œì‹œ", "í…ìŠ¤íŠ¸"), ("ESG ì „ëµ", "í…ìŠ¤íŠ¸"), ("ìˆ˜ìµì„± ê°œì„ ", "í…ìŠ¤íŠ¸")
        ]
    }
    
    for category, keywords in categories.items():
        with st.expander(category):
            cols = st.columns(2)
            for idx, (kw, ftype) in enumerate(keywords):
                col = cols[idx % 2]
                if col.button(f"â• {kw}", key=f"add_{category}_{kw}", use_container_width=True):
                    if not any(f['name'] == kw for f in st.session_state.template):
                        st.session_state.template.append({"name": kw, "type": ftype})
                        st.rerun()
    
    st.markdown("---")
    st.subheader("âœï¸ ì§ì ‘ ì¶”ê°€")
    
    with st.form("add_field_form"):
        field_name = st.text_input("í•„ë“œ ì´ë¦„", placeholder="ì˜ˆ: íšŒì‚¬ì´ë¦„")
        field_type = st.selectbox("ë°ì´í„° íƒ€ì…", ["í…ìŠ¤íŠ¸", "ìˆ«ì"])
        submitted = st.form_submit_button("â• í•„ë“œ ì¶”ê°€", use_container_width=True)
        
        if submitted and field_name:
            if not any(f['name'] == field_name for f in st.session_state.template):
                st.session_state.template.append({"name": field_name, "type": field_type})
                st.rerun()
            else:
                st.warning(f"'{field_name}'ì€(ëŠ”) ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    col1, col2 = st.columns(2)
    if col1.button("ğŸ“‹ ì˜ˆì‹œ ë¡œë“œ", use_container_width=True):
        st.session_state.template = [
            {"name": "íšŒì‚¬ì´ë¦„", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ëŒ€í‘œì´ë¦„", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ì‚¬ì—…ë¶„ì•¼", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ì—°ë§¤ì¶œ", "type": "ìˆ«ì"},
        ]
        st.rerun()
    
    if col2.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.template = []
        st.rerun()

# ============================================
# ë©”ì¸ í™”ë©´ - ì‚¬ìš©ì ë¡œê·¸ì¸ ì²´í¬
# ============================================

# ì‚¬ìš©ì ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¡œê·¸ì¸ í™”ë©´ í‘œì‹œ
if not st.session_state.user_name:
    st.markdown("""
    <div style='text-align: center; padding: 50px 20px;'>
        <h1>ğŸš€ ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°</h1>
        <p style='font-size: 18px; color: #666; margin-bottom: 40px;'>
            AI ê¸°ë°˜ ìë™ ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„± ì‹œìŠ¤í…œ
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # ì¤‘ì•™ ì •ë ¬ëœ ë¡œê·¸ì¸ í¼
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("""
        <div style='background: white; padding: 40px; border-radius: 16px; 
        box-shadow: 0 10px 40px rgba(0,0,0,0.1); border: 2px solid #667eea;'>
        """, unsafe_allow_html=True)
        
        st.markdown("### ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì…ë ¥")
        st.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ë¡œê·¸ ìˆ˜ì§‘ì„ ìœ„í•´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        with st.form("user_login_form"):
            user_name = st.text_input("ì´ë¦„ *", placeholder="í™ê¸¸ë™", key="login_name")
            user_email = st.text_input("ì´ë©”ì¼ (ì„ íƒ)", placeholder="hong@example.com", key="login_email")
            
            col_btn1, col_btn2 = st.columns([1, 1])
            with col_btn1:
                submitted = st.form_submit_button("ğŸš€ ì‹œì‘í•˜ê¸°", use_container_width=True, type="primary")
            
            if submitted:
                if user_name:
                    st.session_state.user_name = user_name
                    st.session_state.user_email = user_email if user_email else None
                    
                    # ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ì¡°íšŒ
                    if supabase_client:
                        user = create_or_get_test_user(user_name, user_email)
                        if user:
                            st.success(f"âœ… {user_name}ë‹˜ í™˜ì˜í•©ë‹ˆë‹¤!")
                            log_activity("user_login", "success", {"name": user_name, "email": user_email})
                            time.sleep(0.5)  # ì„±ê³µ ë©”ì‹œì§€ ë³´ì—¬ì£¼ê¸°
                            st.rerun()
                    else:
                        st.session_state.user_name = user_name
                        st.session_state.user_email = user_email
                        st.success(f"âœ… {user_name}ë‹˜ í™˜ì˜í•©ë‹ˆë‹¤!")
                        time.sleep(0.5)
                        st.rerun()
                else:
                    st.error("âŒ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”")
        
        st.markdown("</div>", unsafe_allow_html=True)
        
        # í•˜ë‹¨ ì„¤ëª…
        st.markdown("---")
        st.markdown("""
        ### âœ¨ ì£¼ìš” ê¸°ëŠ¥
        - ğŸ“„ PDF ìë™ ë¶„ì„ ë° ë°ì´í„° ì¶”ì¶œ
        - ğŸ¤– AI ê¸°ë°˜ ë³´ê³ ì„œ ìë™ ìƒì„±
        - ğŸ’¾ Supabase ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬
        - ğŸ“Š ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘ ë° ëª¨ë‹ˆí„°ë§
        """)
    
    st.stop()  # ë¡œê·¸ì¸ ì „ì—ëŠ” ì•„ë˜ ë‚´ìš© í‘œì‹œ ì•ˆ í•¨

# ============================================
# ë¡œê·¸ì¸ ì™„ë£Œ í›„ - ì‚¬ìš©ì ì •ë³´ í‘œì‹œ (ì‚¬ì´ë“œë°”)
# ============================================
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ‘¤ í˜„ì¬ ì‚¬ìš©ì")
st.sidebar.success(f"âœ… {st.session_state.user_name}ë‹˜")
if st.session_state.user_email:
    st.sidebar.caption(f"ğŸ“§ {st.session_state.user_email}")

if st.sidebar.button("ğŸ”„ ë‹¤ë¥¸ ì‚¬ìš©ìë¡œ ë³€ê²½", use_container_width=True):
    st.session_state.user_name = None
    st.session_state.user_email = None
    st.session_state.session_id = str(uuid.uuid4())
    st.session_state.current_test_session_id = None
    st.rerun()

# ============================================
# ë©”ì¸ ì•±
# ============================================

# ë©”ì¸ ì˜ì—­ - ê´€ë¦¬ì íƒ­ì€ íŠ¹ì • ì‚¬ìš©ìì—ê²Œë§Œ í‘œì‹œ
is_admin = (st.session_state.user_name == "ì‹ ë´‰ê·œ" and 
            st.session_state.user_email == "shinbonggyu@daum.net")

if is_admin:
    tab1, tab2, tab3, tab_admin = st.tabs(["ğŸ“‹ í…œí”Œë¦¿ ëª©ë¡", "ğŸ” ë°ì´í„° ì¶”ì¶œ", "ğŸ“„ ë³´ê³ ì„œ ìƒì„±", "ğŸ”§ ê´€ë¦¬ì"])
else:
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ í…œí”Œë¦¿ ëª©ë¡", "ğŸ” ë°ì´í„° ì¶”ì¶œ", "ğŸ“„ ë³´ê³ ì„œ ìƒì„±"])

with tab1:
    st.subheader("ğŸ“‹ í˜„ì¬ í…œí”Œë¦¿ ëª©ë¡")
    
    if st.session_state.template:
        st.markdown(f"**ì´ {len(st.session_state.template)}ê°œ í•„ë“œ**")
        
        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ (ì¶”ì²œ í‚¤ì›Œë“œì²˜ëŸ¼)
        cols = st.columns(4)  # í•œ ì¤„ì— 4ê°œ
        for idx, field in enumerate(st.session_state.template):
            col = cols[idx % 4]
            type_icon = "ğŸ”¢" if field['type'] == "ìˆ«ì" else "ğŸ“"
            
            with col:
                # í‚¤ì›Œë“œëª…ê³¼ X ë²„íŠ¼ì„ í•œ ì¤„ë¡œ í‘œì‹œ
                button_col1, button_col2 = st.columns([4, 1])
                with button_col1:
                    st.markdown(f"""
                    <div style='
                        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                        color: white;
                        padding: 10px 15px;
                        border-radius: 12px;
                        font-size: 13px;
                        font-weight: 500;
                        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                        margin-bottom: 10px;
                        text-align: left;
                    '>
                        {type_icon} {field['name']}
                    </div>
                    """, unsafe_allow_html=True)
                with button_col2:
                    if st.button("âœ•", key=f"delete_{idx}", help="ì‚­ì œ", use_container_width=True):
                        st.session_state.template.pop(idx)
                        st.rerun()
    else:
        st.info("í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

with tab2:
    st.subheader("ğŸ” ë°ì´í„° ì¶”ì¶œ")
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  AIê°€ ìë™ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
    
    # Upstage API ìƒíƒœ í‘œì‹œ
    if check_upstage_available():
        st.success("ğŸš€ Upstage Document Parse ì—°ê²°ë¨ - í‘œ êµ¬ì¡° ì¸ì‹ ê°€ëŠ¥!")
    else:
        st.warning("âš ï¸ Upstage API ë¯¸ì„¤ì • - ê¸°ë³¸ í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ ê°€ëŠ¥")
    
    # ë©”ì¸ PDF ì—…ë¡œë“œ
    st.markdown("### ğŸ“„ ê¸°ì—… ë³´ê³ ì„œ (í•„ìˆ˜)")
    uploaded_file = st.file_uploader("ê¸°ì—… ì‚¬ì—…ë³´ê³ ì„œ PDF ì—…ë¡œë“œ", type=['pdf'], key="main_pdf")
    
    # ê³ ê¸‰ ë¶„ì„ ì˜µì…˜ - ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½í•˜ê³  ê°•ì¡°
    st.markdown("---")
    st.markdown("### âš™ï¸ ì¶”ì¶œ ì˜µì…˜")
    
    use_ocr_mode = st.checkbox(
        "ğŸ“Š í‘œ êµ¬ì¡° ì¸ì‹ ëª¨ë“œ (Upstage Document Parse) ğŸ”¥ ê¶Œì¥",
        value=True,  # ê¸°ë³¸ê°’ Trueë¡œ ë³€ê²½
        help="â­ ì¬ë¬´ì œí‘œ, ì‹¤ì  ë°ì´í„°ê°€ í¬í•¨ëœ PDFëŠ” ë°˜ë“œì‹œ í™œì„±í™”í•˜ì„¸ìš”! í‘œë¥¼ ì¸ì‹í•˜ì§€ ëª»í•˜ë©´ ì˜ì—…ì´ìµ, ë§¤ì¶œì•¡ ë“±ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    )
    
    if not use_ocr_mode:
        st.warning("âš ï¸ í‘œ êµ¬ì¡° ì¸ì‹ì„ ë¹„í™œì„±í™”í•˜ë©´ ì¬ë¬´ ë°ì´í„° ì¶”ì¶œ ì„±ê³µë¥ ì´ ë‚®ì•„ì§‘ë‹ˆë‹¤.")
    else:
        st.success("âœ… í‘œ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ì •í™•í•œ ë°ì´í„° ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
    
    # ì°¸ê³ ìë£Œ PDF ì—…ë¡œë“œ (RAG)
    st.markdown("---")
    st.markdown("### ğŸ“š ì°¸ê³ ìë£Œ ì¶”ê°€ (ì„ íƒ)")
    st.info("ğŸ’¡ ê²½ìŸì‚¬ ìë£Œ, ì‚°ì—… ë¦¬í¬íŠ¸, ì‹œì¥ ë¶„ì„ ìë£Œ ë“±ì„ ì¶”ê°€í•˜ë©´ ë” ì •í™•í•œ ë³´ê³ ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    
    reference_files = st.file_uploader(
        "ì°¸ê³ ìë£Œ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", 
        type=['pdf'], 
        accept_multiple_files=True,
        key="reference_pdfs_upload"
    )
    
    # ì°¸ê³ ìë£Œ ì²˜ë¦¬
    if reference_files:
        st.markdown("**ğŸ“‹ ì—…ë¡œë“œëœ ì°¸ê³ ìë£Œ:**")
        for ref_file in reference_files:
            st.markdown(f"- {ref_file.name}")
    
    st.markdown("---")
    
    # ì‚¬ìš©ì ì •ë³´ í™•ì¸
    if not st.session_state.user_name:
        st.warning("âš ï¸ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    elif uploaded_file and st.button("ğŸš€ ë°ì´í„° ì¶”ì¶œ ì‹œì‘", type="primary"):
        if not st.session_state.template:
            st.error("âŒ í…œí”Œë¦¿ì„ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”! ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            # í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘
            session_start_time = time.time()
            company_name_temp = "Unknown"
            
            try:
                # ì‚¬ìš©ì ID ê°€ì ¸ì˜¤ê¸°
                user = create_or_get_test_user(st.session_state.user_name, st.session_state.user_email)
                user_id = user['id'] if user else None
                
                # ì„¸ì…˜ ì‹œì‘ ë¡œê·¸
                if user_id:
                    start_test_session(user_id, "ì²˜ë¦¬ ì¤‘", uploaded_file.name)
                
                # PDF ì²˜ë¦¬ ì‹œì‘
                log_activity("pdf_upload", "started", {"filename": uploaded_file.name, "ocr_mode": use_ocr_mode})
                
                with st.spinner("ğŸ“„ PDF ì²˜ë¦¬ ì¤‘..."):
                    pdf_start = time.time()
                    # ë©”ì¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    pdf_text, num_pages = extract_text_from_pdf(uploaded_file, max_pages=50, use_ocr=use_ocr_mode)
                    st.session_state.pdf_text = pdf_text
                    pdf_time = int((time.time() - pdf_start) * 1000)
                    
                    log_activity("pdf_upload", "success", {
                        "filename": uploaded_file.name,
                        "pages": num_pages,
                        "text_length": len(pdf_text)
                    }, pdf_time)
                    
                    # ì°¸ê³ ìë£Œ PDF ì²˜ë¦¬
                    st.session_state.reference_pdfs = {}
                    if reference_files:
                        with st.spinner(f"ğŸ“š ì°¸ê³ ìë£Œ {len(reference_files)}ê°œ ì²˜ë¦¬ ì¤‘..."):
                            for ref_file in reference_files:
                                ref_text, ref_pages = extract_text_from_pdf(ref_file, max_pages=50, use_ocr=use_ocr_mode)
                                if ref_text:
                                    st.session_state.reference_pdfs[ref_file.name] = ref_text
                                    st.success(f"âœ… {ref_file.name} ì²˜ë¦¬ ì™„ë£Œ ({ref_pages}í˜ì´ì§€, {len(ref_text)}ì)")
                    
                    if pdf_text:
                        st.success(f"âœ… ë©”ì¸ PDF {num_pages}í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ (ì´ {len(pdf_text)}ì ì¶”ì¶œ)")
                        
                        # ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (êµ¬ì¡°í™”ëœ ë°ì´í„° í™œìš©)
                        with st.spinner("ğŸ” ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
                            extract_start = time.time()
                            field_names = [field['name'] for field in st.session_state.template]
                            
                            log_activity("keyword_extraction", "started", {"fields": field_names})
                            
                            # êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì „ë‹¬
                            structured_data = st.session_state.get('structured_data')
                            if structured_data:
                                st.info(f"ğŸ“Š êµ¬ì¡°í™”ëœ ë°ì´í„° í™œìš©: í‘œ {len(structured_data.get('tables', []))}ê°œ, ì œëª© {len(structured_data.get('headings', []))}ê°œ")
                            
                            extracted_data = extract_all_keywords_batch(pdf_text, field_names, structured_data=structured_data)
                            st.session_state.extracted_data = extracted_data
                            extract_time = int((time.time() - extract_start) * 1000)
                            
                            # íšŒì‚¬ëª… ì¶”ì¶œ
                            company_name_temp = extracted_data.get("íšŒì‚¬ëª…") or extracted_data.get("ê¸°ì—…ëª…") or "Unknown"
                            
                            log_activity("keyword_extraction", "success", {
                                "fields_count": len(field_names),
                                "extracted_count": len(extracted_data),
                                "company_name": company_name_temp
                            }, extract_time)
                            
                            # ğŸ†• ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ê¸°ë¡ - OCR vs LLM ì¶”ì¶œ ë¹„êµ
                            log_data_quality(
                                selected_keywords=field_names,
                                ocr_raw_text=pdf_text,
                                ocr_structured_data=structured_data,
                                llm_extracted_data=extracted_data,
                                llm_extraction_time_ms=extract_time,
                                company_name=company_name_temp,
                                pdf_filename=uploaded_file.name,
                                pdf_pages=num_pages
                            )
                        
                        # Supabaseì— ì €ì¥
                        if supabase_client:
                            with st.spinner("ğŸ’¾ Supabaseì— ì €ì¥ ì¤‘..."):
                                save_start = time.time()
                                log_activity("data_save", "started")
                                
                                company_id = save_to_supabase(
                                    company_name=company_name_temp,
                                    pdf_file=uploaded_file,
                                    extracted_text=pdf_text,
                                    extracted_data=extracted_data
                                )
                                save_time = int((time.time() - save_start) * 1000)
                                
                                if company_id:
                                    st.success("âœ… Supabase ì €ì¥ ì™„ë£Œ!")
                                    log_activity("data_save", "success", {"company_id": str(company_id)}, save_time)
                                else:
                                    log_activity("data_save", "failed", {"error": "company_id is None"}, save_time)
                        
                        # ì„¸ì…˜ ì™„ë£Œ ë¡œê·¸
                        total_time = int((time.time() - session_start_time) * 1000)
                        complete_test_session("success", execution_time_ms=total_time)
                        
                        # ì„¸ì…˜ ì—…ë°ì´íŠ¸ (íšŒì‚¬ëª…)
                        if st.session_state.current_test_session_id:
                            try:
                                supabase_client.table("test_sessions").update({
                                    "company_name": company_name_temp
                                }).eq("id", st.session_state.current_test_session_id).execute()
                            except:
                                pass
                        
                        # ê²°ê³¼ í‘œì‹œ - Gradio ìŠ¤íƒ€ì¼ë¡œ
                        st.markdown("---")
                        st.markdown("## âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                        st.markdown("### ğŸ¤– AIê°€ ìë™ìœ¼ë¡œ ì¶”ì¶œí•œ ì •ë³´")
                        
                        # ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                        for field in st.session_state.template:
                            value = extracted_data.get(field['name'], "ì •ë³´ ì—†ìŒ")
                            st.markdown(f"**ğŸ“Œ {field['name']}**")
                            st.markdown(f"""
                            <div style='padding: 10px; background: white; border-radius: 8px; 
                            margin-bottom: 15px; border: 1px solid #e2e8f0;'>
                            {value}
                            </div>
                            """, unsafe_allow_html=True)
                        
                        # ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ
                        st.markdown("---")
                        st.markdown("### ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ (ì „ì²´)")
                        st.markdown(f"""
                        <div style='background: #f8fafc; padding: 15px; border-radius: 8px; 
                        font-family: monospace; font-size: 13px; line-height: 1.6; 
                        max-height: 600px; overflow-y: auto;'>
                        {pdf_text}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.error("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        log_error("pdf_upload", Exception("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨"))
                        complete_test_session("failed", "PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            
            except Exception as e:
                st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                error_trace = traceback.format_exc()
                with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´"):
                    st.code(error_trace)
                
                log_error("data_extraction", e, error_trace)
                complete_test_session("failed", str(e))
    
    # ì´ë¯¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ (ìƒˆë¡œ ì¶”ì¶œí•˜ê±°ë‚˜ ì´ì „ ë¶„ì„ ë¶ˆëŸ¬ì˜¨ ê²½ìš°)
    elif st.session_state.extracted_data:
        st.markdown("---")
        
        # ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ì¸ì§€ í™•ì¸
        if st.session_state.pdf_text:
            st.markdown("## âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        else:
            st.markdown("## ğŸ“‚ ë¶ˆëŸ¬ì˜¨ ë¶„ì„ ë°ì´í„°")
            st.info("ğŸ’¡ ì´ì „ì— ë¶„ì„í•œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤. ë°”ë¡œ ë³´ê³ ì„œ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!")
            
            # êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ ë²„íŠ¼ í‘œì‹œ
            if st.session_state.get('structured_data'):
                st.markdown("### ğŸ”„ ì¶”ê°€ ë¶„ì„")
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.info("ğŸ“Š êµ¬ì¡°í™”ëœ ë¬¸ì„œ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í‚¤ì›Œë“œë¥¼ í…œí”Œë¦¿ì— ì¶”ê°€í•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”!")
                with col2:
                    if st.button("â• ì¶”ê°€ í‚¤ì›Œë“œ ì¶”ì¶œ", type="primary"):
                        # ê¸°ì¡´ í…œí”Œë¦¿ê³¼ ì¶”ì¶œëœ ë°ì´í„° ë¹„êµ
                        template_fields = {field['name'] for field in st.session_state.template}
                        existing_fields = set(st.session_state.extracted_data.keys())
                        new_fields = list(template_fields - existing_fields)
                        
                        if new_fields:
                            with st.spinner(f"ğŸ” {len(new_fields)}ê°œ ìƒˆ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
                                # PDF í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¬êµ¬ì„±
                                if not st.session_state.pdf_text:
                                    structured_data = st.session_state.structured_data
                                    reconstructed_text = ""
                                    
                                    # í‘œ ë°ì´í„° ì¶”ê°€
                                    for table in structured_data.get('tables', []):
                                        reconstructed_text += f"\n{table['content']}\n"
                                    
                                    # ë¬¸ë‹¨ ë°ì´í„° ì¶”ê°€
                                    for para in structured_data.get('paragraphs', [])[:50]:
                                        reconstructed_text += f"{para['content']}\n"
                                    
                                    st.session_state.pdf_text = reconstructed_text
                                
                                # ìƒˆ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
                                new_extracted = extract_all_keywords_batch(
                                    st.session_state.pdf_text,
                                    new_fields,
                                    structured_data=st.session_state.structured_data
                                )
                                
                                # ê¸°ì¡´ ë°ì´í„°ì— ë³‘í•©
                                st.session_state.extracted_data.update(new_extracted)
                                st.success(f"âœ… {len(new_fields)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ! (API ë¹„ìš© ì ˆê°)")
                                st.rerun()
                        else:
                            st.warning("âš ï¸ ì¶”ì¶œí•  ìƒˆ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. í…œí”Œë¦¿ì— í‚¤ì›Œë“œë¥¼ ë¨¼ì € ì¶”ê°€í•˜ì„¸ìš”!")
        
        st.markdown("### ğŸ¤– ì¶”ì¶œëœ ì •ë³´")
        
        # í…œí”Œë¦¿ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í…œí”Œë¦¿ ìˆœì„œëŒ€ë¡œ, ì—†ìœ¼ë©´ ì „ì²´ í‘œì‹œ
        if st.session_state.template:
            for field in st.session_state.template:
                value = st.session_state.extracted_data.get(field['name'], "ì •ë³´ ì—†ìŒ")
                st.markdown(f"**ğŸ“Œ {field['name']}**")
                st.markdown(f"""
                <div style='padding: 10px; background: white; border-radius: 8px; 
                margin-bottom: 15px; border: 1px solid #e2e8f0;'>
                {value}
                </div>
                """, unsafe_allow_html=True)
        else:
            # í…œí”Œë¦¿ ì—†ìœ¼ë©´ ëª¨ë“  ë°ì´í„° í‘œì‹œ
            for key, value in st.session_state.extracted_data.items():
                st.markdown(f"**ğŸ“Œ {key}**")
                st.markdown(f"""
                <div style='padding: 10px; background: white; border-radius: 8px; 
                margin-bottom: 15px; border: 1px solid #e2e8f0;'>
                {value}
                </div>
                """, unsafe_allow_html=True)
        
        # êµ¬ì¡°í™”ëœ ë°ì´í„° ì •ë³´ í‘œì‹œ (í‘œ/ì°¨íŠ¸)
        if st.session_state.get('structured_data'):
            structured_data = st.session_state.structured_data
            table_count = len(structured_data.get("tables", []))
            chart_count = len(structured_data.get("charts", []))
            
            st.markdown("---")
            st.markdown("### ğŸ“Š êµ¬ì¡°í™”ëœ ë°ì´í„° ë¶„ì„ ê²°ê³¼")
            
            # í‘œ ì •ë³´
            if table_count > 0:
                with st.expander(f"ğŸ“Š ì¸ì‹ëœ í‘œ ì •ë³´ ({table_count}ê°œ)", expanded=False):
                    for idx, table in enumerate(structured_data["tables"], 1):
                        st.write(f"**í‘œ {idx} (í˜ì´ì§€ {table.get('page', '?')})**")
                        table_content = table.get('html', '') or table.get('markdown', '') or table.get('content', '')
                        if table_content:
                            st.text(table_content[:300] + ("..." if len(table_content) > 300 else ""))
                        st.markdown("---")
            
            # ì°¨íŠ¸ ì •ë³´
            if chart_count > 0:
                with st.expander(f"ğŸ“ˆ ì¸ì‹ëœ ì°¨íŠ¸/ê·¸ë˜í”„ ì •ë³´ ({chart_count}ê°œ)", expanded=False):
                    for idx, chart in enumerate(structured_data["charts"], 1):
                        st.write(f"**ì°¨íŠ¸ {idx} (í˜ì´ì§€ {chart.get('page', '?')}) - {chart.get('category', 'unknown')}**")
                        chart_content = chart.get('content', '') or chart.get('html', '')
                        if chart_content:
                            st.text(chart_content[:300] + ("..." if len(chart_content) > 300 else ""))
                        st.markdown("---")
        
        # ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ (ìƒˆë¡œ ì¶”ì¶œí•œ ê²½ìš°)
        if st.session_state.pdf_text:
            st.markdown("---")
            st.markdown("### ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ (ì „ì²´)")
            st.markdown(f"""
            <div style='background: #f8fafc; padding: 15px; border-radius: 8px; 
            font-family: monospace; font-size: 13px; line-height: 1.6; 
            max-height: 600px; overflow-y: auto;'>
            {st.session_state.pdf_text}
            </div>
            """, unsafe_allow_html=True)

with tab3:
    st.subheader("ğŸ“„ ë³´ê³ ì„œ ìƒì„±")
    st.info("AIê°€ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤")
    
    if not st.session_state.extracted_data:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì¶”ì¶œ' íƒ­ì—ì„œ PDF ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.")
    else:
        st.markdown("### ğŸ“Š ì¶”ì¶œëœ ë°ì´í„° í™•ì¸")
        
        # í…œí”Œë¦¿ ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œ (í…œí”Œë¦¿ì— ìˆëŠ” í‚¤ì›Œë“œë§Œ)
        if st.session_state.template:
            displayed_count = 0
            for field in st.session_state.template:
                field_name = field['name']
                if field_name in st.session_state.extracted_data:
                    value = st.session_state.extracted_data[field_name]
                    st.markdown(f"**{field_name}**: {value}")
                    displayed_count += 1
            
            # í…œí”Œë¦¿ì— ì—†ëŠ” í‚¤ì›Œë“œë„ í‘œì‹œí• ì§€ í™•ì¸
            all_keys = set(st.session_state.extracted_data.keys())
            template_keys = {field['name'] for field in st.session_state.template}
            extra_keys = all_keys - template_keys
            
            if extra_keys:
                with st.expander(f"â• í…œí”Œë¦¿ì— ì—†ëŠ” ì¶”ê°€ ë°ì´í„° ({len(extra_keys)}ê°œ)"):
                    for key in extra_keys:
                        st.markdown(f"**{key}**: {st.session_state.extracted_data[key]}")
        else:
            # í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ëª¨ë“  ë°ì´í„° í‘œì‹œ
            for key, value in st.session_state.extracted_data.items():
                st.markdown(f"**{key}**: {value}")
        
        st.markdown("---")
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            if st.button("ğŸ“‹ ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°", type="secondary"):
                report_start = time.time()
                log_activity("report_generation", "started", {
                    "sections_count": len(st.session_state.get('report_sections', []))
                })
                
                with st.spinner("âœ¨ OpenAIë¡œ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                    try:
                        # êµ¬ì¡°í™”ëœ ë°ì´í„° ì „ë‹¬
                        structured_data = st.session_state.get('structured_data')
                        
                        report = generate_report_with_openai(
                            data_dict=st.session_state.extracted_data,
                            report_sections=st.session_state.get('report_sections'),
                            structured_data=structured_data
                        )
                        
                        # ì°¸ê³ ìë£Œ ì •ë³´ ì¶”ê°€
                        if st.session_state.get('reference_pdfs'):
                            ref_list = list(st.session_state.reference_pdfs.keys())
                            report += f"\n\n---\n\n**ğŸ“š ì°¸ê³ ìë£Œ ëª©ë¡:**\n"
                            for ref_file in ref_list:
                                report += f"- {ref_file}\n"
                        
                        # êµ¬ì¡° ì •ë³´ ì¶”ê°€
                        if structured_data:
                            report += f"\n\n**ğŸ“Š ë¬¸ì„œ ë¶„ì„ ì •ë³´ (Upstage Parse):**\n"
                            report += f"- í‘œ {len(structured_data.get('tables', []))}ê°œ ì¸ì‹\n"
                            report += f"- ì„¹ì…˜ {len(structured_data.get('headings', []))}ê°œ êµ¬ì¡°í™”\n"
                        
                        # ë³´ê³ ì„œë¥¼ ì„¸ì…˜ì— ì €ì¥
                        st.session_state.report = report
                        
                        report_time = int((time.time() - report_start) * 1000)
                        log_activity("report_generation", "success", {
                            "report_length": len(report),
                            "sections": st.session_state.get('report_sections', [])
                        }, report_time)
                        
                        # ğŸ†• ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì—…ë°ì´íŠ¸ - ë³´ê³ ì„œ ìƒì„± ë°ì´í„° ì¶”ê°€
                        if st.session_state.current_test_session_id:
                            # ê¸°ì¡´ ë¡œê·¸ë¥¼ ì°¾ì•„ì„œ ì—…ë°ì´íŠ¸
                            try:
                                logs = supabase_client.table("data_quality_logs")\
                                    .select("*")\
                                    .eq("session_id", st.session_state.current_test_session_id)\
                                    .order("created_at", desc=True)\
                                    .limit(1)\
                                    .execute()
                                
                                if logs.data and len(logs.data) > 0:
                                    latest_log = logs.data[0]
                                    supabase_client.table("data_quality_logs").update({
                                        "report_generated": True,
                                        "report_content": report[:20000],  # ì²˜ìŒ 20000ìë§Œ ì €ì¥
                                        "report_model": "gpt-4o-mini",
                                        "report_generation_time_ms": report_time
                                    }).eq("id", latest_log['id']).execute()
                                    print(f"âœ… ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {latest_log['id']}")
                            except Exception as e:
                                print(f"âš ï¸ ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                        
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                        error_trace = traceback.format_exc()
                        log_error("report_generation", e, error_trace)
                        with st.expander("ğŸ” ìƒì„¸ ì—ëŸ¬ ì •ë³´"):
                            st.code(error_trace)
        
        with col2:
            if st.button("ğŸ“„ ë³´ê³ ì„œ ìƒì„± (DOCX)", type="primary"):
                if 'report' not in st.session_state or not st.session_state.report:
                    st.error("âŒ ë¨¼ì € 'ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°' ë²„íŠ¼ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.")
                else:
                    try:
                        # DOCX ìƒì„±
                        doc = Document()
                        
                        # ì œëª©
                        title = doc.add_heading('ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ', 0)
                        title.alignment = 1  # ì¤‘ì•™ ì •ë ¬
                        
                        # ì‘ì„±ì¼
                        date_para = doc.add_paragraph(f'ì‘ì„±ì¼: {datetime.now().strftime("%Yë…„ %mì›” %dì¼")}')
                        date_para.alignment = 1
                        doc.add_paragraph('')
                        
                        # ë³´ê³ ì„œ ë‚´ìš© íŒŒì‹± ë° ì¶”ê°€
                        lines = st.session_state.report.split('\n')
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                            
                            # ì œëª© ì²˜ë¦¬ (## ì‹œì‘)
                            if line.startswith('## '):
                                doc.add_heading(line.replace('## ', ''), 1)
                            elif line.startswith('### '):
                                doc.add_heading(line.replace('### ', ''), 2)
                            # ë³¼ë“œ ì²˜ë¦¬ (**í…ìŠ¤íŠ¸**)
                            elif line.startswith('**') and line.endswith('**'):
                                p = doc.add_paragraph()
                                p.add_run(line.strip('*')).bold = True
                            # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
                            elif line.startswith('- ') or line.startswith('* '):
                                doc.add_paragraph(line[2:], style='List Bullet')
                            # ì¼ë°˜ ë¬¸ë‹¨
                            else:
                                doc.add_paragraph(line)
                        
                        doc.add_paragraph('')
                        doc.add_paragraph('â”€' * 50)
                        doc.add_paragraph('')
                        
                        # ì¶”ì¶œëœ ë°ì´í„° í…Œì´ë¸”
                        doc.add_heading('ğŸ“‹ ì¶”ì¶œëœ ìƒì„¸ ë°ì´í„°', 1)
                        
                        table = doc.add_table(rows=1, cols=2)
                        table.style = 'Light Grid Accent 1'
                        
                        hdr = table.rows[0].cells
                        hdr[0].text = 'í•­ëª©'
                        hdr[1].text = 'ë‚´ìš©'
                        
                        for key, val in st.session_state.extracted_data.items():
                            row = table.add_row().cells
                            row[0].text = key
                            row[1].text = str(val)
                        
                        # íŒŒì¼ ì €ì¥
                        output_path = "ê¸°ì—…_ë¶„ì„_ë³´ê³ ì„œ.docx"
                        doc.save(output_path)
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                        with open(output_path, "rb") as file:
                            st.download_button(
                                label="ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                data=file,
                                file_name=f"ê¸°ì—…_ë¶„ì„_ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                        
                        st.success("âœ… DOCX ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                    except Exception as e:
                        st.error(f"âŒ DOCX ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        with col3:
            if st.button("âš™ï¸ í…œí”Œë¦¿", help="ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨ ìˆ˜ì •"):
                st.session_state.show_template_editor = not st.session_state.show_template_editor
                st.rerun()
        
        # ë³´ê³ ì„œ í…œí”Œë¦¿ í¸ì§‘ê¸°
        if st.session_state.show_template_editor:
            st.markdown("---")
            st.markdown("### âš™ï¸ ë³´ê³ ì„œ ì„¹ì…˜ ì„ íƒ")
            st.info("ğŸ’¡ ì›í•˜ëŠ” ë³´ê³ ì„œ ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”. ì„ íƒí•œ ì„¹ì…˜ë§Œ ë³´ê³ ì„œì— í¬í•¨ë©ë‹ˆë‹¤.")
            
            # ëª¨ë“  ì„¹ì…˜ ì²´í¬ë°•ìŠ¤
            available_sections = [
                "ê¸°ì—… ê°œìš”",
                "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„",
                "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„",
                "ì¬ë¬´ ìš”ì•½",
                "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„",
                "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„",
                "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„",
                "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„",
                "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬",
                "ë¦¬ìŠ¤í¬ ìš”ì¸",
                "ì¢…í•© í‰ê°€"
            ]
            
            # 2ì—´ë¡œ ë°°ì¹˜
            cols = st.columns(2)
            selected_sections = []
            
            for idx, section in enumerate(available_sections):
                col = cols[idx % 2]
                with col:
                    is_selected = st.checkbox(
                        section,
                        value=section in st.session_state.report_sections,
                        key=f"section_{section}"
                    )
                    if is_selected:
                        selected_sections.append(section)
            
            col_save, col_reset = st.columns(2)
            with col_save:
                if st.button("ğŸ’¾ ì„ íƒ ì €ì¥", type="primary", use_container_width=True):
                    st.session_state.report_sections = selected_sections
                    st.success(f"âœ… {len(selected_sections)}ê°œ ì„¹ì…˜ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            with col_reset:
                if st.button("ğŸ”„ ì „ì²´ ì„ íƒ", use_container_width=True):
                    st.session_state.report_sections = available_sections.copy()
                    st.success("âœ… ëª¨ë“  ì„¹ì…˜ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
            
            # ì„ íƒëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
            if selected_sections:
                with st.expander("ğŸ“‹ ì„ íƒëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    for section in selected_sections:
                        st.markdown(f"**âœ“ {section}**")
                        if section in REPORT_SECTION_TEMPLATES:
                            st.text(REPORT_SECTION_TEMPLATES[section])
                        st.markdown("---")
        
        # ìƒì„±ëœ ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ
        if 'report' in st.session_state and st.session_state.report:
            st.markdown("---")
            st.markdown("### ğŸ“„ ìƒì„±ëœ ë³´ê³ ì„œ")
            st.markdown(st.session_state.report)

# ============================================
# ê´€ë¦¬ì í˜ì´ì§€
# ============================================
if is_admin:
    with tab_admin:
        st.subheader("ğŸ”§ ê´€ë¦¬ì í˜ì´ì§€")
        
        # ë¹„ë°€ë²ˆí˜¸ í™•ì¸
        if 'admin_logged_in' not in st.session_state:
            st.session_state.admin_logged_in = False
        
        if not st.session_state.admin_logged_in:
            st.info("ğŸ”’ ê´€ë¦¬ì í˜ì´ì§€ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            admin_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="admin_password")
            
            if st.button("ë¡œê·¸ì¸"):
                # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¹„ë°€ë²ˆí˜¸ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: admin123)
                correct_password = os.getenv("ADMIN_PASSWORD", "admin123")
                if admin_password == correct_password:
                    st.session_state.admin_logged_in = True
                    st.rerun()
                else:
                    st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ìŠµë‹ˆë‹¤")
        else:
            st.success("âœ… ê´€ë¦¬ì ë¡œê·¸ì¸ë¨")
            
            if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ"):
                st.session_state.admin_logged_in = False
                st.rerun()
            
            st.markdown("---")
            
            if not supabase_client:
                st.warning("âš ï¸ Supabaseê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ë¡œê·¸ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            else:
                # íƒ­ êµ¬ì„±
                admin_tab1, admin_tab2, admin_tab3, admin_tab4 = st.tabs(["ğŸ“Š í†µê³„", "ğŸ‘¥ ì‚¬ìš©ì ëª©ë¡", "ğŸ“‹ ë¡œê·¸ ì¡°íšŒ", "ğŸ” ë°ì´í„° í’ˆì§ˆ ë¹„êµ"])
                
                with admin_tab1:
                    st.markdown("### ğŸ“Š í…ŒìŠ¤íŠ¸ í†µê³„")
                    
                    try:
                        # ì „ì²´ ì„¸ì…˜ ìˆ˜
                        sessions = supabase_client.table("test_sessions").select("*").execute()
                        total_sessions = len(sessions.data) if sessions.data else 0
                        
                        # ì„±ê³µ/ì‹¤íŒ¨ ì„¸ì…˜
                        success_sessions = len([s for s in sessions.data if s.get('status') == 'success']) if sessions.data else 0
                        failed_sessions = len([s for s in sessions.data if s.get('status') == 'failed']) if sessions.data else 0
                        in_progress = len([s for s in sessions.data if s.get('status') == 'in_progress']) if sessions.data else 0
                        
                        # ì‚¬ìš©ì ìˆ˜
                        users = supabase_client.table("test_users").select("*").execute()
                        total_users = len(users.data) if users.data else 0
                        
                        # ë©”íŠ¸ë¦­ í‘œì‹œ
                        col1, col2, col3, col4 = st.columns(4)
                        col1.metric("ğŸ‘¥ ì´ ì‚¬ìš©ì", total_users)
                        col2.metric("ğŸ“ ì´ ì„¸ì…˜", total_sessions)
                        col3.metric("âœ… ì„±ê³µ", success_sessions)
                        col4.metric("âŒ ì‹¤íŒ¨", failed_sessions)
                        
                        if in_progress > 0:
                            st.info(f"â³ ì§„í–‰ ì¤‘ì¸ ì„¸ì…˜: {in_progress}ê°œ")
                        
                        # ì„±ê³µë¥ 
                        if total_sessions > 0:
                            success_rate = (success_sessions / total_sessions) * 100
                            st.progress(success_rate / 100)
                            st.caption(f"ì„±ê³µë¥ : {success_rate:.1f}%")
                        
                    except Exception as e:
                        st.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
                with admin_tab2:
                    st.markdown("### ğŸ‘¥ ì‚¬ìš©ì ëª©ë¡")
                    
                    try:
                        users = supabase_client.table("test_users").select("*").order("created_at", desc=True).execute()
                        
                        if users.data:
                            for user in users.data:
                                with st.expander(f"ğŸ‘¤ {user.get('name', 'Unknown')} ({user.get('email', 'N/A')})"):
                                    st.write(f"**ì„¸ì…˜ ID**: `{user.get('session_id', 'N/A')}`")
                                    st.write(f"**ê°€ì…ì¼**: {user.get('created_at', 'N/A')}")
                                    
                                    # í•´ë‹¹ ì‚¬ìš©ìì˜ ì„¸ì…˜ ì¡°íšŒ
                                    user_sessions = supabase_client.table("test_sessions").select("*").eq("user_id", user['id']).order("started_at", desc=True).execute()
                                    
                                    if user_sessions.data:
                                        st.write(f"**ì´ ì„¸ì…˜ ìˆ˜**: {len(user_sessions.data)}")
                                        for session in user_sessions.data[:5]:  # ìµœê·¼ 5ê°œë§Œ
                                            status_emoji = "âœ…" if session.get('status') == 'success' else "âŒ" if session.get('status') == 'failed' else "â³"
                                            st.write(f"{status_emoji} {session.get('company_name', 'N/A')} - {session.get('started_at', 'N/A')}")
                        else:
                            st.info("ë“±ë¡ëœ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
                    
                    except Exception as e:
                        st.error(f"ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
                with admin_tab3:
                    st.markdown("### ğŸ“‹ ë¡œê·¸ ì¡°íšŒ ë° ë‹¤ìš´ë¡œë“œ")
                    
                    # í•„í„°
                    col1, col2 = st.columns(2)
                    with col1:
                        log_type = st.selectbox("ë¡œê·¸ ìœ í˜•", ["ì „ì²´", "ì„¸ì…˜ ë¡œê·¸", "í™œë™ ë¡œê·¸", "ì—ëŸ¬ë§Œ"])
                    with col2:
                        limit = st.number_input("í‘œì‹œ ê°œìˆ˜", 10, 500, 100)
                    
                    if st.button("ğŸ” ë¡œê·¸ ì¡°íšŒ", type="primary"):
                        try:
                            if log_type == "ì„¸ì…˜ ë¡œê·¸" or log_type == "ì „ì²´":
                                st.markdown("#### ğŸ“ ì„¸ì…˜ ë¡œê·¸")
                                sessions = supabase_client.table("test_sessions").select("*").order("started_at", desc=True).limit(limit).execute()
                                
                                if sessions.data:
                                    for session in sessions.data:
                                        status_color = "green" if session.get('status') == 'success' else "red" if session.get('status') == 'failed' else "orange"
                                        st.markdown(f"**:{status_color}[{session.get('status', 'unknown').upper()}]** {session.get('company_name', 'N/A')} - {session.get('pdf_filename', 'N/A')}")
                                        st.caption(f"ì‹œì‘: {session.get('started_at', 'N/A')} | ì™„ë£Œ: {session.get('completed_at', 'N/A')}")
                                        if session.get('error_message'):
                                            with st.expander("âŒ ì—ëŸ¬ ë©”ì‹œì§€"):
                                                st.code(session.get('error_message'))
                                        st.markdown("---")
                                    
                                    # CSV ë‹¤ìš´ë¡œë“œ
                                    import pandas as pd
                                    df = pd.DataFrame(sessions.data)
                                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        "ğŸ“¥ ì„¸ì…˜ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
                                        csv,
                                        f"session_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        "text/csv"
                                    )
                            
                            if log_type == "í™œë™ ë¡œê·¸" or log_type == "ì „ì²´":
                                st.markdown("#### ğŸ” í™œë™ ë¡œê·¸")
                                
                                query = supabase_client.table("activity_logs").select("*").order("created_at", desc=True).limit(limit)
                                if log_type == "ì—ëŸ¬ë§Œ":
                                    query = query.eq("status", "failed")
                                
                                logs = query.execute()
                                
                                if logs.data:
                                    for log in logs.data:
                                        status_emoji = "âœ…" if log.get('status') == 'success' else "âŒ" if log.get('status') == 'failed' else "â³"
                                        st.markdown(f"{status_emoji} **{log.get('step', 'unknown')}** - {log.get('status', 'unknown')}")
                                        st.caption(f"ì‹œê°„: {log.get('created_at', 'N/A')} | ì‹¤í–‰ì‹œê°„: {log.get('execution_time_ms', 0)}ms")
                                        
                                        if log.get('details'):
                                            with st.expander("ğŸ“„ ìƒì„¸ ì •ë³´"):
                                                st.json(log.get('details'))
                                        st.markdown("---")
                                    
                                    # CSV ë‹¤ìš´ë¡œë“œ
                                    import pandas as pd
                                    df = pd.DataFrame(logs.data)
                                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        "ğŸ“¥ í™œë™ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
                                        csv,
                                        f"activity_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        "text/csv"
                                    )
                                else:
                                    st.info("ì¡°íšŒëœ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                        
                        except Exception as e:
                            st.error(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                            st.code(traceback.format_exc())
                    
                    st.markdown("---")
                    st.markdown("### ğŸ“¦ ì „ì²´ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("ğŸ“¥ ì„¸ì…˜ ë¡œê·¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ"):
                            try:
                                sessions = supabase_client.table("test_sessions").select("*").order("started_at", desc=True).execute()
                                if sessions.data:
                                    import pandas as pd
                                    df = pd.DataFrame(sessions.data)
                                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        "ë‹¤ìš´ë¡œë“œ",
                                        csv,
                                        f"all_sessions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        "text/csv",
                                        key="download_all_sessions"
                                    )
                            except Exception as e:
                                st.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    
                    with col2:
                        if st.button("ğŸ“¥ í™œë™ ë¡œê·¸ ì „ì²´ ë‹¤ìš´ë¡œë“œ"):
                            try:
                                logs = supabase_client.table("activity_logs").select("*").order("created_at", desc=True).limit(5000).execute()
                                if logs.data:
                                    import pandas as pd
                                    df = pd.DataFrame(logs.data)
                                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        "ë‹¤ìš´ë¡œë“œ",
                                        csv,
                                        f"all_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                        "text/csv",
                                        key="download_all_logs"
                                    )
                            except Exception as e:
                                st.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")                
                with admin_tab4:
                    st.markdown("### ğŸ” ë°ì´í„° í’ˆì§ˆ ë¹„êµ ë¶„ì„")
                    st.info("ğŸ“Š OCR ì¶”ì¶œ â†’ LLM ë°ì´í„° ì¶”ì¶œ â†’ ë³´ê³ ì„œ ìƒì„± ê³¼ì •ì„ ë¹„êµí•˜ì—¬ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤")
                    
                    try:
                        # ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì¡°íšŒ
                        quality_logs = supabase_client.table("data_quality_logs")\
                            .select("*")\
                            .order("created_at", desc=True)\
                            .limit(50)\
                            .execute()
                        
                        if not quality_logs.data:
                            st.warning("ì•„ì§ ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„° ì¶”ì¶œì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
                        else:
                            # ë¡œê·¸ ëª©ë¡ í‘œì‹œ
                            st.markdown(f"**ì´ {len(quality_logs.data)}ê°œì˜ í’ˆì§ˆ ë¡œê·¸**")
                            
                            # ë¡œê·¸ ì„ íƒ
                            log_options = []
                            for log in quality_logs.data:
                                created_at = log.get('created_at', 'N/A')[:19].replace('T', ' ')
                                company = log.get('company_name', 'Unknown')
                                user = log.get('user_name', 'N/A')
                                keywords_count = len(log.get('selected_keywords', []))
                                success_rate = log.get('extraction_success_rate', 0)
                                report_gen = "âœ… ë³´ê³ ì„œ ìˆìŒ" if log.get('report_generated') else "âŒ ë³´ê³ ì„œ ì—†ìŒ"
                                
                                log_options.append(
                                    f"{created_at} | {company} | {user} | í‚¤ì›Œë“œ {keywords_count}ê°œ | ì„±ê³µë¥  {success_rate}% | {report_gen}"
                                )
                            
                            selected_log_idx = st.selectbox(
                                "ë¶„ì„í•  ë¡œê·¸ ì„ íƒ",
                                range(len(log_options)),
                                format_func=lambda x: log_options[x]
                            )
                            
                            if selected_log_idx is not None:
                                selected_log = quality_logs.data[selected_log_idx]
                                
                                st.markdown("---")
                                st.markdown("## ğŸ“‹ ìƒì„¸ ë¹„êµ ë¶„ì„")
                                
                                # ê¸°ë³¸ ì •ë³´
                                col1, col2, col3, col4 = st.columns(4)
                                col1.metric("íšŒì‚¬ëª…", selected_log.get('company_name', 'N/A'))
                                col2.metric("í‚¤ì›Œë“œ ìˆ˜", len(selected_log.get('selected_keywords', [])))
                                col3.metric("ì¶”ì¶œ ì„±ê³µë¥ ", f"{selected_log.get('extraction_success_rate', 0)}%")
                                col4.metric("í‘œ ì¸ì‹", f"{selected_log.get('ocr_tables_count', 0)}ê°œ")
                                
                                st.markdown("---")
                                
                                # 3ë‹¨ê³„ ë¹„êµ íƒ­
                                comp_tab1, comp_tab2, comp_tab3, comp_tab4 = st.tabs([
                                    "1ï¸âƒ£ ì„ íƒëœ í‚¤ì›Œë“œ", 
                                    "2ï¸âƒ£ OCR ì›ë³¸ ë°ì´í„°", 
                                    "3ï¸âƒ£ LLM ì¶”ì¶œ ë°ì´í„°",
                                    "4ï¸âƒ£ ë³´ê³ ì„œ ìƒì„± ê²°ê³¼"
                                ])
                                
                                with comp_tab1:
                                    st.markdown("### ğŸ“Œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¶”ì¶œ í‚¤ì›Œë“œ")
                                    keywords = selected_log.get('selected_keywords', [])
                                    
                                    if keywords:
                                        cols = st.columns(4)
                                        for idx, kw in enumerate(keywords):
                                            col = cols[idx % 4]
                                            col.markdown(f"""
                                            <div style='
                                                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                                                color: white;
                                                padding: 10px;
                                                border-radius: 8px;
                                                text-align: center;
                                                margin: 5px 0;
                                                font-weight: 500;
                                            '>
                                                {kw}
                                            </div>
                                            """, unsafe_allow_html=True)
                                        st.caption(f"ì´ {len(keywords)}ê°œì˜ í‚¤ì›Œë“œê°€ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤")
                                    else:
                                        st.warning("í‚¤ì›Œë“œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                                
                                with comp_tab2:
                                    st.markdown("### ğŸ“„ OCR ì›ë³¸ ì¶”ì¶œ ë°ì´í„° (Upstage Parse)")
                                    
                                    # í‘œ ë°ì´í„°
                                    structured_data = selected_log.get('ocr_structured_data', {})
                                    if structured_data and structured_data.get('tables'):
                                        st.markdown(f"#### ğŸ“Š ì¸ì‹ëœ í‘œ ({len(structured_data['tables'])}ê°œ)")
                                        for idx, table in enumerate(structured_data['tables']):
                                            with st.expander(f"í‘œ {idx+1} (í˜ì´ì§€ {table.get('page', '?')})"):
                                                st.text(table.get('content', 'ë‚´ìš© ì—†ìŒ')[:1000])
                                    else:
                                        st.info("êµ¬ì¡°í™”ëœ í‘œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                                    
                                    # ì›ë³¸ í…ìŠ¤íŠ¸
                                    st.markdown("#### ğŸ“ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ (ì¼ë¶€)")
                                    raw_text = selected_log.get('ocr_raw_text', '')
                                    if raw_text:
                                        st.text_area("OCR ì›ë³¸", raw_text[:2000], height=300)
                                        st.caption(f"ì „ì²´ ê¸¸ì´: {len(raw_text)}ì (ì²˜ìŒ 2000ì í‘œì‹œ)")
                                    else:
                                        st.warning("ì›ë³¸ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                                
                                with comp_tab3:
                                    st.markdown("### ğŸ¤– LLMì´ ì¶”ì¶œí•œ ë°ì´í„°")
                                    
                                    extracted = selected_log.get('llm_extracted_data', {})
                                    if extracted:
                                        # ì„±ê³µ/ì‹¤íŒ¨ êµ¬ë¶„
                                        success_data = {k: v for k, v in extracted.items() if v and v != "ì •ë³´ ì—†ìŒ"}
                                        failed_data = {k: v for k, v in extracted.items() if not v or v == "ì •ë³´ ì—†ìŒ"}
                                        
                                        col1, col2 = st.columns(2)
                                        col1.metric("âœ… ì¶”ì¶œ ì„±ê³µ", len(success_data))
                                        col2.metric("âŒ ì¶”ì¶œ ì‹¤íŒ¨", len(failed_data))
                                        
                                        st.markdown("---")
                                        
                                        # ì„±ê³µí•œ ë°ì´í„°
                                        st.markdown("#### âœ… ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œëœ ë°ì´í„°")
                                        if success_data:
                                            for key, value in success_data.items():
                                                st.markdown(f"**{key}**")
                                                st.markdown(f"""
                                                <div style='
                                                    background: #f0fdf4;
                                                    border-left: 4px solid #22c55e;
                                                    padding: 10px 15px;
                                                    margin: 5px 0 15px 0;
                                                    border-radius: 4px;
                                                '>
                                                    {value}
                                                </div>
                                                """, unsafe_allow_html=True)
                                        else:
                                            st.info("ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                                        
                                        st.markdown("---")
                                        
                                        # ì‹¤íŒ¨í•œ ë°ì´í„°
                                        if failed_data:
                                            st.markdown("#### âŒ ì¶”ì¶œ ì‹¤íŒ¨ ë°ì´í„°")
                                            for key in failed_data.keys():
                                                st.markdown(f"""
                                                <div style='
                                                    background: #fef2f2;
                                                    border-left: 4px solid #ef4444;
                                                    padding: 10px 15px;
                                                    margin: 5px 0;
                                                    border-radius: 4px;
                                                    color: #991b1b;
                                                '>
                                                    <strong>{key}</strong>: ì •ë³´ ì—†ìŒ
                                                </div>
                                                """, unsafe_allow_html=True)
                                        
                                        # LLM ë©”íƒ€ë°ì´í„°
                                        st.markdown("---")
                                        st.caption(f"ëª¨ë¸: {selected_log.get('llm_model', 'N/A')} | "
                                                 f"ì²˜ë¦¬ ì‹œê°„: {selected_log.get('llm_extraction_time_ms', 0)}ms")
                                    else:
                                        st.warning("ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                                
                                with comp_tab4:
                                    st.markdown("### ğŸ“„ ìµœì¢… ìƒì„±ëœ ë³´ê³ ì„œ")
                                    
                                    if selected_log.get('report_generated'):
                                        report = selected_log.get('report_content', '')
                                        if report:
                                            st.markdown(report)
                                            
                                            st.markdown("---")
                                            st.caption(f"ëª¨ë¸: {selected_log.get('report_model', 'N/A')} | "
                                                     f"ìƒì„± ì‹œê°„: {selected_log.get('report_generation_time_ms', 0)}ms | "
                                                     f"ê¸¸ì´: {len(report)}ì")
                                        else:
                                            st.warning("ë³´ê³ ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤")
                                    else:
                                        st.info("ì•„ì§ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                                
                                # ì „ì²´ ë¹„êµ ìš”ì•½
                                st.markdown("---")
                                st.markdown("## ğŸ“Š ì¢…í•© ë¹„êµ ìš”ì•½")
                                
                                col1, col2, col3 = st.columns(3)
                                
                                with col1:
                                    st.markdown("### 1ï¸âƒ£ OCR ë‹¨ê³„")
                                    st.metric("í‘œ ì¸ì‹", f"{selected_log.get('ocr_tables_count', 0)}ê°œ")
                                    st.metric("ì°¨íŠ¸/ê·¸ë˜í”„ ì¸ì‹", f"{selected_log.get('ocr_charts_count', 0)}ê°œ")
                                    st.metric("í…ìŠ¤íŠ¸ ê¸¸ì´", f"{len(selected_log.get('ocr_raw_text', ''))}ì")
                                
                                with col2:
                                    st.markdown("### 2ï¸âƒ£ LLM ì¶”ì¶œ")
                                    st.metric("ì„±ê³µ", selected_log.get('keywords_with_data', 0))
                                    st.metric("ì‹¤íŒ¨", selected_log.get('keywords_missing_data', 0))
                                    st.metric("ì„±ê³µë¥ ", f"{selected_log.get('extraction_success_rate', 0)}%")
                                
                                with col3:
                                    st.markdown("### 3ï¸âƒ£ ë³´ê³ ì„œ ìƒì„±")
                                    if selected_log.get('report_generated'):
                                        st.success("âœ… ìƒì„± ì™„ë£Œ")
                                        st.metric("ê¸¸ì´", f"{len(selected_log.get('report_content', ''))}ì")
                                    else:
                                        st.error("âŒ ë¯¸ìƒì„±")
                                
                                # TXT íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
                                st.markdown("---")
                                st.markdown("## ğŸ“¥ AI ë¶„ì„ìš© TXT íŒŒì¼ ë‚´ë³´ë‚´ê¸°")
                                st.info("ğŸ’¡ ì´ ë¡œê·¸ë¥¼ TXT íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ AIì—ê²Œ ì²¨ë¶€í•˜ë©´, ìë™ìœ¼ë¡œ ë¬¸ì œì ì„ ë¶„ì„í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                
                                if st.button("ğŸ“¥ TXT íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°", type="primary", use_container_width=True):
                                    # TXT íŒŒì¼ ìƒì„±
                                    txt_content = generate_quality_log_txt(selected_log)
                                    
                                    # íŒŒì¼ëª… ìƒì„±
                                    company = selected_log.get('company_name', 'Unknown').replace(' ', '_')
                                    created_at = selected_log.get('created_at', '')[:10]
                                    filename = f"quality_log_{company}_{created_at}.txt"
                                    
                                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                                    st.download_button(
                                        label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                        data=txt_content,
                                        file_name=filename,
                                        mime="text/plain",
                                        use_container_width=True
                                    )
                                    
                                    st.success("âœ… TXT íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                                    
                                    with st.expander("ğŸ“‹ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°"):
                                        st.text(txt_content[:2000] + "\n\n... (ì „ì²´ ë‚´ìš©ì€ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”)")
                    
                    except Exception as e:
                        st.error(f"ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                        st.code(traceback.format_exc())