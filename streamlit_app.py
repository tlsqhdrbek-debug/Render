import streamlit as st
import fitz  # PyMuPDF
import os
import re
import numpy as np
from openai import OpenAI
from pathlib import Path
from docx import Document
from datetime import datetime
import tiktoken

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
    }
    .stApp {
        background: white;
        border-radius: 24px;
        padding: 40px;
        margin: 20px;
        box-shadow: 0 20px 60px rgba(0, 0, 0, 0.15);
    }
    /* ì‚¬ì´ë“œë°” ë„ˆë¹„ ì¦ê°€ */
    [data-testid="stSidebar"] {
        min-width: 350px !important;
        max-width: 350px !important;
    }
    /* ì‚¬ì´ë“œë°” ë²„íŠ¼ í¬ê¸° ì¡°ì • */
    .stSidebar button {
        font-size: 11px !important;
        padding: 5px 10px !important;
        white-space: nowrap !important;
    }
    /* Expander ë‚´ë¶€ ë²„íŠ¼ë„ ì‘ê²Œ */
    [data-testid="stExpander"] button {
        font-size: 11px !important;
    }
    /* íƒ­ ìŠ¤íƒ€ì¼ ê°œì„  */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background-color: #f8fafc;
        padding: 10px;
        border-radius: 12px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 0 30px;
        background-color: white;
        border-radius: 8px;
        font-size: 16px !important;
        font-weight: 600 !important;
        color: #64748b;
        border: 2px solid transparent;
        transition: all 0.3s ease;
    }
    .stTabs [data-baseweb="tab"]:hover {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.3);
    }
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border-color: transparent !important;
    }
    .keyword-tag {
        display: inline-flex;
        align-items: center;
        padding: 4px 10px;
        margin: 3px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 12px;
        font-size: 12px;
        font-weight: 500;
        white-space: nowrap;
    }
    .template-container {
        display: flex;
        flex-wrap: wrap;
        gap: 5px;
        align-items: center;
        margin-bottom: 10px;
    }
    .delete-btn {
        background: rgba(255, 255, 255, 0.2);
        border: none;
        color: white;
        width: 20px;
        height: 20px;
        border-radius: 50%;
        cursor: pointer;
        margin-left: 8px;
    }
</style>
""", unsafe_allow_html=True)

# .env íŒŒì¼ ë¡œë“œ
def load_env():
    """Load environment variables from .env file"""
    env_path = Path(__file__).parent / ".env"
    if env_path.exists():
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

load_env()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_client = None
if os.getenv("OPENAI_API_KEY") and os.getenv("OPENAI_API_KEY") != "your-api-key-here":
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=openai_api_key)
    st.sidebar.success("âœ… OpenAI API í‚¤ ë¡œë“œë¨")
else:
    st.sidebar.warning("âš ï¸ .envì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")

# Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
supabase_client = None
try:
    from supabase import create_client, Client
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")
    
    if supabase_url and supabase_key:
        supabase_client = create_client(supabase_url, supabase_key)
        st.sidebar.success("âœ… Supabase ì—°ê²°ë¨")
    else:
        st.sidebar.info("â„¹ï¸ Supabase ë¯¸ì—°ê²° (í™˜ê²½ë³€ìˆ˜ ë¯¸ì„¤ì •)")
except Exception as e:
    st.sidebar.error(f"âš ï¸ Supabase ì—°ê²° ì‹¤íŒ¨: {e}")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if 'template' not in st.session_state:
    st.session_state.template = []
if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = {}
if 'pdf_text' not in st.session_state:
    st.session_state.pdf_text = ""
if 'report_sections' not in st.session_state:
    # ê¸°ë³¸ ë³´ê³ ì„œ ì„¹ì…˜ ì„ íƒ (ëª¨ë‘ ì„ íƒ)
    st.session_state.report_sections = [
        "ê¸°ì—… ê°œìš”",
        "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„",
        "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„",
        "ì¬ë¬´ ìš”ì•½",
        "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„",
        "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„",
        "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„",
        "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„",
        "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬",
        "ë¦¬ìŠ¤í¬ ìš”ì¸",
        "ì¢…í•© í‰ê°€"
    ]
if 'show_template_editor' not in st.session_state:
    st.session_state.show_template_editor = False
if 'reference_pdfs' not in st.session_state:
    st.session_state.reference_pdfs = {}  # {filename: extracted_text}

# ë³´ê³ ì„œ ì„¹ì…˜ë³„ ì‘ì„± ì§€ì¹¨ ì •ì˜
REPORT_SECTION_TEMPLATES = {
    "ê¸°ì—… ê°œìš”": """1. **ê¸°ì—… ê°œìš”**
   - íšŒì‚¬ëª…, ì—…ì¢…, ì£¼ìš” ì‚¬ì—… ë‚´ìš©
   - ë§¤ì¶œ/ì˜ì—…ì´ìµ ë“± ê¸°ë³¸ ì •ë³´
   - ì„¤ë¦½ ë°°ê²½ ë° ì£¼ìš” ì—°í˜
   - ì¡°ì§ êµ¬ì¡° ìš”ì•½(ì„ íƒ)
   - ì¶”ì¶œëœ ë°ì´í„°ë§Œ ì‚¬ìš©""",
    
    "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„": """2. **ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„**
   - ì£¼ìš” ì‚¬ì—…ë¶€ êµ¬ì¡° ë° ë§¤ì¶œ ë¹„ì¤‘
   - ì œí’ˆ/ì„œë¹„ìŠ¤ë³„ ìˆ˜ìµ ëª¨ë¸
   - ê³ ê° ëŒ€ìƒêµ°(B2B/B2C), ì§€ì—­ë³„ ë§¤ì¶œ êµ¬ì¡°
   - ì£¼ìš” ì›ê°€/ë§ˆì§„ êµ¬ì¡°
   - ì—¬ì‹  ì‹¬ì‚¬ì— í•„ìš”í•œ í•µì‹¬ í•­ëª©
   - ì¶”ì¶œëœ ë°ì´í„° ê¸°ë°˜, ì—†ìœ¼ë©´ ì—…ì¢… íŠ¹ì„± ë°˜ì˜
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ìµœì‹  ì •ë³´ë‚˜ ê²½ìŸì‚¬ ë¹„êµê°€ í•„ìš”í•˜ë©´ ê´€ë ¨ PDFë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„": """3. **ì‚°ì—… ë° ì‹œì¥ ë¶„ì„**
   - ì‚°ì—… ê·œëª¨, ì„±ì¥ì„±, ì‹œì¥ ë™í–¥
   - ê²½ìŸ êµ¬ë„ ë° íŠ¸ë Œë“œ
   - í•´ë‹¹ ê¸°ì—…ì´ ì†í•œ ì‹œì¥ì˜ ìœ„í—˜ ìš”ì¸
   - PDFì— ì •ë³´ ì—†ìœ¼ë©´ ì—…ì¢… ê¸°ì¤€ ì¼ë°˜ ë¶„ì„
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ìµœì‹  ì‚°ì—… ë¦¬í¬íŠ¸ë‚˜ ì‹œì¥ ë¶„ì„ ìë£Œë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ì¬ë¬´ ìš”ì•½": """4. **ì¬ë¬´ ìš”ì•½**
   - ë§¤ì¶œ, ì˜ì—…ì´ìµ, ì„±ì¥ë¥  ë¶„ì„
   - ì¶”ì¶œëœ í•µì‹¬ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜
   - ìˆ˜ìµì„±Â·ì„±ì¥ì„± ì§€í‘œ
   - ì „ë…„ ëŒ€ë¹„ ì„±ì¥ë¥ , ìˆ˜ìµì„± ì§€í‘œ í¬í•¨""",
    
    "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„": """5. **ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„**
   - ë¶€ì±„ êµ¬ì¡°(ë‹¨ê¸°/ì¥ê¸°)
   - ì´ìë³´ìƒë°°ìœ¨, ì°¨ì… ì˜ì¡´ë„
   - ì˜ì—…í˜„ê¸ˆíë¦„ ì•ˆì •ì„±
   - ìˆœìš´ì „ìë³¸(NWC) ë¶„ì„
   - ëŒ€ì¶œ ìƒí™˜ëŠ¥ë ¥ í‰ê°€ í•µì‹¬ ì§€í‘œ
   - ì¶”ì¶œëœ ì¬ë¬´ ë°ì´í„° ê¸°ë°˜""",
    
    "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„": """6. **ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„**
   - ì£¼ìš” ê³ ê°ì‚¬ TOP5
   - ë‹¨ì¼ ê±°ë˜ì²˜ ì˜ì¡´ë„
   - ë§¤ì¶œ ë‹¤ë³€í™” ìˆ˜ì¤€
   - ê±°ë˜ì²˜ ë³€ê²½ ê°€ëŠ¥ì„±
   - ìºí”¼íƒˆ ë¦¬ìŠ¤í¬ ì‹¬ì‚¬ì—ì„œ ë§¤ìš° ì¤‘ìš”
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¸ê¸‰""",
    
    "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„": """7. **ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„**
   - ì—…ì¢… ë‚´ ì£¼ìš” ê²½ìŸì‚¬ ë¹„êµ
   - ê²½ìŸ ìš°ìœ„Â·ì—´ìœ„ ë¶„ì„
   - ì‹œì¥ ì ìœ ìœ¨ ì¶”ì •
   - ë°ì´í„° ì—†ìœ¼ë©´ ì—…ì¢… ê¸°ë°˜ ì¼ë°˜ ë¹„êµ
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*
   - *> ê²½ìŸì‚¬ ì‚¬ì—…ë³´ê³ ì„œë‚˜ IR ìë£Œë¥¼ 'ì°¸ê³ ìë£Œ'ë¡œ ì¶”ê°€ ì—…ë¡œë“œí•˜ì‹œë©´ ë” ì •í™•í•œ ë¹„êµ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.*""",
    
    "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„": """8. **ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„**
   - CEO ë° í•µì‹¬ ì„ì› ê²½ë ¥
   - ì§€ë¶„ êµ¬ì¡°, ì˜¤ë„ˆ ë¦¬ìŠ¤í¬
   - ì§€ë°°êµ¬ì¡° íˆ¬ëª…ì„±
   - ê²½ì˜ì§„ êµì²´ ì´ë ¥
   - íŠ¹íˆ ì¤‘ì†Œê¸°ì—… ì‹¬ì‚¬ì— ë§¤ìš° ì¤‘ìš”
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì–¸ê¸‰ ì•ˆ í•¨""",
    
    "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬": """9. **ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬**
   - ì‹ ìš©ë“±ê¸‰(ìˆìœ¼ë©´)
   - ê°ì‚¬ ì˜ê²¬(ì ì •/í•œì • ë“±)
   - ìµœê·¼ ì†Œì†¡Â·ë¶„ìŸÂ·ì œì¬ ì—¬ë¶€
   - ê³µì •ìœ„/ê¸ˆìœµìœ„ ì œì¬ ì—¬ë¶€
   - ê¸°ë³¸ ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ êµ¬ë¶„ë˜ëŠ” ì •ëŸ‰ì  ë¦¬ìŠ¤í¬
   - PDFì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*""",
    
    "ë¦¬ìŠ¤í¬ ìš”ì¸": """10. **ë¦¬ìŠ¤í¬ ìš”ì¸**
   - ì‚°ì—… ë¦¬ìŠ¤í¬
   - ìš´ì˜ ë¦¬ìŠ¤í¬
   - ì¬ë¬´ì  ì¼ë°˜ ë¦¬ìŠ¤í¬
   - PDFì— ë¦¬ìŠ¤í¬ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©
   - ì—†ìœ¼ë©´ í•´ë‹¹ ì‚°ì—…ì˜ ì¼ë°˜ì  ë¦¬ìŠ¤í¬ ì„¤ëª…
   - *> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´, AI ëª¨ë¸ì´ í•™ìŠµí•œ ì¼ë°˜ ì§€ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. (2023ë…„ 10ì›” ê¸°ì¤€)*""",
    
    "ì¢…í•© í‰ê°€": """11. **ì¢…í•© í‰ê°€ (íˆ¬ì/ëŒ€ì¶œ ê´€ì )**
   - ì¬ë¬´ ì•ˆì •ì„± í‰ê°€
   - ìƒí™˜ ëŠ¥ë ¥ í‰ê°€
   - ì„±ì¥ ê°€ëŠ¥ì„± ìš”ì•½
   - ì¢…í•© ì˜ê²¬ ë° ê¶Œì¥ ì¡°ì¹˜
   - ëŒ€ì¶œ ìŠ¹ì¸/ì¡°ê±´/ìœ ì˜ì‚¬í•­ ì œì‹œ ê°€ëŠ¥
   - ì¶”ì¶œëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°ê´€ì  íŒë‹¨"""
}

# Supabase í—¬í¼ í•¨ìˆ˜
def save_to_supabase(company_name, pdf_file, extracted_text, extracted_data, report_content=None, create_embeddings_flag=True):
    """Supabaseì— ë°ì´í„° ë° ì„ë² ë”© ì €ì¥"""
    if not supabase_client:
        st.warning("âš ï¸ Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # 1. ê¸°ì—… ì •ë³´ ì €ì¥
        company_data = {
            "company_name": company_name,
            "industry": extracted_data.get("ì—…ì¢…") or extracted_data.get("ì‚°ì—…ë¶„ë¥˜") or "ë¯¸ë¶„ë¥˜"
        }
        company_response = supabase_client.table("companies").insert(company_data).execute()
        company_id = company_response.data[0]["id"]
        st.info(f"âœ… ê¸°ì—… ì •ë³´ ì €ì¥ ì™„ë£Œ (ID: {company_id})")
        
        # 2. PDF íŒŒì¼ì„ Storageì— ì €ì¥ (ì„ íƒì‚¬í•­ - ì—ëŸ¬ ë°œìƒ ì‹œ ë¬´ì‹œ)
        try:
            file_path = f"{company_id}/main.pdf"
            pdf_file.seek(0)
            pdf_bytes = pdf_file.read()
            supabase_client.storage.from_("company-pdfs").upload(
                file_path,
                pdf_bytes,
                {"content-type": "application/pdf"}
            )
            file_size = len(pdf_bytes)
            st.info("âœ… PDF íŒŒì¼ Storage ì €ì¥ ì™„ë£Œ")
        except Exception as storage_error:
            st.warning(f"âš ï¸ PDF Storage ì €ì¥ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {storage_error}")
            file_path = "not_stored"
            file_size = 0
        
        # 3. PDF íŒŒì¼ ì •ë³´ ì €ì¥
        pdf_data = {
            "company_id": company_id,
            "file_name": getattr(pdf_file, 'name', 'unknown.pdf'),
            "file_type": "main",
            "storage_path": file_path,
            "file_size": file_size,
            "extracted_text": extracted_text[:50000],  # í…ìŠ¤íŠ¸ í¬ê¸° ì œí•œ
            "pages_count": extracted_text.count("=== í˜ì´ì§€")
        }
        supabase_client.table("pdf_files").insert(pdf_data).execute()
        st.info("âœ… PDF ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
        # 4. ì¶”ì¶œëœ ë°ì´í„° ì €ì¥
        data_entries = []
        for field_name, field_value in extracted_data.items():
            data_entries.append({
                "company_id": company_id,
                "field_name": field_name,
                "field_value": str(field_value)[:5000]  # ê¸¸ì´ ì œí•œ
            })
        
        if data_entries:
            supabase_client.table("extracted_data").insert(data_entries).execute()
            st.info(f"âœ… ì¶”ì¶œ ë°ì´í„° {len(data_entries)}ê°œ ì €ì¥ ì™„ë£Œ")
        
        # 5. ë³´ê³ ì„œ ì €ì¥ (ì„ íƒì‚¬í•­)
        if report_content:
            report_data = {
                "company_id": company_id,
                "report_content": report_content[:100000]  # í¬ê¸° ì œí•œ
            }
            supabase_client.table("reports").insert(report_data).execute()
            st.info("âœ… ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ")
        
        # 6. ì„ë² ë”© ìƒì„± ë° ì €ì¥ (RAG ì‹œìŠ¤í…œ)
        if create_embeddings_flag and openai_client:
            with st.spinner("ğŸ”® ì„ë² ë”© ë²¡í„° ìƒì„± ì¤‘..."):
                # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
                chunks = split_text_into_chunks(extracted_text, max_tokens=500, overlap_tokens=50)
                st.info(f"ğŸ“¦ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
                
                # ì„ë² ë”© ìƒì„±
                embeddings = create_embeddings(chunks)
                
                if embeddings:
                    # Supabaseì— ì €ì¥
                    save_embeddings_to_supabase(company_id, embeddings, file_type="main")
                else:
                    st.warning("âš ï¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ê²€ìƒ‰ì€ ì œí•œë©ë‹ˆë‹¤")
        
        return company_id
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"âŒ Supabase ì €ì¥ ì‹¤íŒ¨")
        st.error(f"ì—ëŸ¬: {str(e)}")
        with st.expander("ìƒì„¸ ì—ëŸ¬ ë¡œê·¸"):
            st.code(error_detail)
        return None

def load_companies_list():
    """ì €ì¥ëœ ê¸°ì—… ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not supabase_client:
        return []
    
    try:
        response = supabase_client.table("companies").select("*").order("created_at", desc=True).limit(50).execute()
        return response.data
    except Exception as e:
        st.error(f"ê¸°ì—… ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []

def load_company_data(company_id):
    """íŠ¹ì • ê¸°ì—…ì˜ ì¶”ì¶œëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not supabase_client:
        return {}
    
    try:
        response = supabase_client.table("extracted_data").select("*").eq("company_id", company_id).execute()
        return {item["field_name"]: item["field_value"] for item in response.data}
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

# ============================================
# ì„ë² ë”© ë° RAG ì‹œìŠ¤í…œ
# ============================================

def split_text_into_chunks(text, max_tokens=500, overlap_tokens=50):
    """í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸°ë°˜ìœ¼ë¡œ ì²­í¬ ë¶„í• """
    try:
        encoding = tiktoken.encoding_for_model("text-embedding-3-small")
        tokens = encoding.encode(text)
        
        chunks = []
        start = 0
        
        while start < len(tokens):
            end = start + max_tokens
            chunk_tokens = tokens[start:end]
            chunk_text = encoding.decode(chunk_tokens)
            
            chunks.append({
                "text": chunk_text,
                "start_pos": start,
                "end_pos": end,
                "token_count": len(chunk_tokens)
            })
            
            start += (max_tokens - overlap_tokens)
        
        return chunks
    except Exception as e:
        st.error(f"ì²­í¬ ë¶„í•  ì‹¤íŒ¨: {e}")
        # í´ë°±: ë‹¨ìˆœ ë¬¸ì ê¸°ë°˜ ë¶„í• 
        chunk_size = 2000
        overlap = 200
        chunks = []
        start = 0
        while start < len(text):
            end = start + chunk_size
            chunk_text = text[start:end]
            chunks.append({
                "text": chunk_text,
                "start_pos": start,
                "end_pos": end,
                "token_count": len(chunk_text) // 4  # ëŒ€ëµì  ì¶”ì •
            })
            start += (chunk_size - overlap)
        return chunks

def create_embeddings(text_chunks):
    """OpenAI APIë¡œ ì„ë² ë”© ë²¡í„° ìƒì„±"""
    if not openai_client:
        st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    embeddings = []
    try:
        for i, chunk in enumerate(text_chunks):
            response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=chunk["text"]
            )
            embedding_vector = response.data[0].embedding
            
            embeddings.append({
                "chunk_index": i,
                "text": chunk["text"],
                "embedding": embedding_vector,
                "token_count": chunk["token_count"]
            })
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            if (i + 1) % 10 == 0:
                st.info(f"ì„ë² ë”© ìƒì„± ì¤‘... {i + 1}/{len(text_chunks)}")
        
        return embeddings
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return []

def save_embeddings_to_supabase(company_id, embeddings, file_type="main"):
    """Supabaseì— ì„ë² ë”© ë²¡í„° ì €ì¥"""
    if not supabase_client:
        st.warning("Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # ë²¡í„° ë°ì´í„° ì¤€ë¹„
        vector_entries = []
        for emb in embeddings:
            vector_entries.append({
                "company_id": company_id,
                "file_type": file_type,
                "chunk_index": emb["chunk_index"],
                "chunk_text": emb["text"][:5000],  # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                "embedding": emb["embedding"],
                "token_count": emb["token_count"]
            })
        
        # ë°°ì¹˜ë¡œ ì €ì¥ (í•œ ë²ˆì— ë„ˆë¬´ ë§ìœ¼ë©´ ë¶„í• )
        batch_size = 100
        for i in range(0, len(vector_entries), batch_size):
            batch = vector_entries[i:i + batch_size]
            supabase_client.table("document_embeddings").insert(batch).execute()
            st.info(f"ë²¡í„° ì €ì¥ ì¤‘... {min(i + batch_size, len(vector_entries))}/{len(vector_entries)}")
        
        st.success(f"âœ… {len(vector_entries)}ê°œ ì„ë² ë”© ë²¡í„° ì €ì¥ ì™„ë£Œ!")
        return True
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        st.error(f"ë²¡í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        with st.expander("ìƒì„¸ ì—ëŸ¬ ë¡œê·¸"):
            st.code(error_detail)
        return False

def semantic_search(query, company_id=None, top_k=5, file_type=None):
    """ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ ê²€ìƒ‰"""
    if not supabase_client or not openai_client:
        st.warning("Supabase ë˜ëŠ” OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        response = openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=query
        )
        query_embedding = response.data[0].embedding
        
        # Supabaseì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (RPC í•¨ìˆ˜ ì‚¬ìš©)
        rpc_params = {
            "query_embedding": query_embedding,
            "match_threshold": 0.5,
            "match_count": top_k
        }
        
        # íšŒì‚¬ ID í•„í„°
        if company_id:
            rpc_params["filter_company_id"] = company_id
        
        # íŒŒì¼ íƒ€ì… í•„í„°
        if file_type:
            rpc_params["filter_file_type"] = file_type
        
        # RPC í˜¸ì¶œ
        result = supabase_client.rpc(
            "match_documents",
            rpc_params
        ).execute()
        
        return result.data
    except Exception as e:
        st.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def retrieve_relevant_context(query, company_id=None, max_tokens=3000):
    """RAG: ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    search_results = semantic_search(query, company_id=company_id, top_k=10)
    
    if not search_results:
        return "ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # í† í° ì œí•œ ë‚´ì—ì„œ ê´€ë ¨ í…ìŠ¤íŠ¸ ì¡°í•©
    context_parts = []
    total_tokens = 0
    
    for result in search_results:
        chunk_text = result.get("chunk_text", "")
        similarity = result.get("similarity", 0)
        token_count = result.get("token_count", 0)
        
        if total_tokens + token_count > max_tokens:
            break
        
        context_parts.append(f"[ìœ ì‚¬ë„: {similarity:.3f}]\n{chunk_text}")
        total_tokens += token_count
    
    return "\n\n---\n\n".join(context_parts)

# OCR Reader (lazy loading)
_ocr_reader = None

def get_ocr_reader():
    """OCR Readerë¥¼ lazy loadingìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
    global _ocr_reader
    if _ocr_reader is None:
        import easyocr
        _ocr_reader = easyocr.Reader(['ko', 'en'], gpu=False)
    return _ocr_reader

def extract_text_from_pdf(pdf_file, max_pages=5):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        num_pages = min(len(doc), max_pages)
        
        text = ""
        for page_num in range(num_pages):
            page = doc[page_num]
            page_text = page.get_text()
            text += f"\n\n=== í˜ì´ì§€ {page_num+1} ===\n\n{page_text}"
        
        if len(text.strip()) > 100:
            doc.close()
            return text, num_pages
        
        # OCR í´ë°± (í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•œ ê²½ìš°)
        st.warning("í…ìŠ¤íŠ¸ ì¶”ì¶œëŸ‰ì´ ì ì–´ OCRì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
        return extract_text_with_easyocr(pdf_file, max_pages)
        
    except Exception as e:
        st.error(f"PDF ì½ê¸° ì˜¤ë¥˜: {e}")
        return "", 0

def extract_text_with_easyocr(pdf_file, max_pages=5):
    """EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    text = ""
    try:
        pdf_file.seek(0)
        doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
        num_pages = min(len(doc), max_pages)
        
        for page_num in range(num_pages):
            page = doc[page_num]
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)
            
            if pix.n == 4:
                img_array = img_array[:, :, :3]
            
            ocr_reader = get_ocr_reader()
            ocr_result = ocr_reader.readtext(img_array, detail=0, paragraph=True)
            page_text = "\n".join(ocr_result)
            text += f"\n\n=== í˜ì´ì§€ {page_num+1} ===\n\n{page_text}"
        
        doc.close()
        return text, num_pages
    except Exception as e:
        st.error(f"OCR ì˜¤ë¥˜: {e}")
        return "", 0

def extract_all_keywords_batch(text, field_names):
    """ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•œ ë²ˆì— ì¶”ì¶œ (í† í° ì ˆê°)"""
    if not openai_client:
        # API ì—†ìœ¼ë©´ ê°œë³„ ë°©ì‹ìœ¼ë¡œ í´ë°±
        result = {}
        for field_name in field_names:
            result[field_name] = extract_keyword_simple(text, field_name)
        return result
    
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
        text_preview = text[:4000]
        
        # ëª¨ë“  í•„ë“œë¥¼ í•œ ë²ˆì— ìš”ì²­
        fields_list = "\n".join([f"{i+1}. {name}" for i, name in enumerate(field_names)])
        
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ì•„ë˜ í•­ëª©ë“¤ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì„œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text_preview}

ì¶”ì¶œí•  í•­ëª©:
{fields_list}

ìš”êµ¬ì‚¬í•­:
1. ê° í•­ëª©ë³„ë¡œ ê´€ë ¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¶”ì¶œ
2. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì •ë³´ ì—†ìŒ"ì´ë¼ê³ ë§Œ ì‘ë‹µ
3. ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ìœ ì§€
4. ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€ (ê° í•­ëª©ì€ ìƒˆ ì¤„ì—):

[í•­ëª©ëª…]: ì¶”ì¶œëœ ë‚´ìš©

ë‹µë³€:"""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ '[í•­ëª©ëª…]: ë‚´ìš©' í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=800,
            temperature=0.1
        )
        
        result_text = response.choices[0].message.content.strip()
        print(f"[DEBUG] ë°°ì¹˜ ì¶”ì¶œ ê²°ê³¼:\n{result_text}\n")
        
        # ê²°ê³¼ íŒŒì‹± - ë” ê°„ë‹¨í•œ ë°©ì‹
        extracted_data = {}
        
        for line in result_text.split('\n'):
            line = line.strip()
            if not line:
                continue
            
            # [í•­ëª©ëª…]: ë˜ëŠ” í•­ëª©ëª…: í˜•ì‹ ì°¾ê¸°
            if ':' in line:
                # [ ] ì œê±°
                line = line.replace('[', '').replace(']', '')
                parts = line.split(':', 1)
                
                if len(parts) == 2:
                    field_name = parts[0].strip()
                    value = parts[1].strip()
                    
                    # í•„ë“œëª…ì´ ìš”ì²­í•œ í•­ëª© ì¤‘ í•˜ë‚˜ì¸ì§€ í™•ì¸
                    for fn in field_names:
                        if fn == field_name or fn in field_name or field_name in fn:
                            extracted_data[fn] = value
                            break
        
        # ëˆ„ë½ëœ í•„ë“œëŠ” "ì •ë³´ ì—†ìŒ"ìœ¼ë¡œ ì±„ìš°ê¸°
        for field_name in field_names:
            if field_name not in extracted_data:
                extracted_data[field_name] = "ì •ë³´ ì—†ìŒ"
        
        print(f"[DEBUG] íŒŒì‹±ëœ ë°ì´í„°: {extracted_data}\n")
        return extracted_data
        
    except Exception as e:
        print(f"[DEBUG] ë°°ì¹˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê°œë³„ ë°©ì‹ìœ¼ë¡œ í´ë°±
        result = {}
        for field_name in field_names:
            result[field_name] = extract_keyword_simple(text, field_name)
        return result

def extract_keyword(text, field_name):
    """OpenAI APIë¡œ ì§€ëŠ¥ì ìœ¼ë¡œ í‚¤ì›Œë“œ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ"""
    if not openai_client:
        return extract_keyword_simple(text, field_name)
    
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì œí•œ)
        text_preview = text[:4000]
        
        prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ "{field_name}"ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì„œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.

í…ìŠ¤íŠ¸:
{text_preview}

ìš”êµ¬ì‚¬í•­:
1. "{field_name}"ì™€ ê´€ë ¨ëœ ëª¨ë“  ì •ë³´ë¥¼ ì¶”ì¶œ
2. ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì •ë³´ ì—†ìŒ"ì´ë¼ê³ ë§Œ ì‘ë‹µ
3. ì¶”ì¶œí•œ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ë‹µë³€ (ì„¤ëª… ì—†ì´)
4. ì—¬ëŸ¬ í•­ëª©ì´ ìˆìœ¼ë©´ ëª¨ë‘ í¬í•¨
5. ì›ë¬¸ì˜ í‘œí˜„ì„ ìµœëŒ€í•œ ìœ ì§€

ë‹µë³€:"""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ë¬¸ì„œì—ì„œ ì •í™•í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìš”ì²­ë°›ì€ ì •ë³´ë¥¼ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì™„ì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.1
        )
        
        result = response.choices[0].message.content.strip()
        
        # ë¹ˆ ì‘ë‹µì´ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ í´ë°±
        if not result or len(result) < 2:
            return extract_keyword_simple(text, field_name)
        
        return result
        
    except Exception as e:
        print(f"[DEBUG] OpenAI ì¶”ì¶œ ì‹¤íŒ¨ ({field_name}): {e}")
        return extract_keyword_simple(text, field_name)

def extract_keyword_simple(text, field_name):
    """ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë§¤ì¹­ ë°©ì‹ (í´ë°±)"""
    keywords_map = {
        "íšŒì‚¬": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "íšŒì‚¬ëª…": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "íšŒì‚¬ì´ë¦„": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "ê¸°ì—…ëª…": ["íšŒì‚¬", "ê¸°ì—…", "ë²•ì¸", "ãˆœ", "(ì£¼)", "ì£¼ì‹íšŒì‚¬"],
        "ëŒ€í‘œ": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "ëŒ€í‘œì´ë¦„": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "ëŒ€í‘œì´ì‚¬": ["ëŒ€í‘œ", "CEO", "ëŒ€í‘œì´ì‚¬", "ëŒ€í‘œì"],
        "CEO": ["CEO", "ëŒ€í‘œ", "ëŒ€í‘œì´ì‚¬"],
        "ì‚¬ì—…": ["ì‚¬ì—…", "ì—…ì¢…", "ì‚¬ì—…ë¶„ì•¼", "ì‚¬ì—…ë‚´ìš©"],
        "ì‚¬ì—…ë¶„ì•¼": ["ì‚¬ì—…ë¶„ì•¼", "ì‚¬ì—…", "ì—…ì¢…", "ì£¼ìš” ì‚¬ì—…"],
        "ì‚¬ì—…ë‚´ìš©": ["ì‚¬ì—…ë‚´ìš©", "ì‚¬ì—…", "ì—…ì¢…"],
        "ë§¤ì¶œ": ["ë§¤ì¶œ", "ë§¤ì¶œì•¡", "Revenue"],
        "ë§¤ì¶œì•¡": ["ë§¤ì¶œì•¡", "ë§¤ì¶œ", "Revenue"],
        "ì—°ë§¤ì¶œ": ["ì—°ë§¤ì¶œ", "ë§¤ì¶œì•¡", "ë§¤ì¶œ", "ì—°ê°„ë§¤ì¶œ"],
        "ì˜ì—…ì´ìµ": ["ì˜ì—…ì´ìµ", "ì˜ì—…ìµ", "Operating Profit"],
        "ìˆœì´ìµ": ["ìˆœì´ìµ", "ë‹¹ê¸°ìˆœì´ìµ", "Net Profit"],
        "ì„±ê³¼": ["ì„±ê³¼", "ì‹¤ì ", "ì£¼ìš” ì„±ê³¼", "ì„±ê³¼ ì§€í‘œ"],
    }
    
    search_keywords = keywords_map.get(field_name, [field_name])
    
    lines = text.split('\n')
    result = []
    
    for keyword in search_keywords:
        pattern = re.compile(rf'{re.escape(keyword)}[:\s]*([^\n]+)', re.IGNORECASE)
        for line in lines:
            match = pattern.search(line)
            if match:
                value = match.group(1).strip()
                if value and len(value) > 1:
                    result.append(value)
    
    return result[0] if result else "ì •ë³´ ì—†ìŒ"

def generate_report_with_openai(data_dict, report_sections=None, model="gpt-4o-mini", company_id=None, use_rag=True):
    """RAG ê¸°ë°˜ OpenAI APIë¡œ ì²´ê³„ì ì¸ ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
    if not openai_client:
        return "âŒ OpenAI API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”."
    
    # ë³´ê³ ì„œ ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if report_sections is None:
        report_sections = st.session_state.get('report_sections', [])
    
    # ì„ íƒëœ ì„¹ì…˜ì— í•´ë‹¹í•˜ëŠ” ì‘ì„± ì§€ì¹¨ë§Œ ì¡°í•©
    selected_guidelines = []
    for section in report_sections:
        if section in REPORT_SECTION_TEMPLATES:
            selected_guidelines.append(REPORT_SECTION_TEMPLATES[section])
    
    report_template = "\n\n".join(selected_guidelines)
    
    # ì‘ì„± ê·œì¹™ ì¶”ê°€
    report_template += """

**ì‘ì„± ê·œì¹™:**
- ê° ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±
- PDFì—ì„œ ì¶”ì¶œí•œ ì •ë³´ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
- PDFì— ì—†ëŠ” ì •ë³´ë¡œ ì™¸ë¶€ ì§€ì‹ì„ í™œìš©í•  ë•ŒëŠ” ë°˜ë“œì‹œ "*> ë³¸ ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´ ì™¸ë¶€ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€ ìƒì„± (ì¶œì²˜: [ì •ë³´ ì¶œì²˜])*" í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš© (## ì œëª©, **ê°•ì¡°**)
- ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ í†¤ ìœ ì§€
- êµ¬ì²´ì ì¸ ìˆ«ìì™€ ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±"""
    
    # ì¶”ì¶œëœ ë°ì´í„° ì •ë¦¬
    available_data = []
    missing_fields = []
    
    for key, value in data_dict.items():
        if value and value != "ì •ë³´ ì—†ìŒ":
            available_data.append(f"- {key}: {value}")
        else:
            missing_fields.append(key)
    
    if not available_data:
        return "âŒ ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    available_data_text = "\n".join(available_data)
    missing_fields_text = ", ".join(missing_fields) if missing_fields else "ì—†ìŒ"
    
    # RAG: ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    rag_context = ""
    if use_rag and company_id and supabase_client:
        with st.spinner("ğŸ” ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘..."):
            # ë³´ê³ ì„œ ì„¹ì…˜ë³„ ì¿¼ë¦¬ ìƒì„±
            queries = [
                f"{company_name} ì¬ë¬´ ì •ë³´ ë§¤ì¶œ ì˜ì—…ì´ìµ",
                f"{company_name} ì‚¬ì—… êµ¬ì¡° ì œí’ˆ ì„œë¹„ìŠ¤",
                f"{company_name} ê²½ìŸì‚¬ ì‹œì¥ ë¶„ì„",
                "ë¦¬ìŠ¤í¬ ìš”ì¸ ìœ„í—˜ ìš”ì†Œ"
            ]
            
            retrieved_contexts = []
            for query in queries:
                context = retrieve_relevant_context(query, company_id=company_id, max_tokens=1000)
                if context and context != "ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.":
                    retrieved_contexts.append(context)
            
            if retrieved_contexts:
                rag_context = "\n\n**ğŸ” ê´€ë ¨ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ (ë²¡í„° ê²€ìƒ‰ ê²°ê³¼):**\n" + "\n\n".join(retrieved_contexts[:2])  # ìƒìœ„ 2ê°œë§Œ
                st.success(f"âœ… {len(retrieved_contexts)}ê°œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì™„ë£Œ")
    
    # ì°¸ê³ ìë£Œ í…ìŠ¤íŠ¸ ì¶”ê°€ (ê¸°ì¡´ ë°©ì‹)
    reference_context = ""
    if st.session_state.get('reference_pdfs'):
        reference_texts = []
        for filename, text in st.session_state.reference_pdfs.items():
            # ê° ì°¸ê³ ìë£Œì—ì„œ ì•ë¶€ë¶„ 2000ìë§Œ ì‚¬ìš© (í† í° ì ˆì•½)
            reference_texts.append(f"[{filename}]\n{text[:2000]}")
        
        reference_context = "\n\n**ì°¸ê³ ìë£Œ (ê²½ìŸì‚¬/ì‚°ì—… ë¶„ì„ ìë£Œ):**\n" + "\n\n---\n\n".join(reference_texts)
    
    try:
        prompt = f"""ë‹¤ìŒ ê¸°ì—… ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

**PDFì—ì„œ ì¶”ì¶œëœ ë°ì´í„°:**
{available_data_text}

**PDFì— ì—†ëŠ” ì •ë³´:** {missing_fields_text}

{rag_context}

{reference_context}

**ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨:**
{report_template}

**ë³´ê³ ì„œ:**"""
        
        response = openai_client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": """ë‹¹ì‹ ì€ ê¸°ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì œê³µëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì´ê³  ì „ë¬¸ì ì¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

**ì¶œì²˜ í‘œì‹œ ê·œì¹™ (í•„ìˆ˜):**
1. PDFì—ì„œ ì¶”ì¶œí•œ ì›ë³¸ ë°ì´í„°: `[ì¶œì²˜: ë©”ì¸ PDF]`
   ì˜ˆ: "2023ë…„ ë§¤ì¶œì€ 100ì–µì›ì…ë‹ˆë‹¤. [ì¶œì²˜: ë©”ì¸ PDF]"

2. ì°¸ê³ ìë£Œì—ì„œ ê°€ì ¸ì˜¨ ì •ë³´: `[ì¶œì²˜: ì°¸ê³ ìë£Œ - íŒŒì¼ëª…]`
   ì˜ˆ: "ê²½ìŸì‚¬ Aì˜ ì‹œì¥ì ìœ ìœ¨ì€ 30%ì…ë‹ˆë‹¤. [ì¶œì²˜: ì°¸ê³ ìë£Œ - ì‚°ì—…ë¶„ì„.pdf]"

3. PDF ë°ì´í„°ë¥¼ ë¶„ì„/ì¶”ë¡ í•œ ë‚´ìš©: `[ë¶„ì„: ë©”ì¸ PDF ê¸°ë°˜]`
   ì˜ˆ: "ì˜ì—…ì´ìµë¥ ì´ 16%ë¡œ ì´ìë³´ìƒëŠ¥ë ¥ì´ ì–‘í˜¸í•  ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤. [ë¶„ì„: ë©”ì¸ PDF ê¸°ë°˜]"

4. AI í•™ìŠµ ë°ì´í„° ê¸°ë°˜ ì¼ë°˜ ì§€ì‹: `[ì¶œì²˜: AI í•™ìŠµ ë°ì´í„° (2023ë…„ 10ì›” ê¸°ì¤€)]`
   ì˜ˆ: "AI ì‚°ì—…ì€ ê¸°ìˆ  ë³€í™”ê°€ ë¹ ë¥¸ íŠ¹ì„±ì´ ìˆìŠµë‹ˆë‹¤. [ì¶œì²˜: AI í•™ìŠµ ë°ì´í„° (2023ë…„ 10ì›” ê¸°ì¤€)]"

5. PDF + AI ì§€ì‹ì„ ì¢…í•© ë¶„ì„: `[ë¶„ì„: ì¢…í•© íŒë‹¨]`
   ì˜ˆ: "ì•ˆì •ì  ìˆ˜ìµì„±ì„ ë³´ìœ í•˜ë‚˜ ê²½ìŸ ì‹¬í™”ë¡œ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•©ë‹ˆë‹¤. [ë¶„ì„: ì¢…í•© íŒë‹¨]"

**ì¤‘ìš”:**
- ëª¨ë“  ë¬¸ì¥ì— ë°˜ë“œì‹œ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- [ì¶”ì •], [ì˜ˆìƒ] ê°™ì€ ì• ë§¤í•œ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€
- ì¶œì²˜ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ ë‚´ìš©ì„ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”

íˆ¬ììì™€ ëŒ€ì¶œ ì‹¬ì‚¬ì—­ì´ ì½ê¸°ì— ì í•©í•œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤."""},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=2000
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"âŒ OpenAI API ì˜¤ë¥˜: {str(e)}"

# íƒ€ì´í‹€
st.markdown("""
<div style='
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 20px 40px;
    border-radius: 20px;
    margin-bottom: 30px;
    box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
    text-align: center;
'>
    <div style='
        font-size: 32px;
        font-weight: 800;
        color: white;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        margin-bottom: 8px;
        letter-spacing: -1px;
    '>
        ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ê¸°
    </div>
    <div style='
        font-size: 15px;
        color: rgba(255, 255, 255, 0.95);
        font-weight: 500;
        letter-spacing: 0.5px;
    '>
        âœ¨ AI ê¸°ë°˜ ìë™ ì •ë³´ ì¶”ì¶œ ë° ì „ë¬¸ ë³´ê³ ì„œ ì‘ì„± ì‹œìŠ¤í…œ
    </div>
</div>
""", unsafe_allow_html=True)
st.markdown("")

# ì‚¬ì´ë“œë°” - í…œí”Œë¦¿ ì„¤ì •
with st.sidebar:
    st.header("ğŸ“ í…œí”Œë¦¿ ì„¤ì •")
    
    # ì´ì „ ë¶„ì„ ë¶ˆëŸ¬ì˜¤ê¸°
    if supabase_client:
        st.markdown("---")
        with st.expander("ğŸ“‚ ì´ì „ ë¶„ì„ ë¶ˆëŸ¬ì˜¤ê¸°"):
            companies = load_companies_list()
            if companies:
                company_names = [f"{c['company_name']} ({c['created_at'][:10]})" for c in companies]
                selected = st.selectbox("ê¸°ì—… ì„ íƒ", ["ì„ íƒí•˜ì„¸ìš”..."] + company_names)
                
                if selected != "ì„ íƒí•˜ì„¸ìš”...":
                    idx = company_names.index(selected)
                    company_id = companies[idx]["id"]
                    
                    if st.button("ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
                        loaded_data = load_company_data(company_id)
                        if loaded_data:
                            st.session_state.extracted_data = loaded_data
                            st.success("âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
                            st.rerun()
            else:
                st.info("ì €ì¥ëœ ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
    
    # ì¶”ì²œ í‚¤ì›Œë“œ
    st.subheader("ğŸ¯ ì¶”ì²œ í‚¤ì›Œë“œ")
    
    categories = {
        "ğŸ¢ ê¸°ì—… ê¸°ë³¸ ì •ë³´": [
            ("íšŒì‚¬ëª…", "í…ìŠ¤íŠ¸"), ("ê¸°ì—…ëª…", "í…ìŠ¤íŠ¸"), ("ë²•ì¸ëª…", "í…ìŠ¤íŠ¸"), ("ì„¤ë¦½ì¼", "í…ìŠ¤íŠ¸"),
            ("ë³¸ì‚¬ ìœ„ì¹˜", "í…ìŠ¤íŠ¸"), ("ëŒ€í‘œì´ì‚¬", "í…ìŠ¤íŠ¸"), ("CEO", "í…ìŠ¤íŠ¸"), ("ì§ì› ìˆ˜", "í…ìŠ¤íŠ¸"),
            ("ê³„ì—´ì‚¬", "í…ìŠ¤íŠ¸"), ("ì—…ì¢…", "í…ìŠ¤íŠ¸"), ("ì‚°ì—…ë¶„ë¥˜", "í…ìŠ¤íŠ¸"), ("ê¸°ì—… ê·œëª¨", "í…ìŠ¤íŠ¸")
        ],
        "ğŸ’° ì¬ë¬´ì •ë³´": [
            ("ë§¤ì¶œì•¡", "ìˆ«ì"), ("ì˜ì—…ì´ìµ", "ìˆ«ì"), ("ì˜ì—…ì´ìµë¥ ", "ìˆ«ì"), ("ìˆœì´ìµ", "ìˆ«ì"),
            ("EBITDA", "ìˆ«ì"), ("ë¶€ì±„ë¹„ìœ¨", "ìˆ«ì"), ("í˜„ê¸ˆíë¦„", "ìˆ«ì"), ("ROE", "ìˆ«ì"),
            ("CAPEX", "ìˆ«ì"), ("ì „ë…„ ëŒ€ë¹„ ì¦ê°", "ìˆ«ì"), ("YoY", "ìˆ«ì"), ("ë¶„ê¸° ì‹¤ì ", "ìˆ«ì")
        ],
        "ğŸ­ ì‚¬ì—…êµ¬ì¡° & ì œí’ˆ": [
            ("ì‚¬ì—…ë¶„ì•¼", "í…ìŠ¤íŠ¸"), ("ì£¼ìš” ì œí’ˆ", "í…ìŠ¤íŠ¸"), ("í•µì‹¬ ê¸°ìˆ ", "í…ìŠ¤íŠ¸"), ("ê²½ìŸìš°ìœ„", "í…ìŠ¤íŠ¸"),
            ("ì‹œì¥ ì ìœ ìœ¨", "í…ìŠ¤íŠ¸"), ("ê³ ê°ì‚¬", "í…ìŠ¤íŠ¸"), ("ìœ í†µ êµ¬ì¡°", "í…ìŠ¤íŠ¸"), ("í”Œë«í¼", "í…ìŠ¤íŠ¸")
        ],
        "âš”ï¸ ê²½ìŸí™˜ê²½": [
            ("ê²½ìŸì‚¬", "í…ìŠ¤íŠ¸"), ("ì‹œì¥ ê·œëª¨", "í…ìŠ¤íŠ¸"), ("ì‹œì¥ ì„±ì¥ë¥ ", "í…ìŠ¤íŠ¸"), ("ì§„ì…ì¥ë²½", "í…ìŠ¤íŠ¸"),
            ("SWOT ë¶„ì„", "í…ìŠ¤íŠ¸"), ("ê·œì œ ì´ìŠˆ", "í…ìŠ¤íŠ¸"), ("ì‚°ì—… íŠ¸ë Œë“œ", "í…ìŠ¤íŠ¸"), ("CAGR", "í…ìŠ¤íŠ¸")
        ],
        "âš ï¸ ì£¼ìš” ë¦¬ìŠ¤í¬": [
            ("ì¬ë¬´ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ìš´ì˜ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ê³µê¸‰ë§ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("ê¸°ìˆ  ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"),
            ("ê·œì œ ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸"), ("í™˜ìœ¨ ì˜í–¥", "í…ìŠ¤íŠ¸"), ("ë²•ì  ì´ìŠˆ", "í…ìŠ¤íŠ¸"), ("ESG ë¦¬ìŠ¤í¬", "í…ìŠ¤íŠ¸")
        ],
        "ğŸš€ ê¸°íšŒ ìš”ì¸ & ì „ëµ": [
            ("ì‹ ê·œ ì‚¬ì—…", "í…ìŠ¤íŠ¸"), ("M&A", "í…ìŠ¤íŠ¸"), ("íˆ¬ì ê³„íš", "í…ìŠ¤íŠ¸"), ("ê¸€ë¡œë²Œ ì§„ì¶œ", "í…ìŠ¤íŠ¸"),
            ("R&D", "í…ìŠ¤íŠ¸"), ("ì‹ ì œí’ˆ ì¶œì‹œ", "í…ìŠ¤íŠ¸"), ("ESG ì „ëµ", "í…ìŠ¤íŠ¸"), ("ìˆ˜ìµì„± ê°œì„ ", "í…ìŠ¤íŠ¸")
        ]
    }
    
    for category, keywords in categories.items():
        with st.expander(category):
            cols = st.columns(2)
            for idx, (kw, ftype) in enumerate(keywords):
                col = cols[idx % 2]
                if col.button(f"â• {kw}", key=f"add_{category}_{kw}", use_container_width=True):
                    if not any(f['name'] == kw for f in st.session_state.template):
                        st.session_state.template.append({"name": kw, "type": ftype})
                        st.rerun()
    
    st.markdown("---")
    st.subheader("âœï¸ ì§ì ‘ ì¶”ê°€")
    
    with st.form("add_field_form"):
        field_name = st.text_input("í•„ë“œ ì´ë¦„", placeholder="ì˜ˆ: íšŒì‚¬ì´ë¦„")
        field_type = st.selectbox("ë°ì´í„° íƒ€ì…", ["í…ìŠ¤íŠ¸", "ìˆ«ì"])
        submitted = st.form_submit_button("â• í•„ë“œ ì¶”ê°€", use_container_width=True)
        
        if submitted and field_name:
            if not any(f['name'] == field_name for f in st.session_state.template):
                st.session_state.template.append({"name": field_name, "type": field_type})
                st.rerun()
            else:
                st.warning(f"'{field_name}'ì€(ëŠ”) ì´ë¯¸ ì¶”ê°€ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
    
    col1, col2 = st.columns(2)
    if col1.button("ğŸ“‹ ì˜ˆì‹œ ë¡œë“œ", use_container_width=True):
        st.session_state.template = [
            {"name": "íšŒì‚¬ì´ë¦„", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ëŒ€í‘œì´ë¦„", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ì‚¬ì—…ë¶„ì•¼", "type": "í…ìŠ¤íŠ¸"},
            {"name": "ì—°ë§¤ì¶œ", "type": "ìˆ«ì"},
        ]
        st.rerun()
    
    if col2.button("ğŸ—‘ï¸ ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.template = []
        st.rerun()

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3 = st.tabs(["ğŸ“‹ í…œí”Œë¦¿ ëª©ë¡", "ğŸ” ë°ì´í„° ì¶”ì¶œ", "ğŸ“„ ë³´ê³ ì„œ ìƒì„±"])

with tab1:
    st.subheader("ğŸ“‹ í˜„ì¬ í…œí”Œë¦¿ ëª©ë¡")
    
    if st.session_state.template:
        st.markdown(f"**ì´ {len(st.session_state.template)}ê°œ í•„ë“œ**")
        
        # ë²„íŠ¼ ìŠ¤íƒ€ì¼ë¡œ í‘œì‹œ (ì¶”ì²œ í‚¤ì›Œë“œì²˜ëŸ¼)
        cols = st.columns(4)  # í•œ ì¤„ì— 4ê°œ
        for idx, field in enumerate(st.session_state.template):
            col = cols[idx % 4]
            type_icon = "ğŸ”¢" if field['type'] == "ìˆ«ì" else "ğŸ“"
            
            with col:
                # í‚¤ì›Œë“œëª…ê³¼ X ë²„íŠ¼ì„ í•œ ì¤„ë¡œ í‘œì‹œ
                button_col1, button_col2 = st.columns([4, 1])
                with button_col1:
                    st.markdown(f"""
                    <div style='
                        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                        color: white;
                        padding: 10px 15px;
                        border-radius: 12px;
                        font-size: 13px;
                        font-weight: 500;
                        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                        margin-bottom: 10px;
                        text-align: left;
                    '>
                        {type_icon} {field['name']}
                    </div>
                    """, unsafe_allow_html=True)
                with button_col2:
                    if st.button("âœ•", key=f"delete_{idx}", help="ì‚­ì œ", use_container_width=True):
                        st.session_state.template.pop(idx)
                        st.rerun()
    else:
        st.info("í…œí”Œë¦¿ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")

with tab2:
    st.subheader("ğŸ” ë°ì´í„° ì¶”ì¶œ")
    st.info("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  AIê°€ ìë™ìœ¼ë¡œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
    
    # ë©”ì¸ PDF ì—…ë¡œë“œ
    st.markdown("### ğŸ“„ ê¸°ì—… ë³´ê³ ì„œ (í•„ìˆ˜)")
    uploaded_file = st.file_uploader("ê¸°ì—… ì‚¬ì—…ë³´ê³ ì„œ PDF ì—…ë¡œë“œ", type=['pdf'], key="main_pdf")
    
    # ì°¸ê³ ìë£Œ PDF ì—…ë¡œë“œ (RAG)
    st.markdown("---")
    st.markdown("### ğŸ“š ì°¸ê³ ìë£Œ ì¶”ê°€ (ì„ íƒ)")
    st.info("ğŸ’¡ ê²½ìŸì‚¬ ìë£Œ, ì‚°ì—… ë¦¬í¬íŠ¸, ì‹œì¥ ë¶„ì„ ìë£Œ ë“±ì„ ì¶”ê°€í•˜ë©´ ë” ì •í™•í•œ ë³´ê³ ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    
    reference_files = st.file_uploader(
        "ì°¸ê³ ìë£Œ PDF ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", 
        type=['pdf'], 
        accept_multiple_files=True,
        key="reference_pdfs_upload"
    )
    
    # ì°¸ê³ ìë£Œ ì²˜ë¦¬
    if reference_files:
        st.markdown("**ğŸ“‹ ì—…ë¡œë“œëœ ì°¸ê³ ìë£Œ:**")
        for ref_file in reference_files:
            st.markdown(f"- {ref_file.name}")
    
    st.markdown("---")
    
    if uploaded_file and st.button("ğŸš€ ë°ì´í„° ì¶”ì¶œ ì‹œì‘", type="primary"):
        if not st.session_state.template:
            st.error("âŒ í…œí”Œë¦¿ì„ ë¨¼ì € ì„¤ì •í•˜ì„¸ìš”! ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        else:
            with st.spinner("ğŸ“„ PDF ì²˜ë¦¬ ì¤‘..."):
                # ë©”ì¸ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
                pdf_text, num_pages = extract_text_from_pdf(uploaded_file, max_pages=5)
                st.session_state.pdf_text = pdf_text
                
                # ì°¸ê³ ìë£Œ PDF ì²˜ë¦¬
                st.session_state.reference_pdfs = {}
                if reference_files:
                    with st.spinner(f"ğŸ“š ì°¸ê³ ìë£Œ {len(reference_files)}ê°œ ì²˜ë¦¬ ì¤‘..."):
                        for ref_file in reference_files:
                            ref_text, ref_pages = extract_text_from_pdf(ref_file, max_pages=10)
                            if ref_text:
                                st.session_state.reference_pdfs[ref_file.name] = ref_text
                                st.success(f"âœ… {ref_file.name} ì²˜ë¦¬ ì™„ë£Œ ({ref_pages}í˜ì´ì§€, {len(ref_text)}ì)")
                
                if pdf_text:
                    st.success(f"âœ… ë©”ì¸ PDF {num_pages}í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ (ì´ {len(pdf_text)}ì ì¶”ì¶œ)")
                    
                    # ë°°ì¹˜ ë°©ì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (í† í° ì ˆê°)
                    with st.spinner("ğŸ” ë°ì´í„° ì¶”ì¶œ ì¤‘..."):
                        field_names = [field['name'] for field in st.session_state.template]
                        extracted_data = extract_all_keywords_batch(pdf_text, field_names)
                        st.session_state.extracted_data = extracted_data
                    
                    # Supabaseì— ì €ì¥
                    if supabase_client:
                        with st.spinner("ğŸ’¾ Supabaseì— ì €ì¥ ì¤‘..."):
                            company_name = extracted_data.get("íšŒì‚¬ëª…") or extracted_data.get("ê¸°ì—…ëª…") or "Unknown"
                            company_id = save_to_supabase(
                                company_name=company_name,
                                pdf_file=uploaded_file,
                                extracted_text=pdf_text,
                                extracted_data=extracted_data
                            )
                            if company_id:
                                st.success("âœ… Supabase ì €ì¥ ì™„ë£Œ!")
                    
                    # ê²°ê³¼ í‘œì‹œ - Gradio ìŠ¤íƒ€ì¼ë¡œ
                    st.markdown("---")
                    st.markdown("## âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                    st.markdown("### ğŸ¤– AIê°€ ìë™ìœ¼ë¡œ ì¶”ì¶œí•œ ì •ë³´")
                    
                    # ì¶”ì¶œëœ ë°ì´í„°ë¥¼ ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    for field in st.session_state.template:
                        value = extracted_data.get(field['name'], "ì •ë³´ ì—†ìŒ")
                        st.markdown(f"**ğŸ“Œ {field['name']}**")
                        st.markdown(f"""
                        <div style='padding: 10px; background: white; border-radius: 8px; 
                        margin-bottom: 15px; border: 1px solid #e2e8f0;'>
                        {value}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ
                    st.markdown("---")
                    st.markdown("### ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì)")
                    st.markdown(f"""
                    <div style='background: #f8fafc; padding: 15px; border-radius: 8px; 
                    font-family: monospace; font-size: 13px; line-height: 1.6; 
                    max-height: 400px; overflow-y: auto;'>
                    {pdf_text[:1000]}...
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.error("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì´ë¯¸ ì¶”ì¶œëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    elif st.session_state.extracted_data and st.session_state.pdf_text:
        st.markdown("---")
        st.markdown("## âœ… ì²˜ë¦¬ ì™„ë£Œ!")
        st.markdown("### ğŸ¤– AIê°€ ìë™ìœ¼ë¡œ ì¶”ì¶œí•œ ì •ë³´")
        
        for field in st.session_state.template:
            value = st.session_state.extracted_data.get(field['name'], "ì •ë³´ ì—†ìŒ")
            st.markdown(f"**ğŸ“Œ {field['name']}**")
            st.markdown(f"""
            <div style='padding: 10px; background: white; border-radius: 8px; 
            margin-bottom: 15px; border: 1px solid #e2e8f0;'>
            {value}
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        st.markdown("### ğŸ“„ ì¶”ì¶œëœ ì›ë³¸ í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì)")
        st.markdown(f"""
        <div style='background: #f8fafc; padding: 15px; border-radius: 8px; 
        font-family: monospace; font-size: 13px; line-height: 1.6; 
        max-height: 400px; overflow-y: auto;'>
        {st.session_state.pdf_text[:1000]}...
        </div>
        """, unsafe_allow_html=True)

with tab3:
    st.subheader("ğŸ“„ ë³´ê³ ì„œ ìƒì„±")
    st.info("AIê°€ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ ë³´ê³ ì„œë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤")
    
    if not st.session_state.extracted_data:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì¶”ì¶œ' íƒ­ì—ì„œ PDF ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.")
    else:
        st.markdown("### ğŸ“Š ì¶”ì¶œëœ ë°ì´í„° í™•ì¸")
        for key, value in st.session_state.extracted_data.items():
            st.markdown(f"**{key}**: {value}")
        
        st.markdown("---")
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            if st.button("ğŸ“‹ ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°", type="secondary"):
                with st.spinner("âœ¨ OpenAIë¡œ ë³´ê³ ì„œ ìƒì„± ì¤‘..."):
                    try:
                        report = generate_report_with_openai(
                            st.session_state.extracted_data
                        )
                        
                        # ì°¸ê³ ìë£Œ ì •ë³´ ì¶”ê°€
                        if st.session_state.get('reference_pdfs'):
                            ref_list = list(st.session_state.reference_pdfs.keys())
                            report += f"\n\n---\n\n**ğŸ“š ì°¸ê³ ìë£Œ ëª©ë¡:**\n"
                            for ref_file in ref_list:
                                report += f"- {ref_file}\n"
                        
                        # ë³´ê³ ì„œë¥¼ ì„¸ì…˜ì— ì €ì¥
                        st.session_state.report = report
                        st.rerun()
                        
                    except Exception as e:
                        st.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        with col2:
            if st.button("ğŸ“„ ë³´ê³ ì„œ ìƒì„± (DOCX)", type="primary"):
                if 'report' not in st.session_state or not st.session_state.report:
                    st.error("âŒ ë¨¼ì € 'ë³´ê³ ì„œ ë¯¸ë¦¬ë³´ê¸°' ë²„íŠ¼ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ì„¸ìš”.")
                else:
                    try:
                        # DOCX ìƒì„±
                        doc = Document()
                        
                        # ì œëª©
                        title = doc.add_heading('ê¸°ì—… ë¶„ì„ ë³´ê³ ì„œ', 0)
                        title.alignment = 1  # ì¤‘ì•™ ì •ë ¬
                        
                        # ì‘ì„±ì¼
                        date_para = doc.add_paragraph(f'ì‘ì„±ì¼: {datetime.now().strftime("%Yë…„ %mì›” %dì¼")}')
                        date_para.alignment = 1
                        doc.add_paragraph('')
                        
                        # ë³´ê³ ì„œ ë‚´ìš© íŒŒì‹± ë° ì¶”ê°€
                        lines = st.session_state.report.split('\n')
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                            
                            # ì œëª© ì²˜ë¦¬ (## ì‹œì‘)
                            if line.startswith('## '):
                                doc.add_heading(line.replace('## ', ''), 1)
                            elif line.startswith('### '):
                                doc.add_heading(line.replace('### ', ''), 2)
                            # ë³¼ë“œ ì²˜ë¦¬ (**í…ìŠ¤íŠ¸**)
                            elif line.startswith('**') and line.endswith('**'):
                                p = doc.add_paragraph()
                                p.add_run(line.strip('*')).bold = True
                            # ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
                            elif line.startswith('- ') or line.startswith('* '):
                                doc.add_paragraph(line[2:], style='List Bullet')
                            # ì¼ë°˜ ë¬¸ë‹¨
                            else:
                                doc.add_paragraph(line)
                        
                        doc.add_paragraph('')
                        doc.add_paragraph('â”€' * 50)
                        doc.add_paragraph('')
                        
                        # ì¶”ì¶œëœ ë°ì´í„° í…Œì´ë¸”
                        doc.add_heading('ğŸ“‹ ì¶”ì¶œëœ ìƒì„¸ ë°ì´í„°', 1)
                        
                        table = doc.add_table(rows=1, cols=2)
                        table.style = 'Light Grid Accent 1'
                        
                        hdr = table.rows[0].cells
                        hdr[0].text = 'í•­ëª©'
                        hdr[1].text = 'ë‚´ìš©'
                        
                        for key, val in st.session_state.extracted_data.items():
                            row = table.add_row().cells
                            row[0].text = key
                            row[1].text = str(val)
                        
                        # íŒŒì¼ ì €ì¥
                        output_path = "ê¸°ì—…_ë¶„ì„_ë³´ê³ ì„œ.docx"
                        doc.save(output_path)
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ
                        with open(output_path, "rb") as file:
                            st.download_button(
                                label="ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                                data=file,
                                file_name=f"ê¸°ì—…_ë¶„ì„_ë³´ê³ ì„œ_{datetime.now().strftime('%Y%m%d')}.docx",
                                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                            )
                        
                        st.success("âœ… DOCX ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        
                    except Exception as e:
                        st.error(f"âŒ DOCX ìƒì„± ì‹¤íŒ¨: {str(e)}")
        
        with col3:
            if st.button("âš™ï¸ í…œí”Œë¦¿", help="ë³´ê³ ì„œ ì‘ì„± ì§€ì¹¨ ìˆ˜ì •"):
                st.session_state.show_template_editor = not st.session_state.show_template_editor
                st.rerun()
        
        # ë³´ê³ ì„œ í…œí”Œë¦¿ í¸ì§‘ê¸°
        if st.session_state.show_template_editor:
            st.markdown("---")
            st.markdown("### âš™ï¸ ë³´ê³ ì„œ ì„¹ì…˜ ì„ íƒ")
            st.info("ğŸ’¡ ì›í•˜ëŠ” ë³´ê³ ì„œ ì„¹ì…˜ì„ ì„ íƒí•˜ì„¸ìš”. ì„ íƒí•œ ì„¹ì…˜ë§Œ ë³´ê³ ì„œì— í¬í•¨ë©ë‹ˆë‹¤.")
            
            # ëª¨ë“  ì„¹ì…˜ ì²´í¬ë°•ìŠ¤
            available_sections = [
                "ê¸°ì—… ê°œìš”",
                "ì‚¬ì—… êµ¬ì¡° ë° Revenue Model ë¶„ì„",
                "ì‚°ì—… ë° ì‹œì¥ ë¶„ì„",
                "ì¬ë¬´ ìš”ì•½",
                "ì¬ë¬´ ê±´ì „ì„± ì‹¬í™” ë¶„ì„",
                "ê³ ê°ì‚¬ ë° ë§¤ì¶œ ì§‘ì¤‘ë„ ë¶„ì„",
                "ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„",
                "ê²½ì˜ì§„ ì—­ëŸ‰ ë° ì§€ë°°êµ¬ì¡° ë¶„ì„",
                "ì‹ ìš©ë„ ë° ë²•ë¥  ë¦¬ìŠ¤í¬",
                "ë¦¬ìŠ¤í¬ ìš”ì¸",
                "ì¢…í•© í‰ê°€"
            ]
            
            # 2ì—´ë¡œ ë°°ì¹˜
            cols = st.columns(2)
            selected_sections = []
            
            for idx, section in enumerate(available_sections):
                col = cols[idx % 2]
                with col:
                    is_selected = st.checkbox(
                        section,
                        value=section in st.session_state.report_sections,
                        key=f"section_{section}"
                    )
                    if is_selected:
                        selected_sections.append(section)
            
            col_save, col_reset = st.columns(2)
            with col_save:
                if st.button("ğŸ’¾ ì„ íƒ ì €ì¥", type="primary", use_container_width=True):
                    st.session_state.report_sections = selected_sections
                    st.success(f"âœ… {len(selected_sections)}ê°œ ì„¹ì…˜ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            with col_reset:
                if st.button("ğŸ”„ ì „ì²´ ì„ íƒ", use_container_width=True):
                    st.session_state.report_sections = available_sections.copy()
                    st.success("âœ… ëª¨ë“  ì„¹ì…˜ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.rerun()
            
            # ì„ íƒëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
            if selected_sections:
                with st.expander("ğŸ“‹ ì„ íƒëœ ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    for section in selected_sections:
                        st.markdown(f"**âœ“ {section}**")
                        if section in REPORT_SECTION_TEMPLATES:
                            st.text(REPORT_SECTION_TEMPLATES[section])
                        st.markdown("---")
        
        # ìƒì„±ëœ ë³´ê³ ì„œê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ
        if 'report' in st.session_state and st.session_state.report:
            st.markdown("---")
            st.markdown("### ğŸ“„ ìƒì„±ëœ ë³´ê³ ì„œ")
            st.markdown(st.session_state.report)


